@article{abburuOntologyStorageModels2016,
  title = {Ontology {{Storage Models}} and {{Tools}}: {{An Authentic Survey}}},
  shorttitle = {Ontology {{Storage Models}} and {{Tools}}},
  author = {Abburu, Sunitha and Golla, Suresh Babu},
  year = {2016},
  month = oct,
  journal = {Journal of Intelligent Systems},
  volume = {25},
  number = {4},
  pages = {539--553},
  issn = {2191-026X, 0334-1860},
  doi = {10.1515/jisys-2014-0167},
  urldate = {2024-08-17},
  abstract = {Ontology is a formal, explicit specification of a shared conceptualization. Ontology provides domain vocabulary, domain knowledge, common understanding, shareability, information interoperability, reusability, concept hierarchy, and relationships that support semantic information retrieval. Ontology improves performance of the system by addressing interoperability issues due to semantic and syntactic heterogeneity. Vast numbers of application domain experts are using ontologies in diverse applications. Use of effective and efficient ontology storage system results improved performance in applications and enables semantic information retrieval. Many prominent researchers and software agencies have proposed and developed several ontology storage methods and tools with various features. The choice of a specific storage model/tool always depend on the specific purpose of the application and the nature of features that are available in the storage model/tool to be utilized in the specific applications. The familiarity of various ontology storage models and tools with the respective features helps user to choose an appropriate storage structure aiming at high-performance applications. The current research work is a comprehensively authentic study carryout out on various ontology storage models and tools with their respective features, which are very essential for optimum performance.},
  copyright = {http://creativecommons.org/licenses/by-nc-nd/3.0/},
  langid = {english},
}

@article{abdel-nabiDeepLearningbasedQuestion2023,
  title = {Deep Learning-Based Question Answering: A Survey},
  shorttitle = {Deep Learning-Based Question Answering},
  author = {{Abdel-Nabi}, Heba and Awajan, Arafat and Ali, Mostafa Z.},
  year = {2023},
  month = apr,
  journal = {Knowledge and Information Systems},
  volume = {65},
  number = {4},
  pages = {1399--1485},
  issn = {0219-1377, 0219-3116},
  doi = {10.1007/s10115-022-01783-5},
  urldate = {2024-03-04},
  abstract = {Question Answering is a crucial natural language processing task. This field of research has attracted a sudden amount of interest lately due mainly to the integration of the deep learning models in the Question Answering Systems which consequently power up many advancements and improvements. This survey aims to explore and shed light upon the recent and most powerful deep learning-based Question Answering Systems and classify them based on the deep learning model used, stating the details of the used word representation, datasets, and evaluation metrics. It aims to highlight and discuss the currently used models and give insights that direct future research to enhance this increasingly growing field.},
  langid = {english},
}

@inproceedings{abeduLLMBasedChatbotsMining2024,
  title = {{{LLM-Based Chatbots}} for {{Mining Software Repositories}}: {{Challenges}} and {{Opportunities}}},
  shorttitle = {{{LLM-Based Chatbots}} for {{Mining Software Repositories}}},
  booktitle = {Proceedings of the 28th {{International Conference}} on {{Evaluation}} and {{Assessment}} in {{Software Engineering}}},
  author = {Abedu, Samuel and Abdellatif, Ahmad and Shihab, Emad},
  year = {2024},
  month = jun,
  pages = {201--210},
  publisher = {ACM},
  address = {Salerno Italy},
  doi = {10.1145/3661167.3661218},
  urldate = {2024-08-17},
  abstract = {Software repositories have a plethora of information about software development, encompassing details such as code contributions, bug reports, code reviews, and project documentation. This rich source of data can be harnessed to enhance not only software quality and development velocity but also to gain insights into team collaboration, identify potential bottlenecks, and inform strategic decision-making throughout the software development lifecycle. Previous studies show that many stakeholders cannot benefit from the project information due to the technical knowledge and expertise required to extract the project data. To lower the barrier to entry by automating the process of extracting and analyzing repository data, we explored the potential of using a large language model (LLM) to develop a chatbot for answering questions related to software repositories. We evaluated the chatbot on a set of 150 software repository-related questions. We found that the chatbot correctly answered one question about the repository. This result prompted us to shift our focus to investigate the challenges in adopting LLMs for the out-of-the-box development of software repository chatbots. We identified five main challenges related to retrieving data, structuring the data, and generating the answer to the user's query. Among these challenges, the most frequent (83.3\%) is the inaccurate retrieval of data to answer questions. In this paper, we share our experience and challenges in developing an LLM-based chatbot to answer software repository-related questions within the SE community. We also provide recommendations on mitigating these challenges. Our findings will serve as a foundation to drive future research aimed at enhancing LLMs for adoption in extracting useful information from software repositories, fostering advancements in natural language understanding, data retrieval, and response generation within the context of software repository-related questions and analytics.},
  isbn = {9798400717017},
  langid = {english},
}

@article{AbstractSemanticGraph2024,
  title = {Abstract Semantic Graph},
  year = {2024},
  month = jul,
  journal = {Wikipedia},
  url = {https://en.wikipedia.org/w/index.php?title=Abstract_semantic_graph&oldid=1233821054},
  urldate = {2024-11-22},
  abstract = {In computer science, an abstract semantic graph (ASG) or term graph is a form of abstract syntax in which an expression of a formal or programming language is represented by a graph whose vertices are the expression's subterms. An ASG is at a higher level of abstraction than an abstract syntax tree (or AST), which is used to express the syntactic structure of an expression or program. ASGs are more complex and concise than ASTs because they may contain shared subterms (also known as "common subexpressions"). Abstract semantic graphs are often used as an intermediate representation by compilers to store the results of performing common subexpression elimination upon abstract syntax trees. ASTs are trees and are thus incapable of representing shared terms. ASGs are usually directed acyclic graphs (DAG), although in some applications graphs containing cycles may be permitted. For example, a graph containing a cycle might be used to represent the recursive expressions that are commonly used in functional programming languages as non-looping iteration constructs. The mutability of these types of graphs, is studied in the field of graph rewriting. The nomenclature term graph is associated with the field of term graph rewriting, which involves the transformation and processing of expressions by the specification of rewriting rules, whereas abstract semantic graph is used when discussing linguistics, programming languages, type systems and compilation. Abstract syntax trees are not capable of sharing subexpression nodes because it is not possible for a node in a proper tree to have more than one parent. Although this conceptual simplicity is appealing, it may come at the cost of redundant representation and, in turn, possibly inefficiently duplicating the computation of identical terms. For this reason ASGs are often used as an intermediate language at a subsequent compilation stage to abstract syntax tree construction via parsing. An abstract semantic graph is typically constructed from an abstract syntax tree by a process of enrichment and abstraction. The enrichment can for example be the addition of back-pointers, edges from an identifier node (where a variable is being used) to a node representing the declaration of that variable. The abstraction can entail the removal of details which are relevant only in parsing, not for semantics.},
  copyright = {Creative Commons Attribution-ShareAlike License},
  langid = {english},
  annotation = {Page Version ID: 1233821054},
}

@inproceedings{abu-aishehExactGraphEdit2015,
  title = {An {{Exact Graph Edit Distance Algorithm}} for {{Solving Pattern Recognition Problems}}},
  booktitle = {4th {{International Conference}} on {{Pattern Recognition Applications}} and {{Methods}} 2015},
  author = {{Abu-Aisheh}, Zeina and Raveaux, Romain and Ramel, Jean-Yves and Martineau, Patrick},
  year = {2015},
  month = jan,
  address = {Lisbon, Portugal},
  doi = {10.5220/0005209202710278},
  urldate = {2024-08-02},
  abstract = {Graph edit distance is an error tolerant matching technique emerged as a powerful and flexible graph matching paradigm that can be used to address different tasks in pattern recognition, machine learning and data mining; it represents the minimum-cost sequence of basic edit operations to transform one graph into another by means of insertion, deletion and substitution of vertices and/or edges. A widely used method for exact graph edit distance computation is based on the A* algorithm. To overcome its high memory load while traversing the search tree for storing pending solutions to be explored, we propose a depth-first graph edit distance algorithm which requires less memory and searching time. An evaluation of all possible solutions is performed without explicitly enumerating them all. Candidates are discarded using an upper and lower bounds strategy. A solid experimental study is proposed; experiments on a publicly available database empirically demonstrated that our approach is better than the A* graph edit distance computation in terms of speed, accuracy and classification rate.},
  keywords = {Classification,Graph Edit Distance,Graph Matching,Pattern Recognition},
}

@inproceedings{agarwalNeurIPS2020NLC2CMD2021,
  title = {{{NeurIPS}} 2020 {{NLC2CMD Competition}}: {{Translating Natural Language}} to {{Bash Commands}}},
  shorttitle = {{{NeurIPS}} 2020 {{NLC2CMD Competition}}},
  booktitle = {Proceedings of the {{NeurIPS}} 2020 {{Competition}} and {{Demonstration Track}}},
  author = {Agarwal, Mayank and Chakraborti, Tathagata and Fu, Quchen and Gros, David and Lin, Xi Victoria and Maene, Jaron and Talamadupula, Kartik and Teng, Zhongwei and White, Jules},
  year = {2021},
  month = aug,
  pages = {302--324},
  publisher = {PMLR},
  issn = {2640-3498},
  urldate = {2024-08-26},
  abstract = {The NLC2CMD Competition hosted at NeurIPS 2020 aimed to bring the power of natural language processing to the command line. Participants were tasked with building models that can transform descriptions of command line tasks in English to their Bash syntax. This is a report on the competition with details of the task, metrics, data, attempted solutions, and lessons learned.},
  langid = {english},
  annotation = {https://proceedings.mlr.press/v133/agarwal21b.html},
}

@misc{agarwalProjectCLAIInstrumenting2020,
  title = {Project {{CLAI}}: {{Instrumenting}} the {{Command Line}} as a {{New Environment}} for {{AI Agents}}},
  shorttitle = {Project {{CLAI}}},
  author = {Agarwal, Mayank and Barroso, Jorge J. and Chakraborti, Tathagata and Dow, Eli M. and Fadnis, Kshitij and Godoy, Borja and Pallan, Madhavan and Talamadupula, Kartik},
  year = {2020},
  month = jun,
  number = {arXiv:2002.00762},
  eprint = {2002.00762},
  primaryclass = {cs},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/2002.00762},
  urldate = {2023-12-08},
  abstract = {This paper reports on Project CLAI (Command Line AI) which aims to bring the power of AI to the command line interface (CLI). The CLAI platform sets up the CLI as a new environment for AI researchers to conquer by surfacing the command line as a generic environment that researchers can interface to using a simple sense-act API, much like the traditional AI agent architecture. In this paper, we discuss the design and implementation of the platform in detail, through illustrative use cases of new end user interaction patterns enabled by this design, and through quantitative evaluation of the system footprint of a CLAI-enabled terminal. We also report on some early user feedback on CLAI's features from an internal survey.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Human-Computer Interaction},
}

@misc{ahmadanisFineTuningLLAMAv22023,
  title = {Fine {{Tuning LLAMAv2}} with {{QLora}} on {{Google Colab}} for {{Free}}},
  author = {{Ahmad Anis}},
  year = {2023},
  month = sep,
  journal = {KDnuggets},
  url = {https://www.kdnuggets.com/fine-tuning-llamav2-with-qlora-on-google-colab-for-free},
  urldate = {2024-08-14},
  abstract = {Learn how to fine-tune one of the most influential open-source models for free on Google Colab.},
  chapter = {Originals},
  langid = {american},
}

@article{albersModelbasedSystemsEngineering2019,
  title = {Model-Based Systems Engineering in Modular Design},
  author = {Albers, Albert and Bursac, Nikola and Scherer, Helmut and Birk, Clemens and Powelske, Jonas and Muschik, Sabine},
  year = {2019},
  month = jan,
  journal = {Design Science},
  volume = {5},
  pages = {e17},
  issn = {2053-4701},
  doi = {10.1017/dsj.2019.15},
  urldate = {2024-09-11},
  abstract = {Modular design allows to reduce costs based on scaling effects. However, due to strong alternating effects between the resulting modules and products, methods and tools are required that enable engineers to use specific views in which the respective information can be linked and retrieved according to the situation. Within the scope of this paper, the model-based systems engineering (MBSE) approach is used to model the complex real-world problem of vehicle modular kits. The aim is to investigate the potentials in this context, how modular kits and products can be efficiently modeled and finally how MBSE can support modular design. In order to investigate this in detail, two extensive studies are carried out in a company over a period of three years. The studies show that modular kits lead to an increased complexity of development. Across industries and companies, the demand for reference product models is shown, which facilitate the unification of inhomogeneous partial models and serve as a knowledge repository for the development of future product generations. On this basis, a framework is derived which enables the reuse of large proportions of the product models of previous product generations. This framework is evaluated on the basis of five case studies.},
  langid = {english},
  keywords = {case studies,mbse,modular design,PGE - product generation engineering,reference product models},
}

@misc{anglesFoundationsModernQuery2017,
  title = {Foundations of {{Modern Query Languages}} for {{Graph Databases}}},
  author = {Angles, Renzo and Arenas, Marcelo and Barcelo, Pablo and Hogan, Aidan and Reutter, Juan and Vrgoc, Domagoj},
  year = {2017},
  month = jun,
  publisher = {arXiv},
  doi = {10.48550/arXiv.1610.06264},
  urldate = {2024-08-05},
  abstract = {We survey foundational features underlying modern graph query languages. We first discuss two popular graph data models: edge-labelled graphs, where nodes are connected by directed, labelled edges; and property graphs, where nodes and edges can further have attributes. Next we discuss the two most fundamental graph querying functionalities: graph patterns and navigational expressions. We start with graph patterns, in which a graph-structured query is matched against the data. Thereafter we discuss navigational expressions, in which patterns can be matched recursively against the graph to navigate paths of arbitrary length; we give an overview of what kinds of expressions have been proposed, and how they can be combined with graph patterns. We also discuss several semantics under which queries using the previous features can be evaluated, what effects the selection of features and semantics has on complexity, and offer examples of such features in three modern languages that are used to query graphs: SPARQL, Cypher and Gremlin. We conclude by discussing the importance of formalisation for graph query languages; a summary of what is known about SPARQL, Cypher and Gremlin in terms of expressivity and complexity; and an outline of possible future directions for the area.},
  langid = {english},
  keywords = {Computer Science - Databases},
}

@misc{anKnowledgeGraphQuestion2024,
  title = {Knowledge {{Graph Question Answering}} for {{Materials Science}} ({{KGQA4MAT}}): {{Developing Natural Language Interface}} for {{Metal-Organic Frameworks Knowledge Graph}} ({{MOF-KG}}) {{Using LLM}}},
  shorttitle = {Knowledge {{Graph Question Answering}} for {{Materials Science}} ({{KGQA4MAT}})},
  author = {An, Yuan and Greenberg, Jane and Kalinowski, Alex and Zhao, Xintong and Hu, Xiaohua and {Uribe-Romo}, Fernando J. and Langlois, Kyle and Furst, Jacob and {G{\'o}mez-Gualdr{\'o}n}, Diego A.},
  year = {2024},
  month = jun,
  number = {arXiv:2309.11361},
  eprint = {2309.11361},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2309.11361},
  urldate = {2024-12-17},
  abstract = {We present a comprehensive benchmark dataset for Knowledge Graph Question Answering in Materials Science (KGQA4MAT), with a focus on metal-organic frameworks (MOFs). A knowledge graph for metal-organic frameworks (MOF-KG) has been constructed by integrating structured databases and knowledge extracted from the literature. To enhance MOF-KG accessibility for domain experts, we aim to develop a natural language interface for querying the knowledge graph. We have developed a benchmark comprised of 161 complex questions involving comparison, aggregation, and complicated graph structures. Each question is rephrased in three additional variations, resulting in 644 questions and 161 KG queries. To evaluate the benchmark, we have developed a systematic approach for utilizing the LLM, ChatGPT, to translate natural language questions into formal KG queries. We also apply the approach to the well-known QALD-9 dataset, demonstrating ChatGPT's potential in addressing KGQA issues for different platforms and query languages. The benchmark and the proposed approach aim to stimulate further research and development of user-friendly and efficient interfaces for querying domain-specific materials science knowledge graphs, thereby accelerating the discovery of novel materials.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence},
}

@article{arenasSPARQLFormalization,
  title = {{{SPARQL Formalization}}},
  author = {Arenas, Marcelo and Gutierrez, Claudio and P{\'e}rez, Jorge},
  langid = {english},
}

@article{aslaniParallelTBoxClassification,
  title = {Parallel {{TBox Classification}} in {{Description Logics}} -- {{First Experimental Results}}},
  author = {Aslani, Mina and Haarslev, Volker},
  abstract = {One of the most frequently used inference services of description logic reasoners classifies all named classes of OWL ontologies into a subsumption hierarchy. Due to emerging OWL ontologies from the web community consisting of up to hundreds of thousand of named classes and the increasing availability of multi-processor and multi- or many-core computers, we extend our work on parallel TBox classification and propose a new algorithm that is sound and complete and demonstrates in a first experimental evaluation a low overhead w.r.t. subsumption tests (less than 3\%) if compared with sequential classification.},
  langid = {english},
}

@misc{auerSciQABenchmarkDataset2023,
  title = {{{SciQA}} Benchmark: {{Dataset}} and {{RDF}} Dump},
  shorttitle = {{{SciQA}} Benchmark},
  author = {Auer, S{\"o}ren and Barone, Dante A. C. and Bartz, Cassiano and Cortes, Eduardo G. and Jaradeh, Mohamad Yaser and Karras, Oliver and Koubarakis, Manolis and Mouromtsev, Dmitry and Pliukhin, Dmitrii and Radyush, Daniil and Shilin, Ivan and Stocker, Markus and Tsalapati, Eleni},
  year = {2023},
  month = mar,
  publisher = {Zenodo},
  doi = {10.5281/ZENODO.7729047},
  urldate = {2024-07-10},
  abstract = {SciQA benchmark of questions and queries. The data dump is in NTriples format (RDF NT) taken from the ORKG system on 14.02.2023 at 02:04PM. The dump can be imported into a virtuoso endpoint or any RDF engine so it can be queried. The questions/queries are provided as spread sheets (Excel format \& CSV format), also train and test files are provided for each of the sets. Huggingface~datasets are also attached in the archive to make it easy to integrate with existing workflows and to enable the automated evaluation of SciQA within challenges. Types of questions and queries: 	 Handcrafted set of 100 questions 	 Auto-generated set of 2465 questions More details on certain columns: "Classification rationale" It may contain the following values: 	 Nested facts in the question 	 Sorting, sum, average, minimum, maximum or count calculation required 	 Filter used 	 Mappings of Asking Point in the question to the ORKG ontology Explanation of Rationale for Non-factoid: 	 Nested facts in the question. An entity (e.g., a system or a paper) or predicate is requested that is not explicitly stated in the question text and must be inferred while searching for an answer.~ 	 Sorting, sum, average, minimum, maximum or count calculation required. To get the answer to the question it is necessary to make an aggregation of the query results.~ 	 Filter used. To get the answer to the question it is necessary to use filtering of the query results by some conditions.},
  copyright = {Creative Commons Attribution 4.0 International, Open Access},
  langid = {english},
  keywords = {ORKG,QA dataset,Question answering,rdf dump,Scholarly knowledge graph,SciQA benchmark},
}

@article{auerSciQAScientificQuestion2023,
  title = {The {{SciQA Scientific Question Answering Benchmark}} for {{Scholarly Knowledge}}},
  author = {Auer, S{\"o}ren and Barone, Dante A. C. and Bartz, Cassiano and Cortes, Eduardo G. and Jaradeh, Mohamad Yaser and Karras, Oliver and Koubarakis, Manolis and Mouromtsev, Dmitry and Pliukhin, Dmitrii and Radyush, Daniil and Shilin, Ivan and Stocker, Markus and Tsalapati, Eleni},
  year = {2023},
  month = may,
  journal = {Scientific Reports},
  volume = {13},
  number = {1},
  pages = {7240},
  issn = {2045-2322},
  doi = {10.1038/s41598-023-33607-z},
  urldate = {2024-05-27},
  abstract = {Abstract             Knowledge graphs have gained increasing popularity in the last decade in science and technology. However, knowledge graphs are currently relatively simple to moderate semantic structures that are mainly a collection of factual statements. Question answering (QA) benchmarks and systems were so far mainly geared towards encyclopedic knowledge graphs such as DBpedia and Wikidata. We present SciQA a scientific QA benchmark for scholarly knowledge. The benchmark leverages the Open Research Knowledge Graph (ORKG) which includes almost 170,000 resources describing research contributions of almost 15,000 scholarly articles from 709 research fields. Following a bottom-up methodology, we first manually developed a set of 100 complex questions that can be answered using this knowledge graph. Furthermore, we devised eight question templates with which we automatically generated further 2465 questions, that can also be answered with the ORKG. The questions cover a range of research fields and question types and are translated into corresponding SPARQL queries over the ORKG. Based on two preliminary evaluations, we show that the resulting SciQA benchmark represents a challenging task for next-generation QA systems. This task is part of the open competitions at the 22nd International Semantic Web Conference 2023 as the Scholarly Question Answering over Linked Data (QALD) Challenge.},
  langid = {english},
  annotation = {Read\_Status: Read\\
Read\_Status\_Date: 2024-12-10T10:33:01.492Z},
}

@misc{ayoolaReFinEDEfficientZeroshotcapable2022,
  title = {{{ReFinED}}: {{An Efficient Zero-shot-capable Approach}} to {{End-to-End Entity Linking}}},
  shorttitle = {{{ReFinED}}},
  author = {Ayoola, Tom and Tyagi, Shubhi and Fisher, Joseph and Christodoulopoulos, Christos and Pierleoni, Andrea},
  year = {2022},
  month = jul,
  publisher = {arXiv},
  doi = {10.48550/arXiv.2207.04108},
  urldate = {2023-12-18},
  abstract = {We introduce ReFinED, an efficient end-toend entity linking model which uses finegrained entity types and entity descriptions to perform linking. The model performs mention detection, fine-grained entity typing, and entity disambiguation for all mentions within a document in a single forward pass, making it more than 60 times faster than competitive existing approaches. ReFinED also surpasses state-of-the-art performance on standard entity linking datasets by an average of 3.7 F1. The model is capable of generalising to large-scale knowledge bases such as Wikidata (which has 15 times more entities than Wikipedia) and of zero-shot entity linking. The combination of speed, accuracy and scale makes ReFinED an effective and cost-efficient system for extracting entities from web-scale datasets, for which the model has been successfully deployed. Our code and pre-trained models are available at https://github.com/alexa/ReFinED.},
  langid = {english},
  keywords = {Computer Science - Computation and Language,KBQA},
}

@article{badenes-olmedoMuHeQAZeroshotQuestion2023,
  title = {{{MuHeQA}}: {{Zero-shot}} Question Answering over Multiple and Heterogeneous Knowledge Bases},
  shorttitle = {{{MuHeQA}}},
  author = {{Badenes-Olmedo}, Carlos and Corcho, Oscar},
  editor = {Fu, Bo and Lambrix, Patrick and Pesquita, Catia},
  year = {2023},
  month = jun,
  journal = {Semantic Web},
  pages = {1--15},
  issn = {22104968, 15700844},
  doi = {10.3233/SW-233379},
  urldate = {2023-12-19},
  abstract = {Abstract. There are two main limitations in most of the existing Knowledge Graph Question Answering (KGQA) algorithms. First, the approaches depend heavily on the structure and cannot be easily adapted to other KGs. Second, the availability and amount of additional domain-specific data in structured or unstructured formats has also proven to be critical in many of these systems. Such dependencies limit the applicability of KGQA systems and make their adoption difficult. A novel algorithm is D proposed, MuHeQA, that alleviates both limitations by retrieving the answer from textual content automatically generated from KGs instead of queries over them. This new approach (1) works on one or several KGs simultaneously, (2) does not require E training data what makes it is domain-independent, (3) enables the combination of knowledge graphs with unstructured information sources to build the answer, and (4) reduces the dependency on the underlying schema since it does not navigate through T structured content but only reads property values. MuHeQA extracts answers from textual summaries created by combining information related to the question from multiple knowledge bases, be them structured or not. Experiments over Wikidata and C DBpedia show that our approach achieves comparable performance to other approaches in single-fact questions while being domain and KG independent. Results raise important questions for future work about how the textual content that can be created E from knowledge graphs enables answer extraction.},
  langid = {english},
  keywords = {KBQA},
}

@inproceedings{banerjeeModernBaselinesSPARQL2022,
  title = {Modern {{Baselines}} for {{SPARQL Semantic Parsing}}},
  booktitle = {Proceedings of the 45th {{International ACM SIGIR Conference}} on {{Research}} and {{Development}} in {{Information Retrieval}}},
  author = {Banerjee, Debayan and Nair, Pranav Ajit and Kaur, Jivat Neet and Usbeck, Ricardo and Biemann, Chris},
  year = {2022},
  month = jul,
  eprint = {2204.12793},
  primaryclass = {cs},
  pages = {2260--2265},
  doi = {10.1145/3477495.3531841},
  urldate = {2024-05-28},
  abstract = {In this work, we focus on the task of generating SPARQL queries from natural language questions, which can then be executed on Knowledge Graphs (KGs). We assume that gold entity and relations have been provided, and the remaining task is to arrange them in the right order along with SPARQL vocabulary, and input tokens to produce the correct SPARQL query. Pre-trained Language Models (PLMs) have not been explored in depth on this task so far, so we experiment with BART, T5 and PGNs (Pointer Generator Networks) with BERT embeddings, looking for new baselines in the PLM era for this task, on DBpedia and Wikidata KGs. We show that T5 requires special input tokenisation, but produces state of the art performance on LC-QuAD 1.0 and LC-QuAD 2.0 datasets, and outperforms task-specific models from previous works. Moreover, the methods enable semantic parsing for questions where a part of the input needs to be copied to the output query, thus enabling a new paradigm in KG semantic parsing. Code and data used for this work can be found at https://github.com/debayan/sigir2022sparqlbaselines.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computation and Language,Computer Science - Information Retrieval},
}

@inproceedings{bayerModelBasedSystems2012,
  title = {Model {{Based Systems Engineering}} on the {{Europa}} Mission Concept Study},
  booktitle = {2012 {{IEEE Aerospace Conference}}},
  author = {Bayer, T. J. and {Seung Chung} and Cole, B. and Cooke, B. and Dekens, F. and Delp, C. and Gontijo, I. and Lewis, K. and Moshir, M. and Rasmussen, R. and Wagner, D.},
  year = {2012},
  month = mar,
  pages = {1--18},
  publisher = {IEEE},
  address = {Big Sky, MT},
  doi = {10.1109/AERO.2012.6187337},
  urldate = {2024-03-05},
  abstract = {At the start of 2011, the proposed Jupiter Europa Orbiter (JEO) mission was staffing up in expectation of becoming an official project later in the year for a launch in 2020. A unique aspect of the pre-project work was a strong emphasis and investment on the foundations of Model-Based Systems Engineering (MBSE). As so often happens in this business, plans changed: NASA's budget and science priorities were released and together fundamentally changed the course of JEO. As a result, it returned to being a study task whose objective is to propose more affordable ways to accomplish the science. As part of this transition, the question arose as to whether it could continue to afford the investment in MBSE. In short, the MBSE infusion has survived and is providing clear value to the study effort. In the process, the need to remain relevant in the new environment has brought about a wave of innovation and progress. By leveraging the existing infrastructure and a modest additional investment, striking advances in the capture and analysis of designs using MBSE were achieved. The effort has reaffirmed the importance of architecting. It has successfully harnessed the synergistic relationship of architecting to system modeling. We have found that MBSE can provide greater agility than traditional methods. We have also found that a diverse `ecosystem' of modeling tools and languages (SysML, Mathematica, even Excel) is not only viable, but an important enabler of agility and adaptability. This paper will describe the successful application of MBSE in the dynamic environment of early mission formulation, the significant results produced and lessons learned in the process.},
  isbn = {978-1-4577-0557-1 978-1-4577-0556-4 978-1-4577-0555-7},
  langid = {english},
}

@inproceedings{beersSysMLProfileStandardized2024,
  title = {A {{SysML Profile}} for the {{Standardized Description}} of {{Processes}} during {{System Development}}},
  booktitle = {2024 {{IEEE International Systems Conference}} ({{SysCon}})},
  author = {Beers, Lasse and Nabizada, Hamied and Weigand, Maximilian and Gehlhoff, Felix and Fay, Alexander},
  year = {2024},
  month = apr,
  pages = {1--8},
  issn = {2472-9647},
  doi = {10.1109/SysCon61195.2024.10553402},
  urldate = {2024-12-09},
  abstract = {A key aspect in creating models of production systems with the use of model-based systems engineering (MBSE) lies in the description of system functions. These functions should be described in a clear and standardized manner.The VDI/VDE 3682 standard for Formalised Process Description (FPD) provides a simple and easily understandable representation of processes. These processes can be conceptualized as functions within the system model, making the FPD particularly well-suited for the standardized representation of the required functions. Hence, this contribution focuses on the development of a Domain-Specific Modeling Language (DSML) that facilitates the integration of VDI/VDE 3682 into the Systems Modeling Language (SysML). The presented approach not only extends classical SysML with domain-specific requirements but also facilitates model verification through constraints modeled in Object Constraint Language (OCL). Additionally, it enables automatic serialization of process descriptions into the Extensible Markup Language (XML) using the Velocity Template Language (VTL). This serialization enables the use of process modeling in applications outside of MBSE. The approach was validated using an collar screwing use case in the major component assembly in aircraft production.},
  keywords = {Aircraft propulsion,Atmospheric modeling,Domain-Specific Modeling Language,Formalised Process Description,Model-Based Systems Engineering,Modeling,Process modeling,Production systems,SysML Profile,Systems Modeling Language,VDI/VDE 3682,XML},
  annotation = {Read\_Status: Read\\
Read\_Status\_Date: 2024-12-09T17:44:27.820Z},
}

@inproceedings{benderDangersStochasticParrots2021,
  title = {On the {{Dangers}} of {{Stochastic Parrots}}: {{Can Language Models Be Too Big}}? ðŸ¦œ},
  shorttitle = {On the {{Dangers}} of {{Stochastic Parrots}}},
  booktitle = {Proceedings of the 2021 {{ACM Conference}} on {{Fairness}}, {{Accountability}}, and {{Transparency}}},
  author = {Bender, Emily M. and Gebru, Timnit and {McMillan-Major}, Angelina and Shmitchell, Shmargaret},
  year = {2021},
  month = mar,
  pages = {610--623},
  publisher = {ACM},
  address = {Virtual Event Canada},
  doi = {10.1145/3442188.3445922},
  urldate = {2023-12-05},
  abstract = {The past 3 years of work in NLP have been characterized by the development and deployment of ever larger language models, especially for English. BERT, its variants, GPT-2/3, and others, most recently Switch-C, have pushed the boundaries of the possible both through architectural innovations and through sheer size. Using these pretrained models and the methodology of fine-tuning them for specific tasks, researchers have extended the state of the art on a wide array of tasks as measured by leaderboards on specific benchmarks for English. In this paper, we take a step back and ask: How big is too big? What are the possible risks associated with this technology and what paths are available for mitigating those risks? We provide recommendations including weighing the environmental and financial costs first, investing resources into curating and carefully documenting datasets rather than ingesting everything on the web, carrying out pre-development exercises evaluating how the planned approach fits into research and development goals and supports stakeholder values, and encouraging research directions beyond ever larger language models.},
  isbn = {978-1-4503-8309-7},
  langid = {english},
  keywords = {Foundational},
}

@article{benderDataStatementsNatural2018,
  title = {Data {{Statements}} for {{Natural Language Processing}}: {{Toward Mitigating System Bias}} and {{Enabling Better Science}}},
  shorttitle = {Data {{Statements}} for {{Natural Language Processing}}},
  author = {Bender, Emily M. and Friedman, Batya},
  editor = {Lee, Lillian and Johnson, Mark and Toutanova, Kristina and Roark, Brian},
  year = {2018},
  journal = {Transactions of the Association for Computational Linguistics},
  volume = {6},
  pages = {587--604},
  publisher = {MIT Press},
  address = {Cambridge, MA},
  doi = {10.1162/tacl_a_00041},
  urldate = {2024-03-02},
  abstract = {In this paper, we propose data statements as a design solution and professional practice for natural language processing technologists, in both research and development. Through the adoption and widespread use of data statements, the field can begin to address critical scientific and ethical issues that result from the use of data from certain populations in the development of technology for other populations. We present a form that data statements can take and explore the implications of adopting them as part of regular practice. We argue that data statements will help alleviate issues related to exclusion and bias in language technology, lead to better precision in claims about how natural language processing research can generalize and thus better engineering results, protect companies from public embarrassment, and ultimately lead to language technology that meets its users in their own preferred linguistic style and furthermore does not misrepresent them to others.},
}

@inproceedings{berantSemanticParsingFreebase2013,
  title = {Semantic {{Parsing}} on {{Freebase}} from {{Question-Answer Pairs}}},
  booktitle = {Proceedings of the 2013 {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}}},
  author = {Berant, Jonathan and Chou, Andrew and Frostig, Roy and Liang, Percy},
  editor = {Yarowsky, David and Baldwin, Timothy and Korhonen, Anna and Livescu, Karen and Bethard, Steven},
  year = {2013},
  month = oct,
  pages = {1533--1544},
  publisher = {Association for Computational Linguistics},
  address = {Seattle, Washington, USA},
  url = {https://aclanthology.org/D13-1160},
  urldate = {2024-08-04},
}

@article{bestaGraphThoughtsSolving2024,
  title = {Graph of {{Thoughts}}: {{Solving Elaborate Problems}} with {{Large Language Models}}},
  shorttitle = {Graph of {{Thoughts}}},
  author = {Besta, Maciej and Blach, Nils and Kubicek, Ales and Gerstenberger, Robert and Podstawski, Michal and Gianinazzi, Lukas and Gajda, Joanna and Lehmann, Tomasz and Niewiadomski, Hubert and Nyczyk, Piotr and Hoefler, Torsten},
  year = {2024},
  month = mar,
  journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
  volume = {38},
  number = {16},
  pages = {17682--17690},
  issn = {2374-3468, 2159-5399},
  doi = {10.1609/aaai.v38i16.29720},
  urldate = {2024-08-17},
  abstract = {We introduce Graph of Thoughts (GoT): a framework that advances prompting capabilities in large language models (LLMs) beyond those offered by paradigms such as Chain-ofThought or Tree of Thoughts (ToT). The key idea and primary advantage of GoT is the ability to model the information generated by an LLM as an arbitrary graph, where units of information (``LLM thoughts'') are vertices, and edges correspond to dependencies between these vertices. This approach enables combining arbitrary LLM thoughts into synergistic outcomes, distilling the essence of whole networks of thoughts, or enhancing thoughts using feedback loops. We illustrate that GoT offers advantages over state of the art on different tasks, for example increasing the quality of sorting by 62\% over ToT, while simultaneously reducing costs by {$>$}31\%. We ensure that GoT is extensible with new thought transformations and thus can be used to spearhead new prompting schemes. This work brings the LLM reasoning closer to human thinking or brain mechanisms such as recurrence, both of which form complex networks.},
  langid = {english},
}

@incollection{bialySoftwareEngineeringModelBased2017,
  title = {Software {{Engineering}} for {{Model-Based Development}} by {{Domain Experts}}},
  booktitle = {Handbook of {{System Safety}} and {{Security}}},
  author = {Bialy, M. and Pantelic, V. and Jaskolka, J. and Schaap, A. and Patcas, L. and Lawford, M. and Wassyng, A.},
  year = {2017},
  pages = {39--64},
  publisher = {Elsevier},
  doi = {10.1016/B978-0-12-803773-7.00003-6},
  urldate = {2024-12-09},
  copyright = {https://www.elsevier.com/tdm/userlicense/1.0/},
  isbn = {978-0-12-803773-7},
  langid = {english},
  annotation = {Read\_Status: Read\\
Read\_Status\_Date: 2024-12-10T10:14:38.964Z},
}

@article{bienstockNotePrizeCollecting1993,
  title = {A Note on the Prize Collecting Traveling Salesman Problem},
  author = {Bienstock, Daniel and Goemans, Michel X. and {Simchi-Levi}, David and Williamson, David},
  year = {1993},
  month = mar,
  journal = {Mathematical Programming},
  volume = {59},
  number = {1-3},
  pages = {413--420},
  issn = {0025-5610, 1436-4646},
  doi = {10.1007/BF01581256},
  urldate = {2024-08-17},
  abstract = {We study the version of the prize collecting traveling salesman problem, where the objective is to find a tour that visits a subset of vertices such that the length of the tour plus the sum of penalties associated with vertices not in the tour is as small as possible. We present an approximation algorithm with constant bound. The algorithm is based on Christofides' algorithm for the traveling salesman problem as well as a method to round fractional solutions of a linear programming relaxation to integers, feasible for the original problem.},
  copyright = {http://www.springer.com/tdm},
  langid = {english},
}

@misc{biswalCLARAClinicalReport2020,
  title = {{{CLARA}}: {{Clinical Report Auto-completion}}},
  shorttitle = {{{CLARA}}},
  author = {Biswal, Siddharth and Xiao, Cao and Glass, Lucas M. and Westover, M. Brandon and Sun, Jimeng},
  year = {2020},
  month = mar,
  number = {arXiv:2002.11701},
  eprint = {2002.11701},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2002.11701},
  urldate = {2024-01-27},
  abstract = {Generating clinical reports from raw recordings such as Xrays and electroencephalogram (EEG) is an essential and routine task for doctors. However, it is often time-consuming to write accurate and detailed reports. Most existing methods try to generate the whole reports from the raw input with limited success because 1) generated reports often contain errors that need manual review and correction, 2) it does not save time when doctors want to write additional information into the report, and 3) the generated reports are not customized based on individual doctors' preference. We propose CLinicAl Report Auto-completion (CLARA), an interactive method that generates reports in a sentence by sentence fashion based on doctors' anchor words and partially completed sentences. CLARA searches for most relevant sentences from existing reports as the template for the current report. The retrieved sentences are sequentially modified by combining with the input feature representations to create the final report. In our experimental evaluation CLARA achieved 0.393 CIDEr and 0.248 BLEU4 on X-ray reports and 0.482 CIDEr and 0.491 BLEU-4 for EEG reports for sentence-level generation, which is up to 35\% improvement over the best baseline. Also via our qualitative evaluation, CLARA is shown to produce reports which have a significantly higher level of approval by doctors in a user study (3.74 out of 5 for CLARA vs 2.52 out of 5 for the baseline).},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Human-Computer Interaction,Computer Science - Machine Learning,Statistics - Machine Learning},
}

@article{bojanowskiEnrichingWordVectors2017,
  title = {Enriching {{Word Vectors}} with {{Subword Information}}},
  author = {Bojanowski, Piotr and Grave, Edouard and Joulin, Armand and Mikolov, Tomas},
  year = {2017},
  month = dec,
  journal = {Transactions of the Association for Computational Linguistics},
  volume = {5},
  pages = {135--146},
  issn = {2307-387X},
  doi = {10.1162/tacl_a_00051},
  urldate = {2024-05-30},
  abstract = {Continuous word representations, trained on large unlabeled corpora are useful for many natural language processing tasks. Popular models that learn such representations ignore the morphology of words, by assigning a distinct vector to each word. This is a limitation, especially for languages with large vocabularies and many rare words. In this paper, we propose a new approach based on the skipgram model, where each word is represented as a bag of character n-grams. A vector representation is associated to each character n-gram; words being represented as the sum of these representations. Our method is fast, allowing to train models on large corpora quickly and allows us to compute word representations for words that did not appear in the training data. We evaluate our word representations on nine different languages, both on word similarity and analogy tasks. By comparing to recently proposed morphological word representations, we show that our vectors achieve state-of-the-art performance on these tasks.},
  langid = {english},
}

@inproceedings{bontchevaAutomaticReportGeneration2004,
  title = {Automatic {{Report Generation}} from {{Ontologies}}: {{The MIAKT Approach}}},
  shorttitle = {Automatic {{Report Generation}} from {{Ontologies}}},
  booktitle = {Natural {{Language Processing}} and {{Information Systems}}},
  author = {Bontcheva, Kalina and Wilks, Yorick},
  editor = {Meziane, Farid and M{\'e}tais, Elisabeth},
  year = {2004},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  pages = {324--335},
  publisher = {Springer},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-540-27779-8_28},
  abstract = {This paper presented an approach for automatic generation of reports from domain ontologies encoded in Semantic Web standards like OWL. The paper identifies the challenges that need to be addressed when generating text from RDF and OWL and demonstrates how the ontology is used during the different stages of the generation process. The main contribution is in showing how NLG tools that take Semantic Web ontologies as their input can be designed to minimises the portability effort, while offering better output than template-based ontology verbalisers.},
  isbn = {978-3-540-27779-8},
  langid = {english},
  keywords = {Domain Ontology,Natural Language Generation,Property Hierarchy,Resource Description Framework,Resource Description Framework Triple},
}

@article{borrotoSPARQLQAv2SystemKnowledge2023,
  title = {{{SPARQL-QA-v2}} System for {{Knowledge Base Question Answering}}},
  author = {Borroto, Manuel A. and Ricca, Francesco},
  year = {2023},
  month = nov,
  journal = {Expert Systems with Applications},
  volume = {229},
  pages = {120383},
  issn = {09574174},
  doi = {10.1016/j.eswa.2023.120383},
  urldate = {2023-12-01},
  abstract = {Accessing the large volumes of information available in public knowledge bases might be complicated for those users unfamiliar with formal languages, such as the SPARQL query language and the ontology definition languages. This issue can be overcome by providing systems able to answer questions posed in natural language on a knowledge base, a task that is called Knowledge Base Question Answering (KBQA) in the literature. More in detail, many KBQA systems aim at translating automatically questions into the corresponding SPARQL queries to be executed over the knowledge base to get the answers. Effective state-of-the-art KBQA systems are based on neural-machine translation but easily fail to recognize words that are Out Of the Vocabulary (OOV) of the training set. This is a serious issue while querying large ontologies where the list of entities is huge and easily evolves over time. In this paper, we present the SPARQL-QA-v2 system that combines in an innovative way Named Entity Linking, Named Entity Recognition, and Neural Machine Translation for addressing the problem of generating SPARQL queries from questions posed in natural language. We demonstrate empirically that SPARQL-QA-v2 is effective and resilient to OOV words and delivers state-of-the-art performance in well-known datasets for question answering over DBpedia and Wikidata knowledge bases.},
  langid = {english},
  keywords = {KBQA},
}

@article{burgerViewbasedModeldrivenSoftware2016,
  title = {View-Based Model-Driven Software Development with {{ModelJoin}}},
  author = {Burger, Erik and Henss, J{\"o}rg and K{\"u}ster, Martin and Kruse, Steffen and Happe, Lucia},
  year = {2016},
  month = may,
  journal = {Software \& Systems Modeling},
  volume = {15},
  number = {2},
  pages = {473--496},
  issn = {1619-1366, 1619-1374},
  doi = {10.1007/s10270-014-0413-5},
  urldate = {2024-04-15},
  abstract = {Fragmentation of information across instances of different metamodels poses a significant problem for software developers and leads to a major increase in effort of transformation development. Moreover, compositions of metamodels tend to be incomplete, imprecise, and erroneous, making it impossible to present it to users or use it directly as input for applications. Customized views satisfy information needs by focusing on a particular concern, and filtering out information that is not relevant to this concern. For a broad establishment of view-based approaches, an automated solution to deal with separate metamodels and the high complexity of model transformations is necessary. In this paper, we present the ModelJoin approach for the rapid creation of views. Using a human-readable textual DSL, developers can define custom views declaratively without having to write model transformations or define a bridging metamodel.},
  langid = {english},
}

@inproceedings{castrofernandezSeepingSemanticsLinking2018,
  title = {Seeping {{Semantics}}: {{Linking Datasets Using Word Embeddings}} for {{Data Discovery}}},
  shorttitle = {Seeping {{Semantics}}},
  booktitle = {2018 {{IEEE}} 34th {{International Conference}} on {{Data Engineering}} ({{ICDE}})},
  author = {Castro Fernandez, Raul and Mansour, Essam and Qahtan, Abdulhakim A. and Elmagarmid, Ahmed and Ilyas, Ihab and Madden, Samuel and Ouzzani, Mourad and Stonebraker, Michael and Tang, Nan},
  year = {2018},
  month = apr,
  pages = {989--1000},
  publisher = {IEEE},
  address = {Paris},
  doi = {10.1109/ICDE.2018.00093},
  urldate = {2024-08-09},
  abstract = {Employees that spend more time finding relevant data than analyzing it suffer from a data discovery problem. The large volume of data in enterprises, and sometimes the lack of knowledge of the schemas aggravates this problem. Similar to how we navigate the Web, we propose to identify semantic links that assist analysts in their discovery tasks. These links relate tables to each other, to facilitate navigating the schemas. They also relate data to external data sources, such as ontologies and dictionaries, to help explain the schema meaning. We materialize the links in an enterprise knowledge graph, where they become available to analysts. The main challenge is how to find pairs of objects that are semantically related. We propose SEMPROP, a DAG of different components that find links based on syntactic and semantic similarities. SEMPROP is commanded by a semantic matcher which leverages word embeddings to find objects that are semantically related. We introduce coherent group, a technique to combine word embeddings that works better than other state of the art combination alternatives. We implement SEMPROP as part of Aurum, a data discovery system we are building, and conduct user studies, real deployments and a quantitative evaluation to understand the benefits of links for data discovery tasks, as well as the benefits of SEMPROP and coherent groups to find those links.},
  isbn = {978-1-5386-5520-7},
  langid = {english},
}

@misc{ChatGPT2024,
  title = {{{ChatGPT}}},
  year = {2024},
  url = {https://chat.openai.com},
  urldate = {2024-04-06},
  abstract = {A conversational AI system that listens, learns, and challenges},
  langid = {american},
}

@misc{chenBidirectionalAttentiveMemory2019,
  title = {Bidirectional {{Attentive Memory Networks}} for {{Question Answering}} over {{Knowledge Bases}}},
  author = {Chen, Yu and Wu, Lingfei and Zaki, Mohammed J.},
  year = {2019},
  month = may,
  number = {arXiv:1903.02188},
  eprint = {1903.02188},
  primaryclass = {cs},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/1903.02188},
  urldate = {2024-03-05},
  abstract = {When answering natural language questions over knowledge bases (KBs), different question components and KB aspects play different roles. However, most existing embedding-based methods for knowledge base question answering (KBQA) ignore the subtle inter-relationships between the question and the KB (e.g., entity types, relation paths and context). In this work, we propose to directly model the two-way flow of interactions between the questions and the KB via a novel Bidirectional Attentive Memory Network, called BAMnet. Requiring no external resources and only very few hand-crafted features, on the WebQuestions benchmark, our method significantly outperforms existing information-retrieval based methods, and remains competitive with (hand-crafted) semantic parsing based methods. Also, since we use attention mechanisms, our method offers better interpretability compared to other baselines.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language},
}

@inproceedings{chenFastAccurateDependency2014,
  title = {A {{Fast}} and {{Accurate Dependency Parser}} Using {{Neural Networks}}},
  booktitle = {Proceedings of the 2014 {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}} ({{EMNLP}})},
  author = {Chen, Danqi and Manning, Christopher},
  year = {2014},
  pages = {740--750},
  publisher = {Association for Computational Linguistics},
  address = {Doha, Qatar},
  doi = {10.3115/v1/D14-1082},
  urldate = {2024-08-29},
  abstract = {Almost all current dependency parsers classify based on millions of sparse indicator features. Not only do these features generalize poorly, but the cost of feature computation restricts parsing speed significantly. In this work, we propose a novel way of learning a neural network classifier for use in a greedy, transition-based dependency parser. Because this classifier learns and uses just a small number of dense features, it can work very fast, while achieving an about 2\% improvement in unlabeled and labeled attachment scores on both English and Chinese datasets. Concretely, our parser is able to parse more than 1000 sentences per second at 92.2\% unlabeled attachment score on the English Penn Treebank.},
  langid = {english},
}

@misc{chengBuildingNeuralSemantic2018,
  title = {Building a {{Neural Semantic Parser}} from a {{Domain Ontology}}},
  author = {Cheng, Jianpeng and Reddy, Siva and Lapata, Mirella},
  year = {2018},
  month = dec,
  number = {arXiv:1812.10037},
  eprint = {1812.10037},
  primaryclass = {cs},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/1812.10037},
  urldate = {2024-08-19},
  abstract = {Semantic parsing is the task of converting natural language utterances into machine interpretable meaning representations which can be executed against a real-world environment such as a database. Scaling semantic parsing to arbitrary domains faces two interrelated challenges: obtaining broad coverage training data effectively and cheaply; and developing a model that generalizes to compositional utterances and complex intentions. We address these challenges with a framework which allows to elicit training data from a domain ontology and bootstrap a neural parser which recursively builds derivations of logical forms. In our framework meaning representations are described by sequences of natural language templates, where each template corresponds to a decomposed fragment of the underlying meaning representation. Although artificial, templates can be understood and paraphrased by humans to create natural utterances, resulting in parallel triples of utterances, meaning representations, and their decompositions. These allow us to train a neural semantic parser which learns to compose rules in deriving meaning representations. We crowdsource training data on six domains, covering both single-turn utterances which exhibit rich compositionality, and sequential utterances where a complex task is procedurally performed in steps. We then develop neural semantic parsers which perform such compositional tasks. In general, our approach allows to deploy neural semantic parsers quickly and cheaply from a given domain ontology.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computation and Language,Question generation,SQUALL generation,Synthetic data},
  annotation = {Read\_Status: To Read\\
Read\_Status\_Date: 2024-11-22T18:16:40.840Z},
}

@misc{chenHiQAHierarchicalContextual2024,
  title = {{{HiQA}}: {{A Hierarchical Contextual Augmentation RAG}} for {{Multi-Documents QA}}},
  shorttitle = {{{HiQA}}},
  author = {Chen, Xinyue and Gao, Pengyu and Song, Jiangjiang and Tan, Xiaoyang},
  year = {2024},
  month = sep,
  number = {arXiv:2402.01767},
  eprint = {2402.01767},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2402.01767},
  urldate = {2024-12-05},
  abstract = {Retrieval-augmented generation (RAG) has rapidly advanced the language model field, particularly in question-answering (QA) systems. By integrating external documents during the response generation phase, RAG significantly enhances the accuracy and reliability of language models. This method elevates the quality of responses and reduces the frequency of hallucinations, where the model generates incorrect or misleading information. However, these methods exhibit limited retrieval accuracy when faced with numerous indistinguishable documents, presenting notable challenges in their practical application. In response to these emerging challenges, we present HiQA, an advanced multi-document question-answering (MDQA) framework that integrates cascading metadata into content and a multi-route retrieval mechanism. We also release a benchmark called MasQA to evaluate and research in MDQA. Finally, HiQA demonstrates the state-of-the-art performance in multi-document environments.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},
}

@article{chenSubgraphGuidedKnowledgeGraph2024,
  title = {Toward {{Subgraph-Guided Knowledge Graph Question Generation With Graph Neural Networks}}},
  author = {Chen, Yu and Wu, Lingfei and Zaki, Mohammed J.},
  year = {2024},
  journal = {IEEE Transactions on Neural Networks and Learning Systems},
  pages = {1--12},
  issn = {2162-237X, 2162-2388},
  doi = {10.1109/TNNLS.2023.3264519},
  urldate = {2024-03-05},
  abstract = {Knowledge graph (KG) question generation (QG) aims to generate natural language questions from KGs and target answers. Previous works mostly focus on a simple setting that is to generate questions from a single KG triple. In this work, we focus on a more realistic setting where we aim to generate questions from a KG subgraph and target answers. In addition, most previous works built on either RNN- or Transformer-based models to encode a linearized KG subgraph, which totally discards the explicit structure information of a KG subgraph. To address this issue, we propose to apply a bidirectional Graph2Seq model to encode the KG subgraph. Furthermore, we enhance our RNN decoder with a node-level copying mechanism to allow direct copying of node attributes from the KG subgraph to the output question. Both automatic and human evaluation results demonstrate that our model achieves new state-of-the-art scores, outperforming existing methods by a significant margin on two QG benchmarks. Experimental results also show that our QG model can consistently benefit the question-answering (QA) task as a means of data augmentation.},
  langid = {english},
  keywords = {Computer Science - Computation and Language},
}

@misc{chikinChars2vecCharacterbasedWord2023,
  title = {Chars2vec: {{Character-based}} Word Embeddings Model Based on {{RNN}} for Handling Real World Texts},
  shorttitle = {Chars2vec},
  author = {Chikin, Vladimir and Milo, Fabrizio and Solodskih, Kirill},
  year = {2023},
  month = feb,
  url = {https://github.com/IntuitionEngineeringTeam/chars2vec},
  urldate = {2024-05-30},
  abstract = {Character-based word embeddings model based on RNN for handling real world~texts - IntuitionEngineeringTeam/chars2vec},
  copyright = {Apache-2.0},
  howpublished = {Intuition.Engineering},
}

@inproceedings{cohenEvaluationSPARQLQuery2013,
  title = {Evaluation of {{SPARQL}} Query Generation from Natural Language Questions},
  booktitle = {Proceedings of the {{Joint Workshop}} on {{NLP}}\&{{LOD}} and {{SWAIE}}: {{Semantic Web}}, {{Linked Open Data}} and {{Information Extraction}}},
  author = {Cohen, K. Bretonnel and Kim, Jin-Dong},
  editor = {Maynard, Diana and {van Erp}, Marieke and Davis, Brian and Osenova, Petya and Simov, Kiril and Georgiev, Georgi and Nakov, Preslav},
  year = {2013},
  month = sep,
  pages = {3--7},
  publisher = {INCOMA Ltd. Shoumen, BULGARIA},
  address = {Hissar, Bulgaria},
  url = {https://aclanthology.org/W13-5202},
  urldate = {2024-05-23},
}

@inproceedings{cohenPresentingModelBasedSystems2021,
  title = {Presenting {{Model-Based Systems Engineering Information}} to {{Non-Modelers}}},
  booktitle = {2021 {{IEEE Aerospace Conference}} (50100)},
  author = {Cohen, Jeffrey R. and Arai, Sarah and Rakalina, Tatyana and Griffin, Emily and Heiser, Jared and Urbina, Michelle and McGuire, Kerry M. and Rubin, David and Seigel, Alex J. and Shah, Alay and Ramachandran, Sandhya and Dixit, Anusha and Legaspi, Jennifer and Mindock, Jennifer A. and Bardina, Jorge and Hailey, Melinda J.},
  year = {2021},
  month = mar,
  pages = {1--18},
  publisher = {IEEE},
  address = {Big Sky, MT, USA},
  doi = {10.1109/AERO50100.2021.9438292},
  urldate = {2024-11-20},
  abstract = {NASA's Human Research Program's (HRP) Exploration Medical Capability (ExMC) Element adopted Systems Engineering (SE) principles and Model Based Systems Engineering (MBSE) tools to capture the system functions, system architecture, requirements, interfaces, and clinical capabilities for a future exploration medical system. There are many different stakeholders who may use the information in the model: systems engineers, clinicians (physicians, nurses, and pharmacists), scientists, and program managers. Many of these individuals do not have access to MBSE modeling tools or have never used these tools. Many of these individuals (clinicians, scientists, even program managers) may have no experience with SE in general let alone interpreting a systems model. The challenge faced by ExMC was how to present the content in the model to non-modelers in a way they could understand with limited to no training in MBSE or the Systems Modeling Language (SysML) without using the modeling tool. Therefore, from the model, ExMC created an HTML report that is accessible to anyone with a browser. When creating the HTML report, the ExMC SE team talked to stakeholders and received their feedback on what content they wanted and how to display this content. Factoring in feedback, the report arranges the content in a way that not only directs readers through the SE process taken to derive the requirements, but also helps them to understand the fundamental steps in an SE approach. The report includes links to source information (i.e., NASA documentation that describes levels of care) and other SE deliverables (e.g., Concept of Operations). These links were provided to aid in the understanding of how the team created this content through a methodical SE approach. This paper outlines the process used to develop the model, the data chosen to share with stakeholders, many of the model elements used in the report, the review process stakeholders followed, the comments received from the stakeholders, and the lessons ExMC learned through producing this HTML report.},
  copyright = {https://doi.org/10.15223/policy-029},
  isbn = {978-1-72817-436-5},
  langid = {english},
}

@misc{cortesQuestionAnsweringLinked2022,
  title = {Question {{Answering}} over Linked Data Benchmark Comparison},
  author = {Cortes, Eduardo and Karras, Oliver},
  year = {2022},
  publisher = {Open Research Knowledge Graph},
  doi = {10.48366/R161787},
  urldate = {2024-12-17},
  abstract = {A Question Answering over linked data benchmark comparison.},
  copyright = {Creative Commons Attribution Share Alike 4.0 International},
  langid = {english},
  keywords = {Natural Language Processing}
}

@article{cuiLifelongEmbeddingLearning2023,
  title = {Lifelong {{Embedding Learning}} and {{Transfer}} for {{Growing Knowledge Graphs}}},
  author = {Cui, Yuanning and Wang, Yuxin and Sun, Zequn and Liu, Wenqiang and Jiang, Yiqiao and Han, Kexin and Hu, Wei},
  year = {2023},
  month = jun,
  journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
  volume = {37},
  number = {4},
  pages = {4217--4224},
  issn = {2374-3468, 2159-5399},
  doi = {10.1609/aaai.v37i4.25539},
  urldate = {2024-07-10},
  abstract = {Existing knowledge graph (KG) embedding models have primarily focused on static KGs. However, real-world KGs do not remain static, but rather evolve and grow in tandem with the development of KG applications. Consequently, new facts and previously unseen entities and relations continually emerge, necessitating an embedding model that can quickly learn and transfer new knowledge through growth. Motivated by this, we delve into an expanding field of KG embedding in this paper, i.e., lifelong KG embedding. We consider knowledge transfer and retention of the learning on growing snapshots of a KG without having to learn embeddings from scratch. The proposed model includes a masked KG autoencoder for embedding learning and update, with an embedding transfer strategy to inject the learned knowledge into the new entity and relation embeddings, and an embedding regularization method to avoid catastrophic forgetting. To investigate the impacts of different aspects of KG growth, we construct four datasets to evaluate the performance of lifelong KG embedding. Experimental results show that the proposed model outperforms the state-of-the-art inductive and lifelong embedding baselines.},
  langid = {english},
}

@misc{dahlMBSEModelsGenerated2021,
  title = {From {{MBSE}} Models to Generated Documents},
  author = {Dahl, Ida},
  year = {2021},
  month = feb,
  journal = {Samares Engineering},
  url = {https://www.samares-engineering.com/en/2021/02/19/from-mbse-models-to-generated-documents},
  urldate = {2024-11-19},
  abstract = {undefined},
  langid = {british},
}

@techreport{darmSystemEngineeringModels2022,
  type = {Executive {{Report Summary}}},
  title = {System {{Engineering Models Meet Knowledge Graphs Executive Report Summary}}},
  author = {Darm, Paul and Berquand, Audrey and Riccardi, Annalisa and Minisci, Edmondo},
  year = {2022},
  month = jun,
  institution = {European Space Agency},
  langid = {english},
}

@misc{DeepLearningGenerating,
  title = {Deep Learning in Generating Radiology Reports: {{A}} Survey - {{ScienceDirect}}},
  url = {https://www.sciencedirect.com/science/article/pii/S0933365719302635#sec0085},
  urldate = {2024-08-05},
  keywords = {Evaluation}
}

@inproceedings{delpModelBasedDocument2013,
  title = {Model Based Document and Report Generation for Systems Engineering},
  booktitle = {2013 {{IEEE Aerospace Conference}}},
  author = {Delp, C. and Lam, D. and Fosse, E. and {Cin-Young Lee}},
  year = {2013},
  month = mar,
  pages = {1--11},
  publisher = {IEEE},
  address = {Big Sky, MT},
  doi = {10.1109/AERO.2013.6496926},
  urldate = {2023-12-01},
  abstract = {As Model Based Systems Engineering (MBSE) practices gain adoption, various approaches have been developed in order to simplify and automate the process of generating documents from models. Essentially, all of these techniques can be unified around the concept of producing different views of the model according to the needs of the intended audience. In this paper, we will describe a technique developed at JPL of applying SysML Viewpoints and Views to generate documents and reports. An architecture of model-based view and document generation will be presented, and the necessary extensions to SysML with associated rationale will be explained. A survey of examples will highlight a variety of views that can be generated, and will provide some insight into how collaboration and integration is enabled. We will also describe the basic architecture for the enterprise applications that support this approach.},
  isbn = {978-1-4673-1813-6},
  langid = {english},
}

@misc{delpViewpointModelingModel2013,
  title = {Viewpoint {{Modeling}} and {{Model Based Media Generation}} for {{Systems Engineers}} -- {{Document Generation}} and {{Scalable Model Based Engineering}}},
  author = {Delp, Christopher},
  year = {2013},
  copyright = {NASA/Caltech Jet Propulsion Laboratory},
}

@article{DescriptionLogic2024,
  title = {Description Logic},
  year = {2024},
  month = nov,
  journal = {Wikipedia},
  url = {https://en.wikipedia.org/w/index.php?title=Description_logic&oldid=1256136767},
  urldate = {2024-11-27},
  abstract = {Description logics (DL) are a family of formal knowledge representation languages. Many DLs are more expressive than propositional logic but less expressive than first-order logic. In contrast to the latter, the core reasoning problems for DLs are (usually) decidable, and efficient decision procedures have been designed and implemented for these problems. There are general, spatial, temporal, spatiotemporal, and fuzzy description logics, and each description logic features a different balance between expressive power and reasoning complexity by supporting different sets of mathematical constructors. DLs are used in artificial intelligence to describe and reason about the relevant concepts of an application domain (known as terminological knowledge). It is of particular importance in providing a logical formalism for ontologies and the Semantic Web: the Web Ontology Language (OWL) and its profiles are based on DLs. The most notable application of DLs and OWL is in biomedical informatics where DL assists in the codification of biomedical knowledge.},
  copyright = {Creative Commons Attribution-ShareAlike License},
  langid = {english},
  annotation = {Page Version ID: 1256136767},
}

@misc{dettmersQLoRAEfficientFinetuning2023,
  title = {{{QLoRA}}: {{Efficient Finetuning}} of {{Quantized LLMs}}},
  shorttitle = {{{QLoRA}}},
  author = {Dettmers, Tim and Pagnoni, Artidoro and Holtzman, Ari and Zettlemoyer, Luke},
  year = {2023},
  month = may,
  number = {arXiv:2305.14314},
  eprint = {2305.14314},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2305.14314},
  urldate = {2024-06-01},
  abstract = {We present QLoRA, an efficient finetuning approach that reduces memory usage enough to finetune a 65B parameter model on a single 48GB GPU while preserving full 16-bit finetuning task performance. QLoRA backpropagates gradients through a frozen, 4-bit quantized pretrained language model into Low Rank Adapters{\textasciitilde}(LoRA). Our best model family, which we name Guanaco, outperforms all previous openly released models on the Vicuna benchmark, reaching 99.3\% of the performance level of ChatGPT while only requiring 24 hours of finetuning on a single GPU. QLoRA introduces a number of innovations to save memory without sacrificing performance: (a) 4-bit NormalFloat (NF4), a new data type that is information theoretically optimal for normally distributed weights (b) double quantization to reduce the average memory footprint by quantizing the quantization constants, and (c) paged optimziers to manage memory spikes. We use QLoRA to finetune more than 1,000 models, providing a detailed analysis of instruction following and chatbot performance across 8 instruction datasets, multiple model types (LLaMA, T5), and model scales that would be infeasible to run with regular finetuning (e.g. 33B and 65B parameter models). Our results show that QLoRA finetuning on a small high-quality dataset leads to state-of-the-art results, even when using smaller models than the previous SoTA. We provide a detailed analysis of chatbot performance based on both human and GPT-4 evaluations showing that GPT-4 evaluations are a cheap and reasonable alternative to human evaluation. Furthermore, we find that current chatbot benchmarks are not trustworthy to accurately evaluate the performance levels of chatbots. A lemon-picked analysis demonstrates where Guanaco fails compared to ChatGPT. We release all of our models and code, including CUDA kernels for 4-bit training.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Machine Learning},
}

@article{dialloComprehensiveEvaluationNeural2024,
  title = {A {{Comprehensive Evaluation}} of {{Neural SPARQL Query Generation From Natural Language Questions}}},
  author = {Diallo, Papa Abdou Karim Karou and Reyd, Samuel and Zouaq, Amal},
  year = {2024},
  month = sep,
  journal = {IEEE Access},
  volume = {12},
  eprint = {2304.07772},
  primaryclass = {cs},
  pages = {125057--125078},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2024.3453215},
  urldate = {2024-05-23},
  abstract = {In recent years, the field of neural machine translation (NMT) for SPARQL query generation has witnessed significant growth. Incorporating the copy mechanism with traditional encoder-decoder architectures and using pre-trained encoderdecoders and large language models have set new performance benchmarks. This paper presents various experiments that replicate and expand upon recent NMT-based SPARQL generation studies, comparing pre-trained language models (PLMs), non-pretrained language models (NPLMs), and large language models (LLMs), highlighting the impact of question annotation and the copy mechanism and testing various fine-tuning methods using LLMs. In particular, we provide a systematic error analysis of the models and test their generalization ability. Our study demonstrates that the copy mechanism yields significant performance enhancements for most PLMs and NPLMs. Annotating the data is pivotal to generating correct URIs, with the "tag-within" strategy emerging as the most effective approach. Additionally, our findings reveal that the primary source of errors stems from incorrect URIs in SPARQL queries that are sometimes replaced with hallucinated URIs when using base models. This does not happen using the copy mechanism, but it sometimes leads to selecting wrong URIs among candidates. Finally, the performance of the tested LLMs fell short of achieving the desired outcomes.},
  archiveprefix = {arXiv},
  copyright = {https://creativecommons.org/licenses/by/4.0/legalcode},
  langid = {english},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning},
}

@article{DomainModel2024,
  title = {Domain Model},
  year = {2024},
  month = may,
  journal = {Wikipedia},
  url = {https://en.wikipedia.org/w/index.php?title=Domain_model&oldid=1223669885},
  urldate = {2024-11-20},
  abstract = {In software engineering, a domain model is a conceptual model of the domain that incorporates both behavior and data. In ontology engineering, a domain model is a formal representation of a knowledge domain with concepts, roles, datatypes, individuals, and rules, typically grounded in a description logic.},
  copyright = {Creative Commons Attribution-ShareAlike License},
  langid = {english},
  annotation = {Page Version ID: 1223669885},
}

@misc{dubeyEARLJointEntity2018,
  title = {{{EARL}}: {{Joint Entity}} and {{Relation Linking}} for {{Question Answering}} over {{Knowledge Graphs}}},
  shorttitle = {{{EARL}}},
  author = {Dubey, Mohnish and Banerjee, Debayan and Chaudhuri, Debanjan and Lehmann, Jens},
  year = {2018},
  month = jun,
  number = {arXiv:1801.03825},
  eprint = {1801.03825},
  primaryclass = {cs},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/1801.03825},
  urldate = {2024-03-07},
  abstract = {Many question answering systems over knowledge graphs rely on entity and relation linking components in order to connect the natural language input to the underlying knowledge graph. Traditionally, entity linking and relation linking have been performed either as dependent sequential tasks or as independent parallel tasks. In this paper, we propose a framework called EARL, which performs entity linking and relation linking as a joint task. EARL implements two different solution strategies for which we provide a comparative analysis in this paper: The first strategy is a formalisation of the joint entity and relation linking tasks as an instance of the Generalised Travelling Salesman Problem (GTSP). In order to be computationally feasible, we employ approximate GTSP solvers. The second strategy uses machine learning in order to exploit the connection density between nodes in the knowledge graph. It relies on three base features and re-ranking steps in order to predict entities and relations. We compare the strategies and evaluate them on a dataset with 5000 questions. Both strategies significantly outperform the current state-of-the-art approaches for entity and relation linking.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
}

@incollection{dubeyLCQuAD20Large2019,
  title = {{{LC-QuAD}} 2.0: {{A Large Dataset}} for {{Complex Question Answering}} over {{Wikidata}} and {{DBpedia}}},
  shorttitle = {{{LC-QuAD}} 2.0},
  booktitle = {The {{Semantic Web}} -- {{ISWC}} 2019},
  author = {Dubey, Mohnish and Banerjee, Debayan and Abdelkawi, Abdelrahman and Lehmann, Jens},
  editor = {Ghidini, Chiara and Hartig, Olaf and Maleshkova, Maria and Sv{\'a}tek, Vojt{\v e}ch and Cruz, Isabel and Hogan, Aidan and Song, Jie and Lefran{\c c}ois, Maxime and Gandon, Fabien},
  year = {2019},
  volume = {11779},
  pages = {69--78},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-30796-7_5},
  urldate = {2024-02-29},
  abstract = {Providing machines with the capability of exploring knowledge graphs and answering natural language questions has been an active area of research over the past decade. In this direction translating natural language questions to formal queries has been one of the key approaches. To advance the research area, several datasets like WebQuestions, QALD and LCQuAD have been published in the past. The biggest data set available for complex questions (LCQuAD) over knowledge graphs contains five thousand questions. We now provide LC-QuAD 2.0 (Large-Scale Complex Question Answering Dataset) with 30,000 questions, their paraphrases and their corresponding SPARQL queries. LC-QuAD 2.0 is compatible with both Wikidata and DBpedia 2018 knowledge graphs. In this article, we explain how the dataset was created and the variety of questions available with examples. We further provide a statistical analysis of the dataset.},
  isbn = {978-3-030-30796-7},
  langid = {english},
}

@misc{duffyStructuralTransferLearning2023,
  title = {Structural {{Transfer Learning}} in {{NL-to-Bash Semantic Parsers}}},
  author = {Duffy, Kyle and Bhattamishra, Satwik and Blunsom, Phil},
  year = {2023},
  month = jul,
  number = {arXiv:2307.16795},
  eprint = {2307.16795},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2307.16795},
  urldate = {2024-11-22},
  abstract = {Large-scale pre-training has made progress in many fields of natural language processing, though little is understood about the design of pre-training datasets. We propose a methodology for obtaining a quantitative understanding of structural overlap between machine translation tasks. We apply our methodology to the natural language to Bash semantic parsing task (NLBash) and show that it is largely reducible to lexical alignment. We also find that there is strong structural overlap between NLBash and natural language to SQL. Additionally, we perform a study varying compute expended during pre-training on the English to German machine translation task and find that more compute expended during pre-training does not always correspond semantic representations with stronger transfer to NLBash.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},
  annotation = {Read\_Status: To Read\\
Read\_Status\_Date: 2024-11-22T17:07:43.767Z},
}

@misc{elaasarOntologicalModelingLanguage2024,
  title = {Ontological {{Modeling Language}} V2},
  author = {Elaasar, Maged and Rouquette, Nicolas},
  year = {2024},
  month = nov,
  url = {https://www.opencaesar.io/oml/},
  urldate = {2025-01-05},
  copyright = {Copyright {\copyright} 2019-2024 California Institute of Technology. Government sponsorship acknowledged.},
}

@inproceedings{elaasarOpenCAESARBalancingAgility2023,
  title = {{{openCAESAR}}: {{Balancing Agility}} and {{Rigor}} in {{Model-Based Systems Engineering}}},
  shorttitle = {{{openCAESAR}}},
  booktitle = {2023 {{ACM}}/{{IEEE International Conference}} on {{Model Driven Engineering Languages}} and {{Systems Companion}} ({{MODELS-C}})},
  author = {Elaasar, Maged and Rouquette, Nicolas and Wagner, David and Oakes, Bentley James and {Hamou-Lhadj}, Abdelwahab and Hamdaqa, Mohammad},
  year = {2023},
  month = oct,
  pages = {221--230},
  publisher = {IEEE},
  address = {V{\"a}ster{\aa}s, Sweden},
  doi = {10.1109/MODELS-C59198.2023.00051},
  urldate = {2024-08-26},
  abstract = {Model-Based System Engineering (MBSE) employs models and formal languages to support development of complex (systems-of-) systems. NASA Jet Propulsion Laboratory (JPL) sees MBSE as a key approach to managing the complexity of system development. However, balancing agility and rigor in MBSE has been reported as a challenging task not yet addressed by modeling tools and frameworks. This is because existing MBSE approaches may enable agility but compromise rigor, or enhance rigor but impede agility. We discuss the challenges of balancing agility and rigor in MBSE across seven systems engineering architectural functions defined by the JPL Integrated Model-Centric Engineering (IMCE) initiative. We demonstrate how openCAESAR, an open-source MBSE methodology and framework created at JPL, can strike a balance between agility and rigor through a case study of the Kepler16b project and discussion of lessons learned from past projects.},
  copyright = {https://doi.org/10.15223/policy-029},
  isbn = {9798350324983},
  langid = {english},
}

@misc{fabbriTreeBasedSemanticParsing2017,
  title = {Tree-{{Based Semantic Parsing}}},
  author = {Fabbri, Alexander and Radev, Dragomir},
  year = 2017,
  publisher = {Department of Computer Science, Yale University},
  url = {https://web.archive.org/web/20250113091733/https://yale-lily.github.io/public/fabbri_alexander_tree_based_semantic_parsing.pdf},
  urldate = {2024-12-05},
}

@misc{fanSurveyRAGMeeting2024,
  title = {A {{Survey}} on {{RAG Meeting LLMs}}: {{Towards Retrieval-Augmented Large Language Models}}},
  shorttitle = {A {{Survey}} on {{RAG Meeting LLMs}}},
  author = {Fan, Wenqi and Ding, Yujuan and Ning, Liangbo and Wang, Shijie and Li, Hengyun and Yin, Dawei and Chua, Tat-Seng and Li, Qing},
  year = {2024},
  month = jun,
  number = {arXiv:2405.06211},
  eprint = {2405.06211},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2405.06211},
  urldate = {2024-08-25},
  abstract = {As one of the most advanced techniques in AI, Retrieval-Augmented Generation (RAG) can offer reliable and up-to-date external knowledge, providing huge convenience for numerous tasks. Particularly in the era of AI-Generated Content (AIGC), the powerful capacity of retrieval in providing additional knowledge enables RAG to assist existing generative AI in producing high-quality outputs. Recently, Large Language Models (LLMs) have demonstrated revolutionary abilities in language understanding and generation, while still facing inherent limitations, such as hallucinations and out-ofdate internal knowledge. Given the powerful abilities of RAG in providing the latest and helpful auxiliary information, RetrievalAugmented Large Language Models (RA-LLMs) have emerged to harness external and authoritative knowledge bases, rather than solely relying on the model's internal knowledge, to augment the generation quality of LLMs. In this survey, we comprehensively review existing research studies in RA-LLMs, covering three primary technical perspectives: architectures, training strategies, and applications. As the preliminary knowledge, we briefly introduce the foundations and recent advances of LLMs. Then, to illustrate the practical significance of RAG for LLMs, we systematically review mainstream relevant work by their architectures, training strategies, and application areas, detailing specifically the challenges of each and the corresponding capabilities of RA-LLMs. Finally, to deliver deeper insights, we discuss current limitations and several promising directions for future research. Updated information about this survey can be found at https:// advanced-recommendersystems.github.io/ RAG-Meets-LLMs/ 1.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Information Retrieval},
}

@misc{fengIncubatorCaseStudy2021,
  title = {The {{Incubator Case Study}} for {{Digital Twin Engineering}}},
  author = {Feng, Hao and Gomes, Cl{\'a}udio and Thule, Casper and Lausdahl, Kenneth and Sandberg, Michael and Larsen, Peter Gorm},
  year = {2021},
  month = feb,
  number = {arXiv:2102.10390},
  eprint = {2102.10390},
  primaryclass = {cs, eess},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/2102.10390},
  urldate = {2024-01-11},
  abstract = {To demystify the Digital Twin concept, we built a simple yet representative thermal incubator system. The incubator is an insulated box fitted with a heatbed, and complete with a software system for communication, a controller, and simulation models. We developed two simulation models to predict the temperature inside the incubator, one with two free parameters and one with four free parameters. Our experiments showed that the latter model was better at predicting the thermal inertia of the heatbed itself, which makes it more appropriate for further development of the digital twin. The hardware and software used in this case study are available open source, providing an accessible platform for those who want to develop and verify their own techniques for digital twins.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Electrical Engineering and Systems Science - Systems and Control},
}

@misc{ferreSQUALL,
  title = {{{SQUALL}}},
  author = {Ferr{\'e}, S{\'e}bastien},
  url = {https://people.irisa.fr/Sebastien.Ferre/software/squall/},
  urldate = {2024-04-07},
  abstract = {SQUALL (Semantic Query and Update High-Level Language) is a controlled natural language (CNL) for querying and updating RDF graphs. The main advantage of CNLs is to reconcile the high-level and natural syntax of natural languages, and the precision and lack of ambiguity of formal languages. SQUALL has a strong adequacy with RDF, and covers all constructs of SPARQL, and many of SPARQL 1.1. Its syntax completely abstracts from low-level notions such as bindings and relational algebra. It features disjunction, negation, quantifiers, built-in predicates, aggregations with grouping, and n-ary relations through reification.},
  langid = {american},
}

@misc{ferreSquall2sparql2023,
  title = {Squall2sparql},
  author = {Ferr{\'e}, S{\'e}bastien},
  year = {2023},
  month = sep,
  url = {http://people.irisa.fr/Sebastien.Ferre/software/squall},
  urldate = {2024-08-18},
  abstract = {A translator from SQUALL (Semantic Query and Update High Level Language) to SPARQL.}
}

@inproceedings{ferreSquall2sparqlTranslatorControlled2013,
  title = {Squall2sparql: A {{Translator}} from {{Controlled English}} to {{Full SPARQL}} 1.1},
  booktitle = {{{CEUR Workshop Proceedings}}},
  author = {Ferr{\'e}, S{\'e}bastien},
  year = {2013},
  month = sep,
  volume = {1179},
  address = {Valencia, Spain},
  abstract = {This paper reports on the participation of the system squall2sparql in the QALD-3 question answering challenge for DBpedia. squall2sparql is a translator from SQUALL, a controlled natural language for English, to SPARQL 1.1, a standard expressive query and update language for linked open data. It covers nearly all features of SPARQL 1.1, and is directly applicable to any SPARQL endpoint.},
  langid = {english},
}

@misc{ferreSQUALLExamples,
  title = {{{SQUALL Examples}}},
  author = {Ferr{\'e}, S{\'e}bastien},
  url = {http://servolis.irisa.fr:3838/squall/examples},
  urldate = {2024-08-23},
}

@article{ferreSQUALLExpressivenessSPARQL2014,
  title = {{{SQUALL}}: {{The}} Expressiveness of {{SPARQL}} 1.1 Made Available as a Controlled Natural Language},
  shorttitle = {{{SQUALL}}},
  author = {Ferr{\'e}, S{\'e}bastien},
  year = {2014},
  month = nov,
  journal = {Data \& Knowledge Engineering},
  volume = {94},
  pages = {163--188},
  issn = {0169023X},
  doi = {10.1016/j.datak.2014.07.010},
  urldate = {2024-03-10},
  abstract = {The Semantic Web (SW) is now made of billions of triples, which are available as Linked Open Data (LOD) or as RDF stores. The SPARQL query language provides a very expressive way to search and explore this wealth of semantic data. However, userfriendly interfaces are needed to bridge the gap between end-users and SW formalisms. Navigation-based interfaces and natural language interfaces require no or little training, but they cover a small fragment of SPARQL's expressivity. We propose SQUALL, a query and update language that provides the full expressiveness of SPARQL 1.1 through a flexible controlled natural language (e.g., solution modifiers through superlatives, relational algebra through coordinations, filters through comparatives). A comprehensive and modular definition is given as a Montague grammar, and an evaluation of naturalness is done on the QALD challenge. SQUALL is conceived as a component of natural language interfaces, to be combined with lexicons, guided input, and contextual disambiguation. It is available as a Web service that translates SQUALL sentences to SPARQL, and submits them to SPARQL endpoints (e.g., DBpedia), therefore ensuring SW compliance, and leveraging the efficiency of SPARQL engines.},
  langid = {english},
}

@article{FutureMathematics2023,
  title = {Future of Mathematics},
  year = {2023},
  month = oct,
  journal = {Wikipedia},
  url = {https://en.wikipedia.org/w/index.php?title=Future_of_mathematics&oldid=1182226887},
  urldate = {2024-12-09},
  abstract = {The progression of both the nature of mathematics and individual mathematical problems into the future is a widely debated topic; many past predictions about modern mathematics have been misplaced or completely false, so there is reason to believe that many predictions today will follow a similar path. However, the subject still carries an important weight and has been written about by many notable mathematicians. Typically, they are motivated by a desire to set a research agenda to direct efforts to specific problems, or a wish to clarify, update and extrapolate the way that subdisciplines relate to the general discipline of mathematics and its possibilities. Examples of agendas pushing for progress in specific areas in the future, historical and recent, include  Felix Klein's Erlangen program, Hilbert's problems, Langlands program, and the Millennium Prize Problems. In the Mathematics Subject Classification section 01Axx History of mathematics and mathematicians, subsection 01A67 is titled Future prospectives. The accuracy of predictions about mathematics has varied widely and has proceeded very closely to that of technology.  As such, it is important to keep in mind that many of the predictions by researchers below may be misguided or turn out to be untrue.},
  copyright = {Creative Commons Attribution-ShareAlike License},
  langid = {english},
  annotation = {Page Version ID: 1182226887},
}

@misc{gaoRetrievalAugmentedGenerationLarge2024,
  title = {Retrieval-{{Augmented Generation}} for {{Large Language Models}}: {{A Survey}}},
  shorttitle = {Retrieval-{{Augmented Generation}} for {{Large Language Models}}},
  author = {Gao, Yunfan and Xiong, Yun and Gao, Xinyu and Jia, Kangxiang and Pan, Jinliu and Bi, Yuxi and Dai, Yi and Sun, Jiawei and Guo, Qianyu and Wang, Meng and Wang, Haofen},
  year = {2024},
  month = jan,
  publisher = {arXiv},
  doi = {10.48550/arXiv.2312.10997},
  urldate = {2024-02-22},
  abstract = {Large Language Models (LLMs) demonstrate significant capabilities but face challenges such as hallucination, outdated knowledge, and nontransparent, untraceable reasoning processes. Retrieval-Augmented Generation (RAG) has emerged as a promising solution by incorporating knowledge from external databases. This enhances the accuracy and credibility of the models, particularly for knowledge-intensive tasks, and allows for continuous knowledge updates and integration of domain-specific information. RAG synergistically merges LLMs' intrinsic knowledge with the vast, dynamic repositories of external databases. This comprehensive review paper offers a detailed examination of the progression of RAG paradigms, encompassing the Naive RAG, the Advanced RAG, and the Modular RAG. It meticulously scrutinizes the tripartite foundation of RAG frameworks, which includes the retrieval , the generation and the augmentation techniques. The paper highlights the state-of-the-art technologies embedded in each of these critical components, providing a profound understanding of the advancements in RAG systems. Furthermore, this paper introduces the metrics and benchmarks for assessing RAG models, along with the most up-to-date evaluation framework. In conclusion, the paper delineates prospective avenues for research, including the identification of challenges, the expansion of multi-modalities, and the progression of the RAG infrastructure and its ecosystem. 1.},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
}

@misc{gebhartKnowledgeSheavesSheafTheoretic2023,
  title = {Knowledge {{Sheaves}}: {{A Sheaf-Theoretic Framework}} for {{Knowledge Graph Embedding}}},
  shorttitle = {Knowledge {{Sheaves}}},
  author = {Gebhart, Thomas and Hansen, Jakob and Schrater, Paul},
  year = {2023},
  month = mar,
  number = {arXiv:2110.03789},
  eprint = {2110.03789},
  primaryclass = {cs, math, stat},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/2110.03789},
  urldate = {2024-03-01},
  abstract = {Knowledge graph embedding involves learning representations of entities -- the vertices of the graph -- and relations -- the edges of the graph -- such that the resulting representations encode the known factual information represented by the knowledge graph and can be used in the inference of new relations. We show that knowledge graph embedding is naturally expressed in the topological and categorical language of {\textbackslash}textit\{cellular sheaves\}: a knowledge graph embedding can be described as an approximate global section of an appropriate {\textbackslash}textit\{knowledge sheaf\} over the graph, with consistency constraints induced by the knowledge graph's schema. This approach provides a generalized framework for reasoning about knowledge graph embedding models and allows for the expression of a wide range of prior constraints on embeddings. Further, the resulting embeddings can be easily adapted for reasoning over composite relations without special training. We implement these ideas to highlight the benefits of the extensions inspired by this new perspective.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Mathematics - Algebraic Topology,Statistics - Machine Learning},
}

@article{gebruDatasheetsDatasets2021,
  title = {Datasheets for Datasets},
  author = {Gebru, Timnit and Morgenstern, Jamie and Vecchione, Briana and Vaughan, Jennifer Wortman and Wallach, Hanna and Iii, Hal Daum{\'e} and Crawford, Kate},
  year = {2021},
  month = dec,
  journal = {Communications of the ACM},
  volume = {64},
  number = {12},
  pages = {86--92},
  issn = {0001-0782, 1557-7317},
  doi = {10.1145/3458723},
  urldate = {2025-01-13},
  abstract = {Documentation to facilitate communication between dataset creators and consumers.},
  langid = {english},
}

@article{geDomainAdaptationPrompt2023,
  title = {Domain {{Adaptation}} via {{Prompt Learning}}},
  author = {Ge, Chunjiang and Huang, Rui and Xie, Mixue and Lai, Zihang and Song, Shiji and Li, Shuang and Huang, Gao},
  year = {2023},
  journal = {IEEE Transactions on Neural Networks and Learning Systems},
  pages = {1--11},
  issn = {2162-2388},
  doi = {10.1109/TNNLS.2023.3327962},
  urldate = {2024-08-26},
  abstract = {Unsupervised domain adaptation (UDA) aims to adapt models learned from a well-annotated source domain to a target domain, where only unlabeled samples are given. Current UDA approaches learn domain-invariant features by aligning source and target feature spaces through statistical discrepancy minimization or adversarial training. However, these constraints could lead to the distortion of semantic feature structures and loss of class discriminability. In this article, we introduce a novel prompt learning paradigm for UDA, named domain adaptation via prompt learning (DAPrompt). In contrast to prior works, our approach learns the underlying label distribution for target domain rather than aligning domains. The main idea is to embed domain information into prompts, a form of representation generated from natural language, which is then used to perform classification. This domain information is shared only by images from the same domain, thereby dynamically adapting the classifier according to each domain. By adopting this paradigm, we show that our model not only outperforms previous methods on several cross-domain benchmarks but also is very efficient to train and easy to implement.},
  keywords = {Adaptation models,Contrastive learning,Feature extraction,Learning systems,Predictive models,prompt learning,Semantics,Task analysis,Training,unsupervised domain adaptation (UDA)},
}

@misc{GeneralizingFewExamples,
  title = {Generalizing from a {{Few Examples}}: {{A Survey}} on {{Few-shot Learning}}: {{ACM Computing Surveys}}: {{Vol}} 53, {{No}} 3},
  url = {https://dl.acm.org/doi/10.1145/3386252},
  urldate = {2024-08-05},
  keywords = {Synthetic data},
}

@article{GoodPracticeRadiological2011,
  title = {Good Practice for Radiological Reporting. {{Guidelines}} from the {{European Society}} of {{Radiology}} ({{ESR}})},
  year = {2011},
  month = feb,
  journal = {Insights into Imaging},
  volume = {2},
  number = {2},
  pages = {93--96},
  issn = {1869-4101},
  doi = {10.1007/s13244-011-0066-7},
  urldate = {2024-01-27},
  abstract = {The views of the European Society of Radiology concerning what constitutes a good radiological report are outlined in this article. Some pertinent literature is reviewed.},
  pmcid = {PMC3259387},
  pmid = {22347937},
}

@incollection{gorlitzSPLODGESystematicGeneration2012,
  title = {{{SPLODGE}}: {{Systematic Generation}} of {{SPARQL Benchmark Queries}} for {{Linked Open Data}}},
  shorttitle = {{{SPLODGE}}},
  booktitle = {The {{Semantic Web}} -- {{ISWC}} 2012},
  author = {G{\"o}rlitz, Olaf and Thimm, Matthias and Staab, Steffen},
  editor = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Doug and Vardi, Moshe Y. and Weikum, Gerhard and {Cudr{\'e}-Mauroux}, Philippe and Heflin, Jeff and Sirin, Evren and Tudorache, Tania and Euzenat, J{\'e}r{\^o}me and Hauswirth, Manfred and Parreira, Josiane Xavier and Hendler, Jim and Schreiber, Guus and Bernstein, Abraham and Blomqvist, Eva},
  year = {2012},
  volume = {7649},
  pages = {116--132},
  publisher = {Springer Berlin Heidelberg},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-642-35176-1_8},
  urldate = {2024-08-17},
  abstract = {The distributed and heterogeneous nature of Linked Open Data requires flexible and federated techniques for query evaluation. In order to evaluate current federation querying approaches a general methodology for conducting benchmarks is mandatory. In this paper, we present a classification methodology for federated SPARQL queries. This methodology can be used by developers of federated querying approaches to compose a set of test benchmarks that cover diverse characteristics of different queries and allows for comparability. We further develop a heuristic called SPLODGE for automatic generation of benchmark queries that is based on this methodology and takes into account the number of sources to be queried and several complexity parameters. We evaluate the adequacy of our methodology and the query generation strategy by applying them on the 2011 billion triple challenge data set.},
  isbn = {978-3-642-35175-4 978-3-642-35176-1},
  langid = {english},
}

@misc{goybetMolabextMolabExtension,
  title = {Molab-Ext: Molab Extension},
  shorttitle = {Molab-Ext},
  author = {Goybet, Fran{\c c}ois},
}

@misc{GraphSimilarityScoring,
  title = {Graph Similarity Scoring and Matching - {{ScienceDirect}}},
  url = {https://www.sciencedirect.com/science/article/pii/S0893965907001012},
  urldate = {2024-08-05},
}

@article{gregorySystemsEngineeringOntology2024,
  title = {Towards a {{Systems Engineering Ontology Stack}}},
  author = {Gregory, Joe and Salado, Alejandro},
  year = {2024},
  journal = {INCOSE International Symposium},
  volume = {34},
  number = {1},
  pages = {1304--1318},
  issn = {2334-5837},
  doi = {10.1002/iis2.13210},
  urldate = {2024-12-09},
  abstract = {Semantic Web Technologies (SWTs) provide an approach to the structuring and understanding of data. SWTs utilize ontologies, reasoners, and query languages to structure existing knowledge, validate knowledge, and infer new knowledge. Ontologies in particular play a central role in enabling reusability and interoperability between domains. A common way to organize ontologies and their dependencies is in a layered ontology stack. These layers often incorporate top-level, core and domain ontologies. Libraries of standard instances can also be used. Federating the conceptualization of a domain across upper- and lower-level ontologies improves the reusability of higher-level terminology in other domains, and therefore improves interoperability between them. The University of Arizona Ontology Stack (UAOS) is a layered, modular ontology stack that has been developed to support digital engineering activities at the University of Arizona. It is based on the Basic Formal Ontology (BFO), and currently comprises five core ontologies and 12 domain ontologies. The UAOS reuses existing ontologies and standards wherever possible. The core ontologies, for example, are based on the Common Core Ontologies, developed at CUBRC, and the Provenance Notation (PROV-N), a W3C standard. Domain ontologies include the System Architecture Ontology, based on ISO 42010, and the Orbits and Trajectories Ontology, based on CUBRC's Space Object Ontology. In this paper, we report on the development of the UAOS, present examples of how it has been used to support digital engineering research, discuss the challenges of integrating ontologies from multiple sources into a cohesive stack, and highlight topics of interest for future research.},
  langid = {english},
  keywords = {digital engineering,education,ontology,Semantic web technologies,verification},
}

@article{GuidelinesWritingClinical2017,
  title = {Guidelines {{To Writing A Clinical Case Report}}},
  year = {2017},
  journal = {Heart Views : The Official Journal of the Gulf Heart Association},
  volume = {18},
  number = {3},
  pages = {104--105},
  issn = {1995-705X},
  doi = {10.4103/1995-705X.217857},
  urldate = {2024-01-27},
  pmcid = {PMC5686928},
  pmid = {29184619}
}

@misc{GuidingFrozenLanguage,
  title = {Guiding {{Frozen Language Models}} with {{Learned Soft Prompts}}},
  url = {http://research.google/blog/guiding-frozen-language-models-with-learned-soft-prompts/},
  urldate = {2024-08-26},
  abstract = {Posted by Brian Lester, AI Resident and Noah Constant, Senior Staff Software Engineer, Google Research Large pre-trained language models, which are...},
  langid = {english},
}

@misc{guKnowledgeBaseQuestion2022,
  title = {Knowledge {{Base Question Answering}}: {{A Semantic Parsing Perspective}}},
  shorttitle = {Knowledge {{Base Question Answering}}},
  author = {Gu, Yu and Pahuja, Vardaan and Cheng, Gong and Su, Yu},
  year = {2022},
  month = oct,
  number = {arXiv:2209.04994},
  eprint = {2209.04994},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2209.04994},
  urldate = {2024-11-24},
  abstract = {Recent advances in deep learning have greatly propelled the research on semantic parsing. Improvement has since been made in many downstream tasks, including natural language interface to web APIs, text-to-SQL generation, among others. However, despite the close connection shared with these tasks, research on question answering over knowledge bases (KBQA) has comparatively been progressing slowly. We identify and attribute this to two unique challenges of KBQA, schema-level complexity and fact-level complexity. In this survey, we situate KBQA in the broader literature of semantic parsing and give a comprehensive account of how existing KBQA approaches attempt to address the unique challenges. Regardless of the unique challenges, we argue that we can still take much inspiration from the literature of semantic parsing, which has been overlooked by existing research on KBQA. Based on our discussion, we can better understand the bottleneck of current KBQA research and shed light on promising directions for KBQA to keep up with the literature of semantic parsing, particularly in the era of pre-trained language models.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  annotation = {Read\_Status: To Read\\
Read\_Status\_Date: 2024-11-24T15:23:17.723Z},
}

@misc{guPPTPretrainedPrompt2022,
  title = {{{PPT}}: {{Pre-trained Prompt Tuning}} for {{Few-shot Learning}}},
  shorttitle = {{{PPT}}},
  author = {Gu, Yuxian and Han, Xu and Liu, Zhiyuan and Huang, Minlie},
  year = {2022},
  month = mar,
  number = {arXiv:2109.04332},
  eprint = {2109.04332},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2109.04332},
  urldate = {2024-08-05},
  abstract = {Prompts for pre-trained language models (PLMs) have shown remarkable performance by bridging the gap between pre-training tasks and various downstream tasks. Among these methods, prompt tuning, which freezes PLMs and only tunes soft prompts, provides an efficient and effective solution for adapting large-scale PLMs to downstream tasks. However, prompt tuning is yet to be fully explored. In our pilot experiments, we find that prompt tuning performs comparably with conventional full-model fine-tuning when downstream data are sufficient, whereas it performs much worse under few-shot learning settings, which may hinder the application of prompt tuning in practice. We attribute this low performance to the manner of initializing soft prompts. Therefore, in this work, we propose to pre-train prompts by adding soft prompts into the pre-training stage to obtain a better initialization. We name this Pre-trained Prompt Tuning framework "PPT". To ensure the generalization of PPT, we formulate similar classification tasks into a unified task form and pre-train soft prompts for this unified task. Extensive experiments show that tuning pre-trained prompts for downstream tasks can reach or even outperform full-model fine-tuning under both full-data and few-shot settings. Our approach is effective and efficient for using large-scale PLMs in practice.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language,Synthetic data},
}

@misc{hajariFactoringExpertiseWorkload2023,
  title = {Factoring {{Expertise}}, {{Workload}}, and {{Turnover}} into {{Code Review Recommendation}}},
  author = {Hajari, Fahimeh and Malmir, Samaneh and Mirsaeedi, Ehsan and Rigby, Peter C.},
  year = {2023},
  month = dec,
  number = {arXiv:2312.17236},
  eprint = {2312.17236},
  primaryclass = {cs},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/2312.17236},
  urldate = {2024-04-02},
  abstract = {Developer turnover is inevitable on software projects and leads to knowledge loss, a reduction in productivity, and an increase in defects. Mitigation strategies to deal with turnover tend to disrupt and increase workloads for developers. In this work, we suggest that through code review recommendation we can distribute knowledge and mitigate turnover while more evenly distributing review workload. We conduct historical analyses to understand the natural concentration of review workload and the degree of knowledge spreading that is inherent in code review. Even though review workload is highly concentrated, we show that code review natural spreads knowledge thereby reducing the files at risk to turnover. Using simulation, we evaluate existing code review recommenders and develop novel recommenders to understand their impact on the level of expertise during review, the workload of reviewers, and the files at risk to turnover. Our simulations use seeded random replacement of reviewers to allow us to compare the reviewer recommenders without the confounding variation of different reviewers being replaced for each recommender. Combining recommenders, we develop the SofiaWL recommender that suggests experts with low active review workload when none of the files under review are known by only one developer. In contrast, when knowledge is concentrated on one developer, it sends the review to other reviewers to spread knowledge. For the projects we study, we are able to globally increase expertise during reviews, +3\%, reduce workload concentration, -12\%, and reduce the files at risk, -28\%. We make our scripts and data available in our replication package. Developers can optimize for a particular outcome measure based on the needs of their project, or use our GitHub bot to automatically balance the outcomes.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Software Engineering},
}

@misc{hanKeywordSearchRDF2017,
  title = {Keyword {{Search}} on {{RDF Graphs}} - {{A Query Graph Assembly Approach}}},
  author = {Han, Shuo and Zou, Lei and Yu, Jeffrey Xu and Zhao, Dongyan},
  year = {2017},
  month = aug,
  number = {arXiv:1704.00205},
  eprint = {1704.00205},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1704.00205},
  urldate = {2024-07-31},
  abstract = {Graph DBXplorer DISCOVER SPARK MetaMatch ...},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Databases},
}

@article{haveliwalaTopicsensitivePagerankContextsensitive2003,
  title = {Topic-Sensitive Pagerank: {{A}} Context-Sensitive Ranking Algorithm for Web Search},
  shorttitle = {Topic-Sensitive Pagerank},
  author = {Haveliwala, T.H.},
  year = {2003},
  month = jul,
  journal = {IEEE Transactions on Knowledge and Data Engineering},
  volume = {15},
  number = {4},
  pages = {784--796},
  issn = {1041-4347},
  doi = {10.1109/TKDE.2003.1208999},
  urldate = {2024-07-30},
  abstract = {The original PageRank algorithm for improving the ranking of search-query results computes a single vector, using the link structure of the Web, to capture the relative ``importance'' of Web pages, independent of any particular search query. To yield more accurate search results, we propose computing a set of PageRank vectors, biased using a set of representative topics, to capture more accurately the notion of importance with respect to a particular topic. For ordinary keyword search queries, we compute the topicsensitive PageRank scores for pages satisfying the query using the topic of the query keywords. For searches done in context (e.g., when the search query is performed by highlighting words in a Web page), we compute the topic-sensitive PageRank scores using the topic of the context in which the query appeared. By using linear combinations of these (precomputed) biased PageRank vectors to generate context-specific importance scores for pages at query time, we show that we can generate more accurate rankings than with a single, generic PageRank vector. We describe techniques for efficiently implementing a large-scale search system based on the topic-sensitive PageRank scheme.},
  copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
  langid = {english},
}

@inproceedings{heAdaptationMultilingualTransformer2020,
  title = {Adaptation of {{Multilingual Transformer Encoder}} for {{Robust Enhanced Universal Dependency Parsing}}},
  booktitle = {Proceedings of the 16th {{International Conference}} on {{Parsing Technologies}} and the {{IWPT}} 2020 {{Shared Task}} on {{Parsing}} into {{Enhanced Universal Dependencies}}},
  author = {He, Han and Choi, Jinho D.},
  year = {2020},
  pages = {181--191},
  publisher = {Association for Computational Linguistics},
  address = {Online},
  doi = {10.18653/v1/2020.iwpt-1.19},
  urldate = {2024-08-20},
  abstract = {This paper presents our enhanced dependency parsing approach using transformer encoders, coupled with a simple yet powerful ensemble algorithm that takes advantage of both tree and graph dependency parsing. Two types of transformer encoders are compared, a multilingual encoder and language-specific encoders. Our dependency tree parsing (DTP) approach generates only primary dependencies to form trees whereas our dependency graph parsing (DGP) approach handles both primary and secondary dependencies to form graphs. Since DGP does not guarantee the generated graphs are acyclic, the ensemble algorithm is designed to add secondary arcs predicted by DGP to primary arcs predicted by DTP. Our results show that models using the multilingual encoder outperform ones using the language specific encoders for most languages. Moreover, the ensemble models generally show higher labeled attachment score on enhanced dependencies (ELAS) than the DTP and DGP models. As the result, our best parsing models rank the third place on the macro-average ELAS over 17 languages.},
  langid = {english},
}

@article{heerAgencyAutomationDesigning2019,
  title = {Agency plus Automation: {{Designing}} Artificial Intelligence into Interactive Systems},
  shorttitle = {Agency plus Automation},
  author = {Heer, Jeffrey},
  year = {2019},
  month = feb,
  journal = {Proceedings of the National Academy of Sciences},
  volume = {116},
  number = {6},
  pages = {1844--1850},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.1807184115},
  urldate = {2024-04-07},
  abstract = {Much contemporary rhetoric regards the prospects and pitfalls of using artificial intelligence techniques to automate an increasing range of tasks, especially those once considered the purview of people alone. These accounts are often wildly optimistic, understating outstanding challenges while turning a blind eye to the human labor that undergirds and sustains ostensibly ``automated'' services. This long-standing focus on purely automated methods unnecessarily cedes a promising design space: one in which computational assistance augments and enriches, rather than replaces, people's intellectual work. This tension between human agency and machine automation poses vital challenges for design and engineering. In this work, we consider the design of systems that enable rich, adaptive interaction between people and algorithms. We seek to balance the often-complementary strengths and weaknesses of each, while promoting human control and skillful action. We share case studies of interactive systems we have developed in three arenas---data wrangling, exploratory analysis, and natural language translation---that integrate proactive computational support into interactive systems. To improve outcomes and support learning by both people and machines, we describe the use of shared representations of tasks augmented with predictive models of human capabilities and actions. We conclude with a discussion of future prospects and scientific frontiers for intelligence augmentation research.},
  langid = {english},
}

@misc{heGRetrieverRetrievalAugmentedGeneration2024,
  title = {G-{{Retriever}}: {{Retrieval-Augmented Generation}} for {{Textual Graph Understanding}} and {{Question Answering}}},
  shorttitle = {G-{{Retriever}}},
  author = {He, Xiaoxin and {Yijun Tian} and {Yifei Sun} and Chawla, Nitesh V. and Laurent, Thomas and LeCun, Yann and Bresson, Xavier and Hooi, Bryan},
  year = {2024},
  month = feb,
  number = {arXiv:2402.07630},
  eprint = {2402.07630},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2402.07630},
  urldate = {2024-02-22},
  abstract = {Given a graph with textual attributes, we enable users to `chat with their graph': that is, to ask questions about the graph using a conversational interface. In response to a user's questions, our method provides textual replies and highlights the relevant parts of the graph. While existing works integrate large language models (LLMs) and graph neural networks (GNNs) in various ways, they mostly focus on either conventional graph tasks (such as node, edge, and graph classification), or on answering simple graph queries on small or synthetic graphs. In contrast, we develop a flexible question-answering framework targeting real-world textual graphs, applicable to multiple applications including scene graph understanding, common sense reasoning, and knowledge graph reasoning. Toward this goal, we first develop our Graph Question Answering (GraphQA) benchmark with data collected from different tasks. Then, we propose our G-Retriever approach, which integrates the strengths of GNNs, LLMs, and Retrieval-Augmented Generation (RAG), and can be fine-tuned to enhance graph understanding via soft prompting. To resist hallucination and to allow for textual graphs that greatly exceed the LLM's context window size, G-Retriever performs RAG over a graph by formulating this task as a Prize-Collecting Steiner Tree optimization problem. Empirical evaluations show that our method outperforms baselines on textual graph tasks from multiple domains, scales well with larger graph sizes, and resists hallucination. (Our codes and datasets are available at: https://github.com/XiaoxinHe/G-Retriever.)},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Machine Learning},
  annotation = {Read\_Status: Read\\
Read\_Status\_Date: 2024-12-04T12:32:05.861Z},
}

@inproceedings{heImprovingMultihopKnowledge2021,
  title = {Improving {{Multi-hop Knowledge Base Question Answering}} by {{Learning Intermediate Supervision Signals}}},
  booktitle = {Proceedings of the 14th {{ACM International Conference}} on {{Web Search}} and {{Data Mining}}},
  author = {He, Gaole and Lan, Yunshi and Jiang, Jing and Zhao, Wayne Xin and Wen, Ji-Rong},
  year = {2021},
  month = mar,
  eprint = {2101.03737},
  primaryclass = {cs},
  pages = {553--561},
  doi = {10.1145/3437963.3441753},
  urldate = {2024-07-10},
  abstract = {Multi-hop Knowledge Base Question Answering (KBQA) aims to find the answer entities that are multiple hops away in the Knowledge Base (KB) from the entities in the question. A major challenge is the lack of supervision signals at intermediate steps. Therefore, multi-hop KBQA algorithms can only receive the feedback from the final answer, which makes the learning unstable or ineffective. To address this challenge, we propose a novel teacher-student approach for the multi-hop KBQA task. In our approach, the student network aims to find the correct answer to the query, while the teacher network tries to learn intermediate supervision signals for improving the reasoning capacity of the student network. The major novelty lies in the design of the teacher network, where we utilize both forward and backward reasoning to enhance the learning of intermediate entity distributions. By considering bidirectional reasoning, the teacher network can produce more reliable intermediate supervision signals, which can alleviate the issue of spurious reasoning. Extensive experiments on three benchmark datasets have demonstrated the effectiveness of our approach on the KBQA task. The code to reproduce our analysis is available at https://github.com/RichardHGL/WSDM2021\_NSM.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
}

@article{hendersonValueBenefitsModelbased2021,
  title = {Value and Benefits of Model-Based Systems Engineering ({{MBSE}}): {{Evidence}} from the Literature},
  shorttitle = {Value and Benefits of Model-Based Systems Engineering ({{MBSE}})},
  author = {Henderson, Kaitlin and Salado, Alejandro},
  year = {2021},
  journal = {Systems Engineering},
  volume = {24},
  number = {1},
  pages = {51--66},
  issn = {1520-6858},
  doi = {10.1002/sys.21566},
  urldate = {2024-03-02},
  abstract = {Traditional document-based practices in systems engineering are being transitioned to model-based ones. Adoption of model-based systems engineering (MBSE) continues to grow in industry and government, and MBSE continues to be a major research theme in the systems engineering community. In fact, MBSE remains a central element in the International Council on Systems Engineering (INCOSE)'s vision for 2025. Examining systems engineering literature, this paper presents an assessment of the extent to which benefits and value of MBSE are supported by empirical evidence. A systematic review of research and practice papers in major systems engineering archival journals and conference proceedings was conducted. Evidence was categorized in four types, two of which inductively emerged from the results: measured, observed (without a formal measurement process), perceived (claimed without evidence), and backed by other references. Results indicate that two thirds of claimed MBSE benefits are only supported by perceived evidence, while only two papers reported measured evidence. The aggregate assessment presented in this paper indicates that claims about the value and benefits of MBSE are mainly based on expectation. We argue that evidence supporting the value and benefits of MBSE remains inconclusive.},
  langid = {english},
  keywords = {literature review,model-based systems engineering (MBSE),value of systems engineering},
  annotation = {Read\_Status: Stopped Reading\\
Read\_Status\_Date: 2024-12-05T15:40:01.166Z},
}

@inproceedings{hilliardCompositionReuseViewpoints2012,
  title = {On the {{Composition}} and {{Reuse}} of {{Viewpoints}} across {{Architecture Frameworks}}},
  booktitle = {2012 {{Joint Working IEEE}}/{{IFIP Conference}} on {{Software Architecture}} and {{European Conference}} on {{Software Architecture}}},
  author = {Hilliard, Rich and Malavolta, Ivano and Muccini, Henry and Pelliccione, Patrizio},
  year = {2012},
  month = aug,
  pages = {131--140},
  publisher = {IEEE},
  address = {Helsinki, Finland},
  doi = {10.1109/WICSA-ECSA.212.21},
  urldate = {2023-12-08},
  abstract = {A central aspect of architecting is architecture description. Architecture descriptions take many forms and serve many purposes throughout the life cycle of development, operation and maintenance activities. The use of multiple views -- diverse representations for distinct audiences and uses -- has been a major tenet of architecture description since the earliest work in software architecture. This tenet has been codified in various ways. Most practising software architects must operate within the confines of a prescribed architecture framework (AF) or architecture description language (ADL) as dictated by their organization or client. Current AFs and ADLs are defined with varying degrees of rigour and offer varying levels of tool support; furthermore, these resources are often closed, making it difficult for the architect to tailor a representational solution to the specific challenges of the project at hand.},
  isbn = {978-1-4673-2809-8 978-0-7695-4827-2},
  langid = {english},
  keywords = {Stakeholders},
}

@article{hilliardViewpointModeling2001,
  title = {Viewpoint {{Modeling}}},
  author = {Hilliard, Rich},
  year = {2001},
  month = mar,
  keywords = {Stakeholders},
}

@inproceedings{hofgenEnhancingModelBasedSystem2024,
  title = {Enhancing {{Model-Based System Architecting Through Formalized Decision Management}}},
  booktitle = {2024 {{IEEE}} 20th {{International Conference}} on {{Automation Science}} and {{Engineering}} ({{CASE}})},
  author = {H{\"o}fgen, Josua and {Vogel-Heuser}, Birgit and Vicaria, Alejandra and Pouzolz, Fran{\c c}ois and Kurzhals, Christian},
  year = {2024},
  month = aug,
  pages = {1053--1060},
  issn = {2161-8089},
  doi = {10.1109/CASE59546.2024.10711329},
  urldate = {2024-12-09},
  abstract = {System architecture decisions are typically informally captured in design documents. This practice leads to a loss of knowledge that impedes later activities like design changes, impact analysis, and reuse. Model-Based Systems Engineering (MBSE) frameworks support the development of increasingly complex systems but must address the problem of capitalization on architectural knowledge. To this end the "Decision Ontology for System Architectures (DOSA)" is developed to provide a formalized data model to capture system architecture decisions. DOSA is developed through a synthesis of decisions observed while developing an architecture model for a preliminary study of a novel satellite navigation system at Airbus Defence and Space. The approach is integrated into an MBSE framework enabling engineers to capture decisions that influence the architecture's characteristics while developing the system model and imminently trace decision to artifacts of the system architecture. Subsequent visual inspection and formal querying of the decision graph facilitates the analysis of made decisions, and their interrelations.},
  keywords = {Atmospheric modeling,Complex systems,Computer aided software engineering,Data models,Decision Management,Inspection,Knowledge engineering,MBSE,Ontologies,Ontology,Satellite navigation systems,System Architecture,Systems architecture,Visualization},
  annotation = {Read\_Status: Read\\
Read\_Status\_Date: 2024-12-09T17:44:27.815Z},
}

@article{hoganKnowledgeGraphs2022,
  title = {Knowledge {{Graphs}}},
  author = {Hogan, Aidan and Blomqvist, Eva and Cochez, Michael and D'amato, Claudia and Melo, Gerard De and Gutierrez, Claudio and Kirrane, Sabrina and Gayo, Jos{\'e} Emilio Labra and Navigli, Roberto and Neumaier, Sebastian and Ngomo, Axel-Cyrille Ngonga and Polleres, Axel and Rashid, Sabbir M. and Rula, Anisa and Schmelzeisen, Lukas and Sequeda, Juan and Staab, Steffen and Zimmermann, Antoine},
  year = {2022},
  month = may,
  journal = {ACM Computing Surveys},
  volume = {54},
  number = {4},
  pages = {1--37},
  issn = {0360-0300, 1557-7341},
  doi = {10.1145/3447772},
  urldate = {2025-01-05},
  abstract = {In this article, we provide a comprehensive introduction to knowledge graphs, which have recently garnered significant attention from both industry and academia in scenarios that require exploiting diverse, dynamic, large-scale collections of data. After some opening remarks, we motivate and contrast various graph-based data models, as well as languages used to query and validate knowledge graphs. We explain how knowledge can be represented and extracted using a combination of deductive and inductive techniques. We conclude with high-level future research directions for knowledge graphs.},
  langid = {english},
}

@misc{hollandDatasetNutritionLabel2018,
  title = {The {{Dataset Nutrition Label}}: {{A Framework To Drive Higher Data Quality Standards}}},
  shorttitle = {The {{Dataset Nutrition Label}}},
  author = {Holland, Sarah and Hosny, Ahmed and Newman, Sarah and Joseph, Joshua and Chmielinski, Kasia},
  year = {2018},
  month = may,
  number = {arXiv:1805.03677},
  eprint = {1805.03677},
  primaryclass = {cs},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/1805.03677},
  urldate = {2024-03-02},
  abstract = {Artificial intelligence (AI) systems built on incomplete or biased data will often exhibit problematic outcomes. Current methods of data analysis, particularly before model development, are costly and not standardized. The Dataset Nutrition Label (the Label) is a diagnostic framework that lowers the barrier to standardized data analysis by providing a distilled yet comprehensive overview of dataset "ingredients" before AI model development. Building a Label that can be applied across domains and data types requires that the framework itself be flexible and adaptable; as such, the Label is comprised of diverse qualitative and quantitative modules generated through multiple statistical and probabilistic modelling backends, but displayed in a standardized format. To demonstrate and advance this concept, we generated and published an open source prototype with seven sample modules on the ProPublica Dollars for Docs dataset. The benefits of the Label are manyfold. For data specialists, the Label will drive more robust data analysis practices, provide an efficient way to select the best dataset for their purposes, and increase the overall quality of AI models as a result of more robust training datasets and the ability to check for issues at the time of model development. For those building and publishing datasets, the Label creates an expectation of explanation, which will drive better data collection practices. We also explore the limitations of the Label, including the challenges of generalizing across diverse datasets, and the risk of using "ground truth" data as a comparison dataset. We discuss ways to move forward given the limitations identified. Lastly, we lay out future directions for the Dataset Nutrition Label project, including research and public policy agendas to further advance consideration of the concept.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computers and Society,Computer Science - Databases},
}

@inproceedings{holmesBusinessApplicationExecution2012,
  title = {From {{Business Application Execution}} to {{Design Through Model-Based Reporting}}},
  booktitle = {2012 {{IEEE}} 16th {{International Enterprise Distributed Object Computing Conference}}},
  author = {Holmes, Taid},
  year = {2012},
  month = sep,
  pages = {143--153},
  publisher = {IEEE},
  address = {Beijing, China},
  doi = {10.1109/EDOC.2012.25},
  urldate = {2023-12-01},
  abstract = {Cross-disciplinary models constitute essential instruments to master complexity. Often it is easier to relate to high-level concepts than to deal with low-level technical details. In model-driven engineering (MDE) models are designated a pivotal role from which systems are generated. As such, MDE enables different stakeholders of business applications to participate in the engineering process. Until now however, MDE does not penetrate phases beyond generation and deployment such as monitoring, analysis, and reporting. To display information from runtime and analytics it would be interesting if reporting could utilize models from design time. Therefore, this paper presents model-based reporting (MbR). Bridging the gap between reporting and design, it enables stakeholders to intuitively specify the reporting through a domain-specific language (DSL) while accelerating development cycles. In nonmodel-driven settings, MbR can help to introduce models as a first step towards MDE.},
  isbn = {978-1-4673-2444-1 978-0-7695-4785-5},
  langid = {english},
}

@article{huangSurveyHallucinationLarge2024,
  title = {A {{Survey}} on {{Hallucination}} in {{Large Language Models}}: {{Principles}}, {{Taxonomy}}, {{Challenges}}, and {{Open Questions}}},
  shorttitle = {A {{Survey}} on {{Hallucination}} in {{Large Language Models}}},
  author = {Huang, Lei and Yu, Weijiang and Ma, Weitao and Zhong, Weihong and Feng, Zhangyin and Wang, Haotian and Chen, Qianglong and Peng, Weihua and Feng, Xiaocheng and Qin, Bing and Liu, Ting},
  year = {2024},
  month = nov,
  journal = {ACM Transactions on Information Systems},
  pages = {3703155},
  issn = {1046-8188, 1558-2868},
  doi = {10.1145/3703155},
  urldate = {2024-03-04},
  abstract = {The emergence of large language models (LLMs) has marked a significant breakthrough in natural language processing (NLP), leading to remarkable advancements in text understanding and generation. Nevertheless, alongside these strides, LLMs exhibit a critical tendency to produce hallucinations, resulting in content that is inconsistent with real-world facts or user inputs. This phenomenon poses substantial challenges to their practical deployment and raises concerns over the reliability of LLMs in real-world scenarios, which attracts increasing attention to detect and mitigate these hallucinations. In this survey, we aim to provide a thorough and in-depth overview of recent advances in the field of LLM hallucinations. We begin with an innovative taxonomy of LLM hallucinations, then delve into the factors contributing to hallucinations. Subsequently, we present a comprehensive overview of hallucination detection methods and benchmarks. Additionally, representative approaches designed to mitigate hallucinations are introduced accordingly. Finally, we analyze the challenges that highlight the current limitations and formulate open questions, aiming to delineate pathways for future research on hallucinations in LLMs.},
  langid = {english},
  keywords = {Computer Science - Computation and Language},
}

@misc{hudsonGQANewDataset2019,
  title = {{{GQA}}: {{A New Dataset}} for {{Real-World Visual Reasoning}} and {{Compositional Question Answering}}},
  shorttitle = {{{GQA}}},
  author = {Hudson, Drew A. and Manning, Christopher D.},
  year = {2019},
  month = may,
  publisher = {arXiv},
  doi = {10.48550/arXiv.1902.09506},
  urldate = {2024-07-10},
  abstract = {We introduce GQA, a new dataset for real-world visual reasoning and compositional question answering, seeking to address key shortcomings of previous VQA datasets. We have developed a strong and robust question engine that leverages Visual Genome scene graph structures to create 22M diverse reasoning questions, which all come with functional programs that represent their semantics. We use the programs to gain tight control over the answer distribution and present a new tunable smoothing technique to mitigate question biases. Accompanying the dataset is a suite of new metrics that evaluate essential qualities such as consistency, grounding and plausibility. A careful analysis is performed for baselines as well as state-of-the-art models, providing fine-grained results for different question types and topologies. Whereas a blind LSTM obtains a mere 42.1\%, and strong VQA models achieve 54.1\%, human performance tops at 89.3\%, offering ample opportunity for new research to explore. We hope GQA will provide an enabling resource for the next generation of models with enhanced robustness, improved consistency, and deeper semantic understanding of vision and language.},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning},
}

@misc{huLoRALowRankAdaptation2021,
  title = {{{LoRA}}: {{Low-Rank Adaptation}} of {{Large Language Models}}},
  shorttitle = {{{LoRA}}},
  author = {Hu, Edward J. and Shen, Yelong and Wallis, Phillip and {Allen-Zhu}, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu},
  year = {2021},
  month = oct,
  number = {arXiv:2106.09685},
  eprint = {2106.09685},
  primaryclass = {cs},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/2106.09685},
  urldate = {2024-03-09},
  abstract = {An important paradigm of natural language processing consists of large-scale pre-training on general domain data and adaptation to particular tasks or domains. As we pre-train larger models, full fine-tuning, which retrains all model parameters, becomes less feasible. Using GPT-3 175B as an example -- deploying independent instances of fine-tuned models, each with 175B parameters, is prohibitively expensive. We propose Low-Rank Adaptation, or LoRA, which freezes the pre-trained model weights and injects trainable rank decomposition matrices into each layer of the Transformer architecture, greatly reducing the number of trainable parameters for downstream tasks. Compared to GPT-3 175B fine-tuned with Adam, LoRA can reduce the number of trainable parameters by 10,000 times and the GPU memory requirement by 3 times. LoRA performs on-par or better than fine-tuning in model quality on RoBERTa, DeBERTa, GPT-2, and GPT-3, despite having fewer trainable parameters, a higher training throughput, and, unlike adapters, no additional inference latency. We also provide an empirical investigation into rank-deficiency in language model adaptation, which sheds light on the efficacy of LoRA. We release a package that facilitates the integration of LoRA with PyTorch models and provide our implementations and model checkpoints for RoBERTa, DeBERTa, and GPT-2 at https://github.com/microsoft/LoRA.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},
}

@misc{hwangSyntacticQuestionAbstraction2020,
  title = {Syntactic {{Question Abstraction}} and {{Retrieval}} for {{Data-Scarce Semantic Parsing}}},
  author = {Hwang, Wonseok and Yim, Jinyeong and Park, Seunghyun and Seo, Minjoon},
  year = {2020},
  month = may,
  number = {arXiv:2005.00644},
  eprint = {2005.00644},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2005.00644},
  urldate = {2024-11-22},
  abstract = {Deep learning approaches to semantic parsing require a large amount of labeled data, but annotating complex logical forms is costly. Here, we propose Syntactic Question Abstraction and Retrieval (SQAR), a method to build a neural semantic parser that translates a natural language (NL) query to a SQL logical form (LF) with less than 1,000 annotated examples. SQAR first retrieves a logical pattern from the train data by computing the similarity between NL queries and then grounds a lexical information on the retrieved pattern in order to generate the final LF. We validate SQAR by training models using various small subsets of WikiSQL train data achieving up to 4.9\% higher LF accuracy compared to the previous state-of-the-art models on WikiSQL test set. We also show that by using query-similarity to retrieve logical pattern, SQAR can leverage a paraphrasing dataset achieving up to 5.9\% higher LF accuracy compared to the case where SQAR is trained by using only WikiSQL data. In contrast to a simple pattern classification approach, SQAR can generate unseen logical patterns upon the addition of new examples without re-training the model. We also discuss an ideal way to create cost efficient and robust train datasets when the data distribution can be approximated under a data-hungry setting.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning},
}

@article{imanReviewDeepTransfer2023,
  title = {A {{Review}} of {{Deep Transfer Learning}} and {{Recent Advancements}}},
  author = {Iman, Mohammadreza and Arabnia, Hamid Reza and Rasheed, Khaled},
  year = {2023},
  month = apr,
  journal = {Technologies},
  volume = {11},
  number = {2},
  pages = {40},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2227-7080},
  doi = {10.3390/technologies11020040},
  urldate = {2024-11-22},
  abstract = {Deep learning has been the answer to many machine learning problems during the past two decades. However, it comes with two significant constraints: dependency on extensive labeled data and training costs. Transfer learning in deep learning, known as Deep Transfer Learning (DTL), attempts to reduce such reliance and costs by reusing obtained knowledge from a source data/task in training on a target data/task. Most applied DTL techniques are network/model-based approaches. These methods reduce the dependency of deep learning models on extensive training data and drastically decrease training costs. Moreover, the training cost reduction makes DTL viable on edge devices with limited resources. Like any new advancement, DTL methods have their own limitations, and a successful transfer depends on specific adjustments and strategies for different scenarios. This paper reviews the concept, definition, and taxonomy of deep transfer learning and well-known methods. It investigates the DTL approaches by reviewing applied DTL techniques in the past five years and a couple of experimental analyses of DTLs to discover the best practice for using DTL in different scenarios. Moreover, the limitations of DTLs (catastrophic forgetting dilemma and overly biased pre-trained models) are discussed, along with possible solutions and research trends.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {deep learning,deep transfer learning,machine learning,progressive learning,transfer learning},
}

@article{jiangSurveySemanticParsing2024,
  title = {A {{Survey}} of {{Semantic Parsing Techniques}}},
  author = {Jiang, Peng and Cai, Xiaodong},
  year = {2024},
  month = sep,
  journal = {Symmetry},
  volume = {16},
  number = {9},
  pages = {1201},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2073-8994},
  doi = {10.3390/sym16091201},
  urldate = {2024-11-22},
  abstract = {In the information age, semantic parsing technology drives efficiency improvement and accelerates the process of intelligence. However, it faces complex understanding, data inflation, inappropriate evaluation, and difficult application of advanced large models. This study analyses the current challenges and looks forward to the development trend of the technology. Specific approaches include: this study adopts a systematic review method and strictly follows the PRISMA framework, deeply analyzes the key ideas, methods, problems, and solutions of traditional and neural network methods, and explores the model performance, API application, dataset, and evaluation mechanism. Through literature analysis, the technology is classified according to its application scenarios. Then, the practical application contributions are summarized, current limitations such as data size, model performance, and resource requirements are analyzed, and future directions such as dataset expansion, real-time performance enhancement, and industrial applications are envisioned. The results of the study show significant advances in semantic parsing technology with far-reaching impacts. Traditional and neural network methods complement each other to promote theoretical and practical innovation. In the future, with the continuous progress and in-depth application of machine learning technology, semantic parsing technology needs to further deepen the research on logical reasoning and evaluation, to better cope with technical challenges and lead the new development of natural language processing and AI.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {logical reasoning and evaluation,machine learning,natural language processing,PRISMA,semantic parsing},
}

@misc{jiangUniKGQAUnifiedRetrieval2023,
  title = {{{UniKGQA}}: {{Unified Retrieval}} and {{Reasoning}} for {{Solving Multi-hop Question Answering Over Knowledge Graph}}},
  shorttitle = {{{UniKGQA}}},
  author = {Jiang, Jinhao and Zhou, Kun and Zhao, Wayne Xin and Wen, Ji-Rong},
  year = {2023},
  month = mar,
  number = {arXiv:2212.00959},
  eprint = {2212.00959},
  primaryclass = {cs},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/2212.00959},
  urldate = {2024-07-10},
  abstract = {Multi-hop Question Answering over Knowledge Graph (KGQA) aims to find the answer entities that are multiple hops away from the topic entities mentioned in a natural language question on a large-scale Knowledge Graph (KG). To cope with the vast search space, existing work usually adopts a two-stage approach: it first retrieves a relatively small subgraph related to the question and then performs the reasoning on the subgraph to find the answer entities accurately. Although these two stages are highly related, previous work employs very different technical solutions for developing the retrieval and reasoning models, neglecting their relatedness in task essence. In this paper, we propose UniKGQA, a novel approach for multi-hop KGQA task, by unifying retrieval and reasoning in both model architecture and parameter learning. For model architecture, UniKGQA consists of a semantic matching module based on a pre-trained language model (PLM) for question-relation semantic matching, and a matching information propagation module to propagate the matching information along the directed edges on KGs. For parameter learning, we design a shared pre-training task based on questionrelation matching for both retrieval and reasoning models, and then propose retrieval- and reasoning-oriented fine-tuning strategies. Compared with previous studies, our approach is more unified, tightly relating the retrieval and reasoning stages. Extensive experiments on three benchmark datasets have demonstrated the effectiveness of our method on the multi-hop KGQA task. Our codes and data are publicly available at https://github.com/RUCAIBox/UniKGQA.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computation and Language},
}

@misc{jikadaraLangGraphComprehensiveGuide2024,
  title = {{{LangGraph}}: {{A Comprehensive Guide}} for {{Beginners}}},
  shorttitle = {{{LangGraph}}},
  author = {Jikadara, Bhavik},
  year = {2024},
  month = may,
  journal = {Medium},
  url = {https://bhavikjikadara.medium.com/langgraph-a-comprehensive-guide-for-beginners-ef17d3dd5383},
  urldate = {2024-08-17},
  abstract = {LangGraph is a library for building stateful, multi-actor applications with LLMs. It extends the LangChain Expression Language with the{\dots}},
  langid = {english},
}

@misc{jingDependencyParsingNeural2021,
  title = {Dependency Parsing with Neural Networks},
  author = {Jing, Jesse},
  year = {2021},
  month = nov,
  journal = {Medium},
  url = {https://medium.com/@chengjing/dependency-parsing-with-neural-networks-e36f5166628d},
  urldate = {2024-08-29},
  abstract = {What's dependency parsing and how to parse sentences with neural networks?},
  langid = {english},
  keywords = {Parsing},
}

@inproceedings{joshiNaturalLanguageInteractive2020,
  title = {A {{Natural Language}} and {{Interactive End-to-End Querying}} and {{Reporting System}}},
  booktitle = {Proceedings of the 7th {{ACM IKDD CoDS}} and 25th {{COMAD}}},
  author = {Joshi, Salil Rajeev and Venkatesh, Bharath and Thomas, Dawn and Jiao, Yue and Roy, Shourya},
  year = {2020},
  month = jan,
  pages = {261--267},
  publisher = {ACM},
  address = {Hyderabad India},
  doi = {10.1145/3371158.3371198},
  urldate = {2024-03-05},
  isbn = {978-1-4503-7738-6},
  langid = {english},
}

@misc{kamathSurveySemanticParsing2019,
  title = {A {{Survey}} on {{Semantic Parsing}}},
  author = {Kamath, Aishwarya and Das, Rajarshi},
  year = {2019},
  month = may,
  number = {arXiv:1812.00978},
  eprint = {1812.00978},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1812.00978},
  urldate = {2024-01-27},
  abstract = {A significant amount of information in today's world is stored in structured and semi-structured knowledge bases. Efficient and simple methods to query them are essential and must not be restricted to only those who have expertise in formal query languages. The field of semantic parsing deals with converting natural language utterances to logical forms that can be easily executed on a knowledge base. In this survey, we examine the various components of a semantic parsing system and discuss prominent work ranging from the initial rule based methods to the current neural approaches to program synthesis. We also discuss methods that operate using varying levels of supervision and highlight the key challenges involved in the learning of such systems.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computation and Language},
}

@article{kandBridgingGapIEEE2002,
  title = {Bridging the Gap between {{IEEE}} 1471, an Architecture Description Language, and {{UML}}},
  author = {Kand{\dbend}, Mohamed M. and Crettaz, Valentin and Strohmeier, Alfred and Sendall, Shane},
  year = {2002},
  month = dec,
  journal = {Software and Systems Modeling},
  volume = {1},
  number = {2},
  pages = {113--129},
  issn = {1619-1366, 1619-1374},
  doi = {10.1007/s10270-002-0010-x},
  urldate = {2023-12-08},
  abstract = {A lot of attention has been paid to software architecture issues in academia, industrial research and standardization organizations working in the software area. The software architecture research community has focused on the creation and improvement of specialpurpose languages: architecture description languages (ADLs). However, ADLs lack adequate support for separating various kinds of stakeholders' concerns along different viewpoints. But also, they do not address the difference between the architecture of a software system and its representations. In contrast, ANSI/IEEE-Std1471 makes a clear distinction between the architecture and the architectural description of a software system.},
  langid = {english},
  keywords = {Stakeholders},
}

@article{karbanJPLSystemsEnvironment2020,
  title = {The {{JPL Systems Environment}}},
  author = {Karban, Robert and Piette, Marie and Brower, Eric and Gomes, Ivan and Bovre, Emilee and Lattimore, Myra and Carr, John and Harris, Chad and Delp, Christopher and Lee, Cin-Young},
  year = {2020},
  abstract = {The Jet Propulsion Laboratory (JPL) carries out a wide range of robotic space missions that require an immense interdisciplinary engineering effort.},
  langid = {english},
}

@inproceedings{kazemnejadParaphraseGenerationLearning2020,
  title = {Paraphrase {{Generation}} by {{Learning How}} to {{Edit}} from {{Samples}}},
  booktitle = {Proceedings of the 58th {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}}},
  author = {Kazemnejad, Amirhossein and Salehi, Mohammadreza and Soleymani Baghshah, Mahdieh},
  editor = {Jurafsky, Dan and Chai, Joyce and Schluter, Natalie and Tetreault, Joel},
  year = {2020},
  month = jul,
  pages = {6010--6021},
  publisher = {Association for Computational Linguistics},
  address = {Online},
  doi = {10.18653/v1/2020.acl-main.535},
  urldate = {2024-05-23},
  abstract = {Neural sequence to sequence text generation has been proved to be a viable approach to paraphrase generation. Despite promising results, paraphrases generated by these models mostly suffer from lack of quality and diversity. To address these problems, we propose a novel retrieval-based method for paraphrase generation. Our model first retrieves a paraphrase pair similar to the input sentence from a pre-defined index. With its novel editor module, the model then paraphrases the input sequence by editing it using the extracted relations between the retrieved pair of sentences. In order to have fine-grained control over the editing process, our model uses the newly introduced concept of Micro Edit Vectors. It both extracts and exploits these vectors using the attention mechanism in the Transformer architecture. Experimental results show the superiority of our paraphrase generation method in terms of both automatic metrics, and human evaluation of relevance, grammaticality, and diversity of generated paraphrases.},
}

@misc{khramtsovaLeveragingLLMsUnsupervised2024,
  title = {Leveraging {{LLMs}} for {{Unsupervised Dense Retriever Ranking}}},
  author = {Khramtsova, Ekaterina and Zhuang, Shengyao and Baktashmotlagh, Mahsa and Zuccon, Guido},
  year = {2024},
  month = feb,
  number = {arXiv:2402.04853},
  eprint = {2402.04853},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2402.04853},
  urldate = {2024-02-29},
  abstract = {This paper introduces a novel unsupervised technique that utilizes large language models (LLMs) to determine the most suitable dense retriever for a specific test(target) corpus. Selecting the appropriate dense retriever is vital for numerous IR applications that employ these retrievers, trained on public datasets, to encode or conduct searches within a new private target corpus. The effectiveness of a dense retriever can significantly diminish when applied to a target corpus that diverges in domain or task from the original training set. The problem becomes more pronounced in cases where the target corpus is unlabeled, e.g. in zero-shot scenarios, rendering direct evaluation of the model's effectiveness on the target corpus unattainable. Therefore, the unsupervised selection of an optimally pre-trained dense retriever, especially under conditions of domain shift, emerges as a critical challenge. Existing methodologies for ranking dense retrievers fall short in addressing these domain shift scenarios. To tackle this, our method capitalizes on LLMs to create pseudo-relevant queries, labels, and reference lists by analyzing a subset of documents from the target corpus. This allows for the ranking of dense retrievers based on their performance with these pseudo-relevant signals. Significantly, this strategy is the first to depend exclusively on the target corpus data, removing the necessity for training data and test labels. We assessed the effectiveness of our approach by compiling a comprehensive pool of cutting-edge dense retrievers and comparing our method against traditional dense retriever selection benchmarks. The findings reveal that our proposed solution surpasses the existing benchmarks in both the selection and ranking of dense retrievers.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Information Retrieval},
}

@misc{kimPureTransformersAre2022,
  title = {Pure {{Transformers}} Are {{Powerful Graph Learners}}},
  author = {Kim, Jinwoo and Nguyen, Tien Dat and Min, Seonwoo and Cho, Sungjun and Lee, Moontae and Lee, Honglak and Hong, Seunghoon},
  year = {2022},
  month = oct,
  number = {arXiv:2207.02505},
  eprint = {2207.02505},
  primaryclass = {cs},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/2207.02505},
  urldate = {2024-08-20},
  abstract = {We show that standard Transformers without graph-specific modifications can lead to promising results in graph learning both in theory and practice. Given a graph, we simply treat all nodes and edges as independent tokens, augment them with token embeddings, and feed them to a Transformer. With an appropriate choice of token embeddings, we prove that this approach is theoretically at least as expressive as an invariant graph network (2-IGN) composed of equivariant linear layers, which is already more expressive than all message-passing Graph Neural Networks (GNN). When trained on a large-scale graph dataset (PCQM4Mv2), our method coined Tokenized Graph Transformer (TokenGT) achieves significantly better results compared to GNN baselines and competitive results compared to Transformer variants with sophisticated graph-specific inductive bias. Our implementation is available at https://github.com/jw9730/tokengt.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning},
}

@techreport{klyneResourceDescriptionFramework2004,
  type = {{{W3C Recommendation}}},
  title = {Resource {{Description Framework}} ({{RDF}}): {{Concepts}} and {{Abstract Syntax}}},
  author = {Klyne, Graham and Carroll, Jeremy J.},
  editor = {McBride, Brian},
  year = {2004},
  month = feb,
  number = {10 February 2004},
  institution = {W3C},
  url = {https://www.w3.org/2001/sw/RDFCore/TR/WD-rdf-concepts-20030117/},
  urldate = {2024-12-03},
  copyright = {Copyright {\copyright} 2004 W3C (MIT, ERCIM, Keio), All Rights Reserved.},
}

@misc{KnowledgeDistillationLLM,
  title = {Knowledge {{Distillation}} of {{LLM}} for {{Education}}},
  url = {https://arxiv.org/html/2312.15842v1},
  urldate = {2024-08-05},
  keywords = {Teacher student},
}

@article{kolkSustainabilityReporting2005,
  title = {Sustainability {{Reporting}}},
  author = {Kolk, Ann},
  year = {2005},
  journal = {VBA Journaal},
  volume = {21},
  number = {3},
  pages = {34--42},
  abstract = {This article gives an overview of developments in sustainability (also sometimes labelled corporate social responsibility) reporting. The article will first briefly indicate how accountability on social and environmental issues started, already in the 1970s when social reports were published. Subsequently, more detailed trends and their peculiarities are given for the period from the early 1990s onwards, based on longitudinal research in which the author has been involved. In addition to data on the extent of sustainability reporting, some attention will also be paid to (regulatory) drivers and motivations for reporting as well as trends in report types and contents. The final section briefly discusses sustainability reporting in the financial sector where interesting developments have taken place in recent years.},
}

@article{koningMethodDefiningIEEE2006,
  title = {A Method for Defining {{IEEE Std}} 1471 Viewpoints},
  author = {Koning, Henk and Van Vliet, Hans},
  year = {2006},
  month = jan,
  journal = {Journal of Systems and Software},
  volume = {79},
  number = {1},
  pages = {120--131},
  issn = {01641212},
  doi = {10.1016/j.jss.2005.02.023},
  urldate = {2023-12-08},
  abstract = {With the growing impact of information technology the proper understanding of IT-architecture designs is becoming ever more important. Much debate has been going on about how to describe them. In 2000, the IEEE Std 1471 proposed a model of an architecture description and its context.},
  langid = {english},
  keywords = {Stakeholders},
}

@inproceedings{kouagouUniversalKnowledgeGraph2024,
  title = {Universal {{Knowledge Graph Embeddings}}},
  booktitle = {Companion {{Proceedings}} of the {{ACM}} on {{Web Conference}} 2024},
  author = {Kouagou, N'Dah Jean and Demir, Caglar and Zahera, Hamada M. and Wilke, Adrian and Heindorf, Stefan and Li, Jiayi and Ngomo, Axel-Cyrille Ngonga},
  year = {2024},
  month = may,
  eprint = {2310.14899},
  primaryclass = {cs},
  pages = {1793--1797},
  doi = {10.1145/3589335.3651978},
  urldate = {2024-08-20},
  abstract = {A variety of knowledge graph embedding approaches have been developed. Most of them obtain embeddings by learning the structure of the knowledge graph within a link prediction setting. As a result, the embeddings reflect only the structure of a single knowledge graph, and embeddings for different knowledge graphs are not aligned, e.g., they cannot be used to find similar entities across knowledge graphs via nearest neighbor search. However, knowledge graph embedding applications such as entity disambiguation require a more global representation, i.e., a representation that is valid across multiple sources. We propose to learn universal knowledge graph embeddings from large-scale interlinked knowledge sources. To this end, we fuse large knowledge graphs based on the owl:sameAs relation such that every entity is represented by a unique identity. We instantiate our idea by computing universal embeddings based on DBpedia and Wikidata yielding embeddings for about 180 million entities, 15 thousand relations, and 1.2 billion triples. We believe our computed embeddings will support the emerging field of graph foundation models. Moreover, we develop a convenient API to provide embeddings as a service. Experiments on link prediction suggest that universal knowledge graph embeddings encode better semantics compared to embeddings computed on a single knowledge graph. For reproducibility purposes, we provide our source code and datasets open access.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence},
}

@article{koutraAlgorithmsGraphSimilarity,
  title = {Algorithms for {{Graph Similarity}} and {{Subgraph Matching}}},
  author = {Koutra, Danai and Parikh, Ankur and Ramdas, Aaditya and Xiang, Jing},
  abstract = {We deal with two independent but related problems, those of graph similarity and subgraph matching, which are both important practical problems useful in several fields of science, engineering and data analysis. For the problem of graph similarity, we develop and test a new framework for solving the problem using belief propagation and related ideas. For the subgraph matching problem, we develop a new algorithm based on existing techniques in the bioinformatics and data mining literature, which uncover periodic or infrequent matchings. We make substantial progress compared to the existing methods for both problems.},
  langid = {english},
}

@article{kuhnSurveyClassificationControlled2014,
  title = {A {{Survey}} and {{Classification}} of {{Controlled Natural Languages}}},
  author = {Kuhn, Tobias},
  year = {2014},
  month = mar,
  journal = {Computational Linguistics},
  volume = {40},
  number = {1},
  pages = {121--170},
  issn = {0891-2017, 1530-9312},
  doi = {10.1162/COLI_a_00168},
  urldate = {2024-04-06},
  abstract = {What is here called controlled natural language (CNL) has traditionally been given many different names. Especially during the last four decades, a wide variety of such languages have been designed. They are applied to improve communication among humans, to improve translation, or to provide natural and intuitive representations for formal notations. Despite the apparent differences, it seems sensible to put all these languages under the same umbrella. To bring order to the variety of languages, a general classification scheme is presented here. A comprehensive survey of existing English-based CNLs is given, listing and describing 100 languages from 1930 until today. Classification of these languages reveals that they form a single scattered cloud filling the conceptual space between natural languages such as English on the one end and formal languages such as propositional logic on the other. The goal of this article is to provide a common terminology and a common model for CNL, to contribute to the understanding of their general nature, to provide a starting point for researchers interested in the area, and to help developers to make design decisions.},
  langid = {english},
}

@article{kujalaStakeholderEngagementPresent2022,
  title = {Stakeholder {{Engagement}}: {{Past}}, {{Present}}, and {{Future}}},
  shorttitle = {Stakeholder {{Engagement}}},
  author = {Kujala, Johanna and Sachs, Sybille and Leinonen, Heta and Heikkinen, Anna and Laude, Daniel},
  year = {2022},
  month = may,
  journal = {Business \& Society},
  volume = {61},
  number = {5},
  pages = {1136--1196},
  issn = {0007-6503, 1552-4205},
  doi = {10.1177/00076503211066595},
  urldate = {2023-12-01},
  abstract = {Stakeholder engagement has grown into a widely used yet often unclear construct in business and society research. The literature lacks a unified understanding of the essentials of stakeholder engagement, and the fragmented use of the stakeholder engagement construct challenges its development and legitimacy. The purpose of this article is to clarify the construct of stakeholder engagement to unfold the full potential of stakeholder engagement research. We conduct a literature review on 90 articles in leading academic journals focusing on stakeholder engagement in the business and society, management and strategy, and environmental management and environmental policy literatures. We present a descriptive analysis of stakeholder engagement research for a 15year period, and we identify the moral, strategic, and pragmatic components of stakeholder engagement as well as its aims, activities, and impacts. Moreover, we offer an inclusive stakeholder engagement definition and provide a guide to organizing the research. Finally, we complement the current understanding with a largely overlooked dark side of stakeholder engagement. We conclude with future research avenues for stakeholder engagement research.},
  langid = {english},
}

@article{kumarPuttingHorseCart,
  title = {Putting the {{Horse Before}} the {{Cart}}: {{A Generator-Evaluator Framework}} for {{Question Generation}} from {{Text}}},
  author = {Kumar, Vishwajeet and Ramakrishnan, Ganesh and Li, Yuan-Fang},
  abstract = {Automatic question generation (QG) is a useful yet challenging task in NLP. Recent neural network-based approaches represent the stateof-the-art in this task. In this work, we attempt to strengthen them significantly by adopting a holistic and novel generator-evaluator framework that directly optimizes objectives that reward semantics and structure. The generator is a sequence-to-sequence model that incorporates the structure and semantics of the question being generated. The generator predicts an answer in the passage that the question can pivot on. Employing the copy and coverage mechanisms, it also acknowledges other contextually important (and possibly rare) keywords in the passage that the question needs to conform to, while not redundantly repeating words. The evaluator model evaluates and assigns a reward to each predicted question based on its conformity to the structure of ground-truth questions. We propose two novel QG-specific reward functions for text conformity and answer conformity of the generated question. The evaluator also employs structure-sensitive rewards based on evaluation measures such as BLEU, GLEU, and ROUGE-L, which are suitable for QG. In contrast, most of the previous works only optimize the cross-entropy loss, which can induce inconsistencies between training (objective) and testing (evaluation) measures. Our evaluation shows that our approach significantly outperforms state-of-the-art systems on the widelyused SQuAD benchmark as per both automatic and human evaluation.},
  langid = {english},
}

@article{kybartasSurveyStoryGeneration2017,
  title = {A {{Survey}} on {{Story Generation Techniques}} for {{Authoring Computational Narratives}}},
  author = {Kybartas, Ben and Bidarra, Rafael},
  year = {2017},
  month = sep,
  journal = {IEEE Transactions on Computational Intelligence and AI in Games},
  volume = {9},
  number = {3},
  pages = {239--253},
  issn = {1943-068X, 1943-0698},
  doi = {10.1109/TCIAIG.2016.2546063},
  urldate = {2024-01-25},
  abstract = {Computers are often used as tools to design, implement, and even visualize a variety of narrative forms. Many researchers and artists are now further attempting to engage the computer actively throughout the development of the narrative itself. Any form of computational narrative authoring is at some level always mixed-initiative, meaning that the processing capabilities of the computer are utilized with a varying degree to automate certain features of the authoring process. We structure this survey by focusing on two key components of stories, plot and space, and more specifically the degree to which these are either automated by the computer or authored manually. By examining the successes of existing research, we identify potential new research directions in the field of computational narrative. We also identify the advantages of developing a standard model of narrative to allow for collaboration between plot and space automation techniques. This would likely benefit the field of automated space generation with the strengths in the field of automated plot generation.},
  langid = {english},
  keywords = {Formalizing model reporting,Narative generation},
}

@misc{LearnMinutesFinding,
  title = {Learn in 5 {{Minutes}}: {{Finding Nearest Neighbor}} Using {{MinHash}} - {{YouTube}}},
  url = {https://www.youtube.com/watch?v=GRHsg0d5X8Y},
  urldate = {2024-08-17}
}

@incollection{lehmannLanguageModelsControlled2023,
  title = {Language {{Models}} as {{Controlled Natural Language Semantic Parsers}} for {{Knowledge Graph Question Answering}}},
  booktitle = {Frontiers in {{Artificial Intelligence}} and {{Applications}}},
  author = {Lehmann, Jens and Gattogi, Preetam and Bhandiwad, Dhananjay and Ferr{\'e}, S{\'e}bastien and Vahdati, Sahar},
  editor = {Gal, Kobi and Now{\'e}, Ann and Nalepa, Grzegorz J. and Fairstein, Roy and R{\u a}dulescu, Roxana},
  year = {2023},
  month = sep,
  pages = {1348--1356},
  publisher = {IOS Press},
  address = {Krakow (Cracovie), Poland},
  doi = {10.3233/FAIA230411},
  urldate = {2023-12-01},
  abstract = {We propose the use of controlled natural language as a target for knowledge graph question answering (KGQA) semantic parsing via language models as opposed to using formal query languages directly. Controlled natural languages are close to (human) natural languages, but can be unambiguously translated into a formal language such as SPARQL. Our research hypothesis is that the pretraining of large language models (LLMs) on vast amounts of textual data leads to the ability to parse into controlled natural language for KGQA with limited training data requirements. We devise an LLMspecific approach for semantic parsing to study this hypothesis. To conduct our study, we created a dataset that allows the comparison of one formal and two different controlled natural languages. Our analysis shows that training data requirements are indeed substantially reduced when using controlled natural languages, which is relevant since collecting and maintaining high-quality KGQA semantic parsing training data is very expensive and time-consuming.},
  isbn = {978-1-64368-437-6},
  langid = {english},
  keywords = {KBQA},
  annotation = {Read\_Status: Read\\
Read\_Status\_Date: 2024-12-04T12:14:05.395Z},
}

@incollection{lehmannLargeLanguageModels2024,
  title = {Large {{Language Models}} for {{Scientific Question Answering}}: {{An Extensive Analysis}} of the {{SciQA Benchmark}}},
  shorttitle = {Large {{Language Models}} for {{Scientific Question Answering}}},
  booktitle = {The {{Semantic Web}}},
  author = {Lehmann, Jens and Meloni, Antonello and Motta, Enrico and Osborne, Francesco and Recupero, Diego Reforgiato and Salatino, Angelo Antonio and Vahdati, Sahar},
  editor = {Mero{\~n}o Pe{\~n}uela, Albert and Dimou, Anastasia and Troncy, Rapha{\"e}l and Hartig, Olaf and Acosta, Maribel and Alam, Mehwish and Paulheim, Heiko and Lisena, Pasquale},
  year = {2024},
  volume = {14664},
  pages = {199--217},
  publisher = {Springer Nature Switzerland},
  address = {Cham},
  doi = {10.1007/978-3-031-60626-7_11},
  urldate = {2024-12-10},
  abstract = {The SciQA benchmark for scientific question answering aims to represent a challenging task for next-generation question-answering systems on which vanilla large language models fail. In this article, we provide an analysis of the performance of language models on this benchmark including prompting and fine-tuning techniques to adapt them to the SciQA task. We show that both fine-tuning and prompting techniques with intelligent few-shot selection allow us to obtain excellent results on the SciQA benchmark. We discuss the valuable lessons and common error categories, and outline their implications on how to optimise large language models for question answering over knowledge graphs.},
  isbn = {978-3-031-60626-7},
  langid = {english},
  annotation = {Read\_Status: Read\\
Read\_Status\_Date: 2024-12-13T10:46:46.733Z},
}

@misc{leoSemanticTextualSimilarity2023,
  title = {Semantic {{Textual Similarity}}},
  author = {Leo, Marie Stephen},
  year = {2023},
  month = may,
  journal = {Medium},
  url = {https://towardsdatascience.com/semantic-textual-similarity-83b3ca4a840e},
  urldate = {2024-01-29},
  abstract = {From Jaccard to OpenAI, implement the best NLP algorithm for your semantic textual similarity projects},
  langid = {english},
}

@inproceedings{lewisRetrievalAugmentedGenerationKnowledgeIntensive2020,
  title = {Retrieval-{{Augmented Generation}} for {{Knowledge-Intensive NLP Tasks}}},
  booktitle = {Proceedings of the 34th {{International Conference}} on {{Neural Information Processing Systems}}},
  author = {Lewis, Patrick and Perez, Ethan and Piktus, Aleksandra and Petroni, Fabio and Karpukhin, Vladimir and Goyal, Naman and K{\"u}ttler, Heinrich and Lewis, Mike and Yih, Wen-tau and Rockt{\"a}schel, Tim and Riedel, Sebastian and Kiela, Douwe},
  year = {2020},
  month = dec,
  series = {{{NIPS}} '20},
  pages = {9459--9474},
  publisher = {Curran Associates Inc.},
  address = {Red Hook, NY, USA},
  urldate = {2024-08-26},
  abstract = {Large pre-trained language models have been shown to store factual knowledge in their parameters, and achieve state-of-the-art results when fine-tuned on downstream NLP tasks. However, their ability to access and precisely manipulate knowledge is still limited, and hence on knowledge-intensive tasks, their performance lags behind task-specific architectures. Additionally, providing provenance for their decisions and updating their world knowledge remain open research problems. Pre-trained models with a differentiable access mechanism to explicit non-parametric memory can overcome this issue, but have so far been only investigated for extractive downstream tasks. We explore a general-purpose fine-tuning recipe for retrieval-augmented generation (RAG) -- models which combine pre-trained parametric and non-parametric memory for language generation. We introduce RAG models where the parametric memory is a pre-trained seq2seq model and the non-parametric memory is a dense vector index of Wikipedia, accessed with a pre-trained neural retriever. We compare two RAG formulations, one which conditions on the same retrieved passages across the whole generated sequence, the other can use different passages per token. We fine-tune and evaluate our models on a wide range of knowledge-intensive NLP tasks and set the state-of-the-art on three open domain QA tasks, outperforming parametric seq2seq models and task-specific retrieve-and-extract architectures. For language generation tasks, we find that RAG models generate more specific, diverse and factual language than a state-of-the-art parametric-only seq2seq baseline.},
  isbn = {978-1-71382-954-6},
}

@inproceedings{liDomainAdaptationSemantic2020,
  title = {Domain {{Adaptation}} for {{Semantic Parsing}}},
  booktitle = {Proceedings of the {{Twenty-Ninth International Joint Conference}} on {{Artificial Intelligence}}},
  author = {Li, Zechang and Lai, Yuxuan and Feng, Yansong and Zhao, Dongyan},
  year = {2020},
  month = jul,
  pages = {3723--3729},
  publisher = {International Joint Conferences on Artificial Intelligence Organization},
  address = {Yokohama, Japan},
  doi = {10.24963/ijcai.2020/515},
  urldate = {2024-11-22},
  abstract = {Recently, semantic parsing has attracted much attention in the community. Although many neural modeling efforts have greatly improved the performance, it still suffers from the data scarcity issue. In this paper, we propose a novel semantic parser for domain adaptation, where we have much fewer annotated data in the target domain compared to the source domain. Our semantic parser benefits from a two-stage coarse-to-fine framework, thus can provide different and accurate treatments for the two stages, i.e., focusing on domain invariant and domain specific information, respectively. In the coarse stage, our novel domain discrimination component and domain relevance attention encourage the model to learn transferable domain general structures. In the fine stage, the model is guided to concentrate on domain related details. Experiments on a benchmark dataset show that our method consistently outperforms several popular domain adaptation strategies.  Additionally, we show that our model can well exploit limited target data to capture the difference between the source and target domain, even when the target domain has far fewer training instances.},
  isbn = {978-0-9992411-6-5},
  langid = {english},
  annotation = {Read\_Status: To Read\\
Read\_Status\_Date: 2024-11-22T15:23:53.017Z},
}

@misc{liEfficientOnePassEndtoEnd2020,
  title = {Efficient {{One-Pass End-to-End Entity Linking}} for {{Questions}}},
  author = {Li, Belinda Z. and Min, Sewon and Iyer, Srinivasan and Mehdad, Yashar and Yih, Wen-tau},
  year = {2020},
  month = oct,
  number = {arXiv:2010.02413},
  eprint = {2010.02413},
  primaryclass = {cs},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/2010.02413},
  urldate = {2024-05-27},
  abstract = {We present ELQ, a fast end-to-end entity linking model for questions, which uses a biencoder to jointly perform mention detection and linking in one pass. Evaluated on WebQSP and GraphQuestions with extended annotations that cover multiple entities per question, ELQ outperforms the previous state of the art by a large margin of +12.7\% and +19.6\% F1, respectively. With a very fast inference time (1.57 examples/s on a single CPU), ELQ can be useful for downstream question answering systems. In a proof-of-concept experiment, we demonstrate that using ELQ significantly improves the downstream QA performance of GraphRetriever (arXiv:1911.03868). Code and data available at https://github.com/facebookresearch/BLINK/tree/master/elq},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
}

@phdthesis{likincsimonromeroHyperspaceGraphConnected2005,
  title = {The Hyperspace Graph of Connected Subgraphs},
  author = {{Likin C Simon Romero}},
  year = {2005},
  month = aug,
  doi = {10.33915/etd.2321},
  urldate = {2024-07-10},
  langid = {english},
  school = {West Virginia University Libraries},
}

@article{likincsimonromeroUniquenessHyperspaceGraph2007,
  title = {Uniqueness of the {{Hyperspace Graph}} of {{Connected Subgraphs}}},
  author = {{Likin C Simon Romero}},
  year = {2007},
  journal = {Topology Proceedings},
  volume = {31},
  pages = {283--294},
  abstract = {An analogous concept for hyperspace of continua can be defined in abstract graph theory. Given a connected graph G, the hyperspace graph of connected subgraphs, denoted by C(G), is defined with the set of all connected nonempty subgraphs of G as the vertex set of C(G). In this paper, it is shown that given G and G{$\prime$} connected graphs such that C(G) is isomorphic to C(G{$\prime$}), then G and G{$\prime$} are isomorphic.},
  langid = {english},
}

@article{liNeuralGraphTransfer2022,
  title = {Neural {{Graph Transfer Learning}} in {{Natural Language Processing Tasks}}},
  author = {Li, Irene},
  year = {2022},
  month = apr,
  journal = {Yale Graduate School of Arts and Sciences Dissertations},
  url = {https://elischolar.library.yale.edu/gsas_dissertations/621},
}

@phdthesis{liSemanticParsingLimited2023,
  title = {Semantic {{Parsing}} in {{Limited Resource Conditions}}},
  author = {Li, Zhuang},
  year = {2023},
  month = sep,
  doi = {10.26180/24083265.V1},
  abstract = {This thesis explores challenges in semantic parsing, specifically focusing on scenarios with limited data and computational resources. It offers solutions using techniques like automatic data curation, knowledge transfer, active learning, and continual learning. For tasks with no parallel training data, the thesis proposes generating synthetic training examples from structured database schemas. When there is abundant data in a source domain but limited parallel data in a target domain, knowledge from the source is leveraged to improve parsing in the target domain. For multilingual situations with limited data in the target languages, the thesis introduces a method to adapt parsers using a limited human translation budget. Active learning is applied to select source-language samples for manual translation, maximizing parser performance in the target language. In addition, an alternative method is also proposed to utilize machine translation services, supplemented by human-translated data, to train a more effective parser. When computational resources are limited, a continual learning approach is introduced to minimize training time and computational memory. This maintains the parser's efficiency in previously learned tasks while adapting it to new tasks, mitigating the problem of catastrophic forgetting. Overall, the thesis provides a comprehensive set of methods to improve semantic parsing in resource-constrained conditions.},
  keywords = {Artificial intelligence not elsewhere classified,Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Deep learning,Machine learning not elsewhere classified,Natural language processing},
  annotation = {Read\_Status: Read\\
Read\_Status\_Date: 2024-12-03T18:17:37.986Z},
}

@misc{liSurveyRetrievalAugmentedText2022,
  title = {A {{Survey}} on {{Retrieval-Augmented Text Generation}}},
  author = {Li, Huayang and Su, Yixuan and Cai, Deng and Wang, Yan and Liu, Lemao},
  year = {2022},
  month = feb,
  publisher = {arXiv},
  doi = {10.48550/arXiv.2202.01110},
  urldate = {2024-02-02},
  abstract = {Recently, retrieval-augmented text generation attracted increasing attention of the computational linguistics community. Compared with conventional generation models, retrievalaugmented text generation has remarkable advantages and particularly has achieved state-ofthe-art performance in many NLP tasks. This paper aims to conduct a survey about retrievalaugmented text generation. It firstly highlights the generic paradigm of retrieval-augmented generation, and then it reviews notable approaches according to different tasks including dialogue response generation, machine translation, and other generation tasks. Finally, it points out some promising directions on top of recent methods to facilitate future research.},
  copyright = {Creative Commons Attribution 4.0 International},
  langid = {english},
  keywords = {Computer Science - Computation and Language},
}

@inproceedings{liuCanWeSoft2024,
  title = {Can We {{Soft Prompt LLMs}} for {{Graph Learning Tasks}}?},
  booktitle = {Companion {{Proceedings}} of the {{ACM}} on {{Web Conference}} 2024},
  author = {Liu, Zheyuan and He, Xiaoxin and Tian, Yijun and Chawla, Nitesh V.},
  year = {2024},
  month = may,
  pages = {481--484},
  doi = {10.1145/3589335.3651476},
  urldate = {2024-05-30},
  abstract = {Graph plays an important role in representing complex relationships in real-world applications such as social networks, biological data and citation networks. In recent years, Large Language Models (LLMs) have achieved tremendous success in various domains, which makes applying LLMs to graphs particularly appealing. However, directly applying LLMs to graph modalities presents unique challenges due to the discrepancy and mismatch between the graph and text modalities. Hence, to further investigate LLMs' potential for comprehending graph information, we introduce GraphPrompter, a novel framework designed to align graph information with LLMs via soft prompts. Specifically, GraphPrompter consists of two main components: a graph neural network to encode complex graph information and an LLM that effectively processes textual information. Comprehensive experiments on various benchmark datasets under node classification and link prediction tasks demonstrate the effectiveness of our proposed method. The GraphPrompter framework unveils the substantial capabilities of LLMs as predictors in graph-related tasks, enabling researchers to utilize LLMs across a spectrum of real-world graph scenarios more effectively1.},
  langid = {english},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning},
}

@misc{liuGraphFoundationModels2024,
  title = {Towards {{Graph Foundation Models}}: {{A Survey}} and {{Beyond}}},
  shorttitle = {Towards {{Graph Foundation Models}}},
  author = {Liu, Jiawei and Yang, Cheng and Lu, Zhiyuan and Chen, Junze and Li, Yibo and Zhang, Mengmei and Bai, Ting and Fang, Yuan and Sun, Lichao and Yu, Philip S. and Shi, Chuan},
  year = {2024},
  month = jun,
  number = {arXiv:2310.11829},
  eprint = {2310.11829},
  primaryclass = {cs},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/2310.11829},
  urldate = {2024-08-20},
  abstract = {Foundation models have emerged as critical components in a variety of artificial intelligence applications, and showcase significant success in natural language processing and several other domains. Meanwhile, the field of graph machine learning is witnessing a paradigm transition from shallow methods to more sophisticated deep learning approaches. The capabilities of foundation models to generalize and adapt motivate graph machine learning researchers to discuss the potential of developing a new graph learning paradigm. This paradigm envisions models that are pre-trained on extensive graph data and can be adapted for various graph tasks. Despite this burgeoning interest, there is a noticeable lack of clear definitions and systematic analyses pertaining to this new domain. To this end, this article introduces the concept of Graph Foundation Models (GFMs), and offers an exhaustive explanation of their key characteristics and underlying technologies. We proceed to classify the existing work related to GFMs into three distinct categories, based on their dependence on graph neural networks and large language models. In addition to providing a thorough review of the current state of GFMs, this article also outlooks potential avenues for future research in this rapidly evolving domain.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Machine Learning},
}

@misc{loganivCuttingPromptsParameters2021,
  title = {Cutting {{Down}} on {{Prompts}} and {{Parameters}}: {{Simple Few-Shot Learning}} with {{Language Models}}},
  shorttitle = {Cutting {{Down}} on {{Prompts}} and {{Parameters}}},
  author = {Logan IV, Robert L. and Bala{\v z}evi{\'c}, Ivana and Wallace, Eric and Petroni, Fabio and Singh, Sameer and Riedel, Sebastian},
  year = {2021},
  month = jul,
  number = {arXiv:2106.13353},
  eprint = {2106.13353},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2106.13353},
  urldate = {2024-08-05},
  abstract = {Prompting language models (LMs) with training examples and task descriptions has been seen as critical to recent successes in few-shot learning. In this work, we show that finetuning LMs in the few-shot setting can considerably reduce the need for prompt engineering. In fact, one can use null prompts, prompts that contain neither task-specific templates nor training examples, and achieve competitive accuracy to manually-tuned prompts across a wide range of tasks. While finetuning LMs does introduce new parameters for each downstream task, we show that this memory overhead can be substantially reduced: finetuning only the bias terms can achieve comparable or better accuracy than standard finetuning while only updating 0.1\% of the parameters. All in all, we recommend finetuning LMs for few-shot learning as it is more accurate, robust to different prompts, and can be made nearly as efficient as using frozen LMs.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning,Synthetic data},
}

@misc{longLLMsDrivenSyntheticData2024,
  title = {On {{LLMs-Driven Synthetic Data Generation}}, {{Curation}}, and {{Evaluation}}: {{A Survey}}},
  shorttitle = {On {{LLMs-Driven Synthetic Data Generation}}, {{Curation}}, and {{Evaluation}}},
  author = {Long, Lin and Wang, Rui and Xiao, Ruixuan and Zhao, Junbo and Ding, Xiao and Chen, Gang and Wang, Haobo},
  year = {2024},
  month = jun,
  publisher = {arXiv},
  doi = {10.48550/arXiv.2406.15126},
  copyright = {arXiv.org perpetual, non-exclusive license},
  keywords = {Computation and Language (cs.CL),FOS: Computer and information sciences},
}

@misc{luoReasoningGraphsFaithful2024,
  title = {Reasoning on {{Graphs}}: {{Faithful}} and {{Interpretable Large Language Model Reasoning}}},
  shorttitle = {Reasoning on {{Graphs}}},
  author = {Luo, Linhao and Li, Yuan-Fang and Haffari, Gholamreza and Pan, Shirui},
  year = {2024},
  month = feb,
  publisher = {arXiv},
  doi = {10.48550/arXiv.2310.01061},
  urldate = {2024-03-06},
  abstract = {Large language models (LLMs) have demonstrated impressive reasoning abilities in complex tasks. However, they lack up-to-date knowledge and experience hallucinations during reasoning, which can lead to incorrect reasoning processes and diminish their performance and trustworthiness. Knowledge graphs (KGs), which capture vast amounts of facts in a structured format, offer a reliable source of knowledge for reasoning. Nevertheless, existing KG-based LLM reasoning methods only treat KGs as factual knowledge bases and overlook the importance of their structural information for reasoning. In this paper, we propose a novel method called reasoning on graphs (RoG) that synergizes LLMs with KGs to enable faithful and interpretable reasoning. Specifically, we present a planning-retrieval-reasoning framework, where RoG first generates relation paths grounded by KGs as faithful plans. These plans are then used to retrieve valid reasoning paths from the KGs for LLMs to conduct faithful reasoning. Furthermore, RoG not only distills knowledge from KGs to improve the reasoning ability of LLMs through training but also allows seamless integration with any arbitrary LLMs during inference. Extensive experiments on two benchmark KGQA datasets demonstrate that RoG achieves state-of-the-art performance on KG reasoning tasks and generates faithful and interpretable reasoning results.},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
}

@article{lutfiIntegrationSysMLVirtual2023,
  title = {Integration of {{SysML}} and {{Virtual Reality Environment}}: {{A Ground Based Telescope System Example}}},
  shorttitle = {Integration of {{SysML}} and {{Virtual Reality Environment}}},
  author = {Lutfi, Mostafa and Valerdi, Ricardo},
  year = {2023},
  month = apr,
  journal = {Systems},
  volume = {11},
  number = {4},
  pages = {189},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2079-8954},
  doi = {10.3390/systems11040189},
  urldate = {2024-12-09},
  abstract = {In recent years, Model Based Systems Engineering (MBSE) has continued to develop as a standard for designing, managing, and maintaining increasingly complex systems. Unlike the document centric approach, MBSE puts the model at the heart of system design. Among the various MBSE language development efforts, ``Systems Modeling Language (SysML)'', is the most anticipated and broadly utilized in the research and in industrial practice. SysML originated from Unified Modeling Language (UML) and follows the Object-Oriented Systems Engineering Method (OOSEM). SysML diagrams help users create various systems engineering artifacts, including requirements, use cases, operational concepts, system architecture, system behaviors, and parametric analyses of a system model. In the early days of implementation, MBSE languages, including SysML, typically relied on static viewpoints and limited simulation support to depict and analyze a system model. Due the continuous improvement efforts and new implementation approaches by researchers and organizations, SysML has advanced vastly to encompass dynamic viewpoints, in-situ simulation and enable integration with external modeling and simulation (M\&S) tools. Virtual Reality (VR) has emerged as a user interactive and immersive visualization technology and can depict reality in a virtual environment at different levels of fidelity. VR can play a crucial role in developing dynamic and interactive viewpoints to improve the MBSE approach. In this research paper, the authors developed and implemented a methodology for integrating SysML and VR, enabling tools to achieve three dimensional viewpoints, an immersive user experience and early design evaluations of the system of interest (SOI). The key components of the methodology being followed in this research paper are the SysML, a VR environment, extracted data and scripting languages. The authors initially developed a SysML for a ground-based telescope system following the four pillars of SysML: Structure, Requirements, Behavior and Parametrics. The SysML diagram components are exported from the model using the velocity template language and then fed into a virtual reality game engine. Then, the SysML diagrams are visualized in the VR environment to enable better comprehension and interaction with users and Digital Twin (DT) technologies. In addition, a VR simulation scenario of space objects is generated based on the input from the SysML, and the simulation result is sent back from the VR tool into the model with the aid of parametric diagram simulation. Hence, by utilizing the developed SysML-VR integration methodology, VR environment scenarios are successfully integrated with the SysML. Finally, the research paper mentions a few limitations of the current implementation and proposes future improvements.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {digital twin (DT),model based systems engineering (MBSE),systems modeling language (SysML),virtual reality (VR)},
  annotation = {Read\_Status: Read\\
Read\_Status\_Date: 2024-12-09T17:44:27.818Z},
}

@misc{maamariEndtoendTexttoSQLGeneration2024,
  title = {End-to-End {{Text-to-SQL Generation}} within an {{Analytics Insight Engine}}},
  author = {Maamari, Karime and Mhedhbi, Amine},
  year = {2024},
  month = jun,
  number = {arXiv:2406.12104},
  eprint = {2406.12104},
  primaryclass = {cs},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/2406.12104},
  urldate = {2024-06-24},
  abstract = {Recent advancements in Text-to-SQL have pushed database management systems towards greater democratization of data access. Today's language models are at the core of these advancements. They enable impressive Text-to-SQL generation as experienced in the development of Distyl AI's Analytics Insight Engine. Its early deployment with enterprise customers has highlighted three core challenges. First, data analysts expect support with authoring SQL queries of very high complexity. Second, requests are ad-hoc and, as such, require low latency. Finally, generation requires an understanding of domain-specific terminology and practices.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Databases,Computer Science - Machine Learning},
}

@misc{maddilaAIAssistedSQLAuthoring2024,
  title = {{{AI-Assisted SQL Authoring}} at {{Industry Scale}}},
  author = {Maddila, Chandra and Ghorbani, Negar and Jabre, Kosay and Murali, Vijayaraghavan and Kim, Edwin and Thakkar, Parth and Laptev, Nikolay Pavlovich and Harman, Olivia and Hsu, Diana and Abreu, Rui and Rigby, Peter C.},
  year = {2024},
  month = jul,
  number = {arXiv:2407.13280},
  eprint = {2407.13280},
  primaryclass = {cs},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/2407.13280},
  urldate = {2024-08-17},
  abstract = {SqlCompose brings generative AI into the data analytics domain. SQL is declarative, has formal table schemas, and is often written in a non-linear manner. We address each of these challenges and develop a set of models that shows the importance of each problem. We first develop an internal SQL benchmark to perform offline tests at Meta. We evaluate how well the Public Llama model performs. We attain a BLEU score of 53\% and 24\% for single- and multi-line predictions, respectively. This performance is consistent with prior works on imperative languages. We then fine-tune Llama on our internal data and database schemas. SqlComposeSA substantially outperforms Llama by 16 percentage points on BLEU score. SQL is often written with multiple sub queries and in a non-sequential manner. We develop SqlComposeFIM which is aware of the context before and after the line(s) that need to be completed. This fill-in-the-middle model outperform SqlComposeFIM by 35 percentage points. We also measure how often the models get the correct table names, and SqlComposeFIM is able to do this 75\% of the time a major improvement over the other two models. Aside from our scientific research, we also roll out SqlComposeFIM at Meta. SqlCompose has is used on a weekly basis by over 10k users including data scientists and software engineers, less than 1\% of users have disabled SqlCompose. We use the feedback from users to improve SqlCompose. Interesting positive themes include completing tedious or repetitive SQL clauses, suggesting boilerplate coding, and help in eliminate the need to remember difficult SQL syntax. The most significant negative themes was table and column name hallucinations, which has been reduced with the release of SqlComposeFIM. The SqlCompose models consistently outperform public and internal LLMs despite their smaller size (7 bn and 13 bn), which provides early indications that smaller specialist models can outperform larger general purpose models.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Databases,Computer Science - Software Engineering},
}

@article{maheshwariHowRevertQuestion2017,
  title = {How to {{Revert Question Answering}} on {{Knowledge Graphs}}},
  author = {Maheshwari, Gaurav and Dubey, Mohnish and Trivedi, Priyansh and Lehmann, Jens},
  year = {2017},
  month = oct,
  abstract = {A large scale question answering dataset has a potential to enable development of robust and more accurate question answering systems. In this direction, we introduce a framework for creating such datasets which decreases the manual intervention and domain expertise, traditionally needed. We describe the architecture and the design decisions we took while creating the framework, in detail.},
  langid = {english},
}

@inproceedings{mansourDomainAdaptationMultiple2008,
  title = {Domain {{Adaptation}} with {{Multiple Sources}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Mansour, Yishay and Mohri, Mehryar and Rostamizadeh, Afshin},
  year = {2008},
  volume = {21},
  publisher = {Curran Associates, Inc.},
  urldate = {2024-08-26},
  abstract = {This paper presents a theoretical analysis of the problem of adaptation with multiple sources. For each source domain, the distribution over the input points as well as a hypothesis with error at most {\textbackslash}epsilon are given. The problem consists of combining these hypotheses to derive a hypothesis with small error with respect to the target domain. We present several theoretical results relating to this problem. In particular, we prove that standard convex combinations of the source hypotheses may in fact perform very poorly and that, instead, combinations weighted by the source distributions benefit from favorable theoretical guarantees. Our main result shows that, remarkably, for any fixed target function, there exists a distribution weighted combining rule that has a loss of at most {\textbackslash}epsilon with respect to any target mixture of the source distributions. We further generalize the setting from a single target function to multiple consistent target functions and show the existence of a combining rule with error at most 3{\textbackslash}epsilon. Finally, we report empirical results for a multiple source adaptation problem with a real-world dataset.},
  annotation = {https://proceedings.neurips.cc/paper/2008/hash/0e65972dce68dad4d52d063967f0a705-Abstract.html},
}

@article{maOntologybasedEntityMatching2019,
  title = {Ontology-Based Entity Matching in Attributed Graphs},
  author = {Ma, Hanchao and Alipourlangouri, Morteza and Wu, Yinghui and Chiang, Fei and Pi, Jiaxing},
  year = {2019},
  month = jun,
  journal = {Proceedings of the VLDB Endowment},
  volume = {12},
  number = {10},
  pages = {1195--1207},
  issn = {2150-8097},
  doi = {10.14778/3339490.3339501},
  urldate = {2024-08-30},
  abstract = {Keys for graphs incorporate the topology and value constraints needed to uniquely identify entities in a graph. They have been studied to support object identification, knowledge fusion, and social network reconciliation. Existing key constraints identify entities as the matches of a graph pattern by subgraph isomorphism, which enforce label equality on node types. These constraints can be too restrictive to characterize structures and node labels that are syntactically different but semantically equivalent. We propose a new class of key constraints,               Ontological Graph Keys               (OGKs) that extend conventional graph keys by ontological subgraph matching between entity labels and an external ontology. We show that the implication and validation problems for OGKs are each NP-complete. To reduce the entity matching cost, we also provide an algorithm to compute a minimal cover for OGKs. We then study the entity matching problem with OGKs, and a practical variant with a budget on the matching cost. We develop efficient algorithms to perform entity matching based on a (budgeted) Chase procedure. Using real-world graphs, we experimentally verify the efficiency and accuracy of OGK-based entity matching.},
  langid = {english},
  annotation = {Read\_Status: To Read\\
Read\_Status\_Date: 2024-12-03T18:16:46.816Z},
}

@misc{maQueryRewritingRetrievalAugmented2023,
  title = {Query {{Rewriting}} for {{Retrieval-Augmented Large Language Models}}},
  author = {Ma, Xinbei and Gong, Yeyun and He, Pengcheng and Zhao, Hai and Duan, Nan},
  year = {2023},
  month = oct,
  number = {arXiv:2305.14283},
  eprint = {2305.14283},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2305.14283},
  urldate = {2025-01-12},
  abstract = {Large Language Models (LLMs) play powerful, black-box readers in the retrieve-then-read pipeline, making remarkable progress in knowledge-intensive tasks. This work introduces a new framework, Rewrite-Retrieve-Read instead of the previous retrieve-then-read for the retrieval-augmented LLMs from the perspective of the query rewriting. Unlike prior studies focusing on adapting either the retriever or the reader, our approach pays attention to the adaptation of the search query itself, for there is inevitably a gap between the input text and the needed knowledge in retrieval. We first prompt an LLM to generate the query, then use a web search engine to retrieve contexts. Furthermore, to better align the query to the frozen modules, we propose a trainable scheme for our pipeline. A small language model is adopted as a trainable rewriter to cater to the black-box LLM reader. The rewriter is trained using the feedback of the LLM reader by reinforcement learning. Evaluation is conducted on downstream tasks, open-domain QA and multiple-choice QA. Experiments results show consistent performance improvement, indicating that our framework is proven effective and scalable, and brings a new framework for retrieval-augmented LLM.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language},
}

@phdthesis{margauxennassihFormalizedAspectsSustainability2023,
  title = {The {{Formalized Aspects Of Sustainability Reporting}}: {{A Qualitative Analysis}}},
  author = {{Margaux Ennassih} and {Abbas Esmaeilzadeh}},
  year = {2023},
}

@article{MathematicalKnowledgeManagement2024,
  title = {Mathematical Knowledge Management},
  year = {2024},
  month = may,
  journal = {Wikipedia},
  url = {https://en.wikipedia.org/w/index.php?title=Mathematical_knowledge_management&oldid=1223568787},
  urldate = {2024-12-09},
  abstract = {Mathematical knowledge management (MKM) is the study of how society can effectively make use of the vast and growing literature on mathematics. It studies approaches such as databases of mathematical knowledge, automated processing of formulae and the use of semantic information, and artificial intelligence. Mathematics is particularly suited to a systematic study of automated knowledge processing due to the high degree of interconnectedness between different areas of mathematics.},
  copyright = {Creative Commons Attribution-ShareAlike License},
  langid = {english},
  annotation = {Page Version ID: 1223568787},
}

@incollection{mathiesonIntroductionProximityGraphs2019,
  title = {An {{Introduction}} to {{Proximity Graphs}}},
  booktitle = {Business and {{Consumer Analytics}}: {{New Ideas}}},
  author = {Mathieson, Luke and Moscato, Pablo},
  editor = {Moscato, Pablo and {de Vries}, Natalie Jane},
  year = {2019},
  pages = {213--233},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-06222-4_4},
  urldate = {2024-12-09},
  abstract = {Proximity graphGraphproximityProximity graphs are one of the combinatorial data-miner's frontline tools. They allow expression of complex proximity relationships and are the basis of many other algorithms. Here we introduce the concept of proximity graphs, present basic definitions and discuss some of the most common types of proximity graphs.},
  isbn = {978-3-030-06222-4},
  langid = {english},
  keywords = {Delaunay triangulation,Gabriel graph,Influence graph,Minimum spanning tree,Nearest neighbour graph,Relative neighbourhood graph,Steiner tree,Unit disk graph,Urquhart graph,Voronoi diagram},
}

@article{messinaSurveyDeepLearning2022,
  title = {A {{Survey}} on {{Deep Learning}} and {{Explainability}} for {{Automatic Report Generation}} from {{Medical Images}}},
  author = {Messina, Pablo and Pino, Pablo and Parra, Denis and Soto, Alvaro and Besa, Cecilia and Uribe, Sergio and And{\'i}a, Marcelo and Tejos, Cristian and Prieto, Claudia and Capurro, Daniel},
  year = {2022},
  month = jan,
  journal = {ACM Computing Surveys},
  volume = {54},
  number = {10s},
  pages = {1--40},
  issn = {0360-0300, 1557-7341},
  doi = {10.1145/3522747},
  urldate = {2023-12-11},
  abstract = {Every year physicians face an increasing demand of image-based diagnosis from patients, a problem that can be addressed with recent artificial intelligence methods. In this context, we survey works in the area of automatic report generation from medical images, with emphasis on methods using deep neural networks, with respect to (1) Datasets, (2) Architecture Design, (3) Explainability, and (4) Evaluation Metrics. Our survey identifies interesting developments but also remaining challenges. Among them, the current evaluation of generated reports is especially weak, since it mostly relies on traditional Natural Language Processing (NLP) metrics, which do not accurately capture medical correctness.},
  langid = {english},
  keywords = {Evaluation},
}

@inproceedings{mishraCrossTaskGeneralizationNatural2022,
  title = {Cross-{{Task Generalization}} via {{Natural Language Crowdsourcing Instructions}}},
  booktitle = {Proceedings of the 60th {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}} ({{Volume}} 1: {{Long Papers}})},
  author = {Mishra, Swaroop and Khashabi, Daniel and Baral, Chitta and Hajishirzi, Hannaneh},
  editor = {Muresan, Smaranda and Nakov, Preslav and Villavicencio, Aline},
  year = {2022},
  month = may,
  pages = {3470--3487},
  publisher = {Association for Computational Linguistics},
  address = {Dublin, Ireland},
  doi = {10.18653/v1/2022.acl-long.244},
  urldate = {2024-03-09},
  abstract = {Humans (e.g., crowdworkers) have a remarkable ability in solving different tasks, by simply reading textual instructions that define them and looking at a few examples. Despite the success of the conventional supervised learning on individual datasets, such models often struggle with generalization across tasks (e.g., a question-answering system cannot solve classification tasks). A long-standing challenge in AI is to build a model that learns a new task by understanding the human-readable instructions that define it. To study this, we introduce NATURAL INSTRUCTIONS, a dataset of 61 distinct tasks, their human-authored instructions, and 193k task instances (input-output pairs). The instructions are obtained from crowdsourcing instructions used to create existing NLP datasets and mapped to a unified schema. Using this meta-dataset, we measure cross-task generalization by training models on seen tasks and measuring generalization to the remaining unseen ones. We adopt generative pre-trained language models to encode task-specific instructions along with input and generate task output. Our results indicate that models benefit from instructions when evaluated in terms of generalization to unseen tasks (19\% better for models utilizing instructions). These models, however, are far behind an estimated performance upperbound indicating significant room for more progress in this direction.},
}

@inproceedings{mitchellModelCardsModel2019,
  title = {Model {{Cards}} for {{Model Reporting}}},
  booktitle = {Proceedings of the {{Conference}} on {{Fairness}}, {{Accountability}}, and {{Transparency}}},
  author = {Mitchell, Margaret and Wu, Simone and Zaldivar, Andrew and Barnes, Parker and Vasserman, Lucy and Hutchinson, Ben and Spitzer, Elena and Raji, Inioluwa Deborah and Gebru, Timnit},
  year = {2019},
  month = jan,
  pages = {220--229},
  publisher = {ACM},
  address = {Atlanta GA USA},
  doi = {10.1145/3287560.3287596},
  urldate = {2025-01-13},
  isbn = {978-1-4503-6125-5},
  langid = {english},
}

@article{ModelbasedSystemsEngineering2024,
  title = {Model-Based Systems Engineering},
  year = {2024},
  month = oct,
  journal = {Wikipedia},
  url = {https://en.wikipedia.org/w/index.php?title=Model-based_systems_engineering&oldid=1251657514},
  urldate = {2024-11-20},
  abstract = {Model-based systems engineering (MBSE), according to the International Council on Systems Engineering (INCOSE), is the formalized application of modeling to support system requirements, design, analysis, verification and validation activities beginning in the conceptual design phase and continuing throughout development and later life cycle phases. MBSE is a technical approach to systems engineering that focuses on creating and exploiting domain models as the primary means of information exchange, rather than on document-based information exchange. MBSE technical approaches are commonly applied to a wide range of industries with complex systems, such as aerospace, defense, rail, automotive, manufacturing, etc.},
  copyright = {Creative Commons Attribution-ShareAlike License},
  langid = {english},
  annotation = {Page Version ID: 1251657514},
}

@article{mullaAutomaticQuestionGeneration2023,
  title = {Automatic Question Generation: A Review of Methodologies, Datasets, Evaluation Metrics, and Applications},
  shorttitle = {Automatic Question Generation},
  author = {Mulla, Nikahat and Gharpure, Prachi},
  year = {2023},
  month = mar,
  journal = {Progress in Artificial Intelligence},
  volume = {12},
  number = {1},
  pages = {1--32},
  issn = {2192-6352, 2192-6360},
  doi = {10.1007/s13748-023-00295-9},
  urldate = {2024-08-20},
  abstract = {Question generation in natural language has a wide variety of applications. It can be a helpful tool for chatbots for generating interesting questions as also for automating the process of question generation from a piece of text. Most modern-day systems, which are conversational, require question generation ability for identifying the user's needs and serving customers better. Generating questions in natural language is now, a more evolved task, which also includes generating questions for an image or video. In this review, we provide an overview of the research progress in automatic question generation. We also present a comprehensive literature review covering the classification of Question Generation systems by categorizing them into three broad use-cases, namely standalone question generation, visual question generation, and conversational question generation. We next discuss the datasets available for the same for each use-case. We further direct this review towards applications of question generation and discuss the challenges in this field of research.},
  langid = {english},
}

@article{nabaviLeveragingNaturalLanguage2023,
  title = {Leveraging {{Natural Language Processing}} for {{Automated Information Inquiry}} from {{Building Information Models}}},
  author = {Nabavi, Armin and Ramaji, Issa and Sadeghi, Naimeh and Anderson, Anne},
  year = {2023},
  month = apr,
  journal = {Journal of Information Technology in Construction},
  volume = {28},
  pages = {266--285},
  issn = {1874-4753},
  doi = {10.36680/j.itcon.2023.013},
  urldate = {2023-12-01},
  abstract = {Building Information Modeling (BIM) is a trending technology in the building industry that can increase efficiency throughout construction. Various practical information can be obtained from BIM models during the project life cycle. However, accessing this information could be tedious and time-consuming for nontechnical users, who might have limited or no knowledge of working with BIM software. Automating the information inquiry process can potentially address this need. This research proposes an Artificial Intelligencebased framework to facilitate accessing information in BIM models. First, the framework uses a support vector machine (SVM) algorithm to determine the user's question type. Simultaneously, it employs natural language processing (NLP) for syntactic analysis to find the main keywords of the user's question. Then it utilizes an ontology database such as IfcOWL and an NLP method (latent semantic analysis (LSA)) for a semantic understanding of the question. The keywords are expanded through the semantic relationship in the ontologies, and eventually, a final query is formed based on keywords and their expanded concepts. A Navisworks API is developed that employs the identified question type and its parameters to extract the results from BIM and display them to the users. The proposed platform also includes a speech recognition module for a more user-friendly interface. The results show that the speed of answering the questions on the platform is up to 5 times faster than the manual use by experts while maintaining high accuracy.},
  langid = {english},
}

@article{nangiDenseRetrievalKnowledge2023,
  title = {Dense {{Retrieval}} of {{Knowledge Graphs}} for {{Question Answering}}},
  author = {Nangi, Sharmila Reddy and Yasunaga, Michihiro and Ren, Hongyu and Huang, Qian and Liang, Percy and Leskovec, Jure},
  year = {2023},
  abstract = {Recent works in commonsense question answering are leveraging the unstructured knowledge from powerful language models and structured knowledge from Knowledge Graphs. QA-GNN [26] is one such method giving state-of-the-art performances, but is limited by its reliance on the extraction of contextual subgraph for every QA pair through entity linking and heuristics. To address this limitation, there is a growing need for more generalizable approaches to sub-graph retrieval. There has been an increasing effort of dense retrieval in the language domain [6, 11, 12] which focus on retrieving relevant information from large knowledge sources like Wikipedia through learning better data and query representations. In this work, we extend this approach to the context of graphs and build DrKG, a dense retrieval framework for Knowledge graphs in the task of question answering. Our experiments with empirical and qualitative results suggest that our framework extracts subgraphs that show improved performance on multiple datasets for commonsense QA.},
  langid = {english},
}

@misc{nirdiamantNirDiamantRAG_Techniques2024,
  title = {{{NirDiamant}}/{{RAG}}\_{{Techniques}}},
  author = {NirDiamant},
  year = {2024},
  month = sep,
  url = {https://github.com/NirDiamant/RAG_Techniques},
  urldate = {2024-09-02},
  abstract = {This repository showcases various advanced techniques for Retrieval-Augmented Generation (RAG) systems. RAG systems combine information retrieval with generative models to provide accurate and contextually rich responses.},
  copyright = {Apache-2.0}
}

@article{NPcompleteness2024,
  title = {{{NP-completeness}}},
  year = {2024},
  month = aug,
  journal = {Wikipedia},
  url = {https://en.wikipedia.org/w/index.php?title=NP-completeness&oldid=1239273276},
  urldate = {2024-08-30},
  abstract = {In computational complexity theory, a problem is NP-complete when: It is a decision problem, meaning that for any input to the problem, the output is either "yes" or "no". When the answer is "yes", this can be demonstrated through the existence of a short (polynomial length) solution. The correctness of each solution can be verified quickly (namely, in polynomial time) and a brute-force search algorithm can find a solution by trying all possible solutions. The problem can be used to simulate every other problem for which we can verify quickly that a solution is correct. In this sense, NP-complete problems are the hardest of the problems to which solutions can be verified quickly. If we could find solutions of some NP-complete problem quickly, we could quickly find the solutions of every other problem to which a given solution can be easily verified. The name "NP-complete" is short for "nondeterministic polynomial-time complete". In this name, "nondeterministic" refers to nondeterministic Turing machines, a way of mathematically formalizing the idea of a brute-force search algorithm. Polynomial time refers to an amount of time that is considered "quick" for a deterministic algorithm to check a single solution, or for a nondeterministic Turing machine to perform the whole search. "Complete" refers to the property of being able to simulate everything in the same complexity class. More precisely, each input to the problem should be associated with a set of solutions of polynomial length, the validity of each of which can be tested quickly (in polynomial time), such that the output for any input is "yes" if the solution set is non-empty and "no" if it is empty. The complexity class of problems of this form is called NP, an abbreviation for "nondeterministic polynomial time". A problem is said to be NP-hard if everything in NP can be transformed in polynomial time into it even though it may not be in NP. A problem is NP-complete if it is both in NP and NP-hard. The NP-complete problems represent the hardest problems in NP. If some NP-complete problem has a polynomial time algorithm, all problems in NP do. The set of NP-complete problems is often denoted by NP-C or NPC. Although a solution to an NP-complete problem can be verified "quickly", there is no known way to find a solution quickly. That is, the time required to solve the problem using any currently known algorithm increases rapidly as the size of the problem grows. As a consequence, determining whether it is possible to solve these problems quickly, called the P versus NP problem, is one of the fundamental unsolved problems in computer science today. While a method for computing the solutions to NP-complete problems quickly remains undiscovered, computer scientists and programmers still frequently encounter NP-complete problems. NP-complete problems are often addressed by using heuristic methods and approximation algorithms.},
  copyright = {Creative Commons Attribution-ShareAlike License},
  langid = {english},
  annotation = {Page Version ID: 1239273276},
}

@incollection{oakesExperiencesCaseStudies2023,
  title = {Experiences from {{Case Studies}} on {{Digital Twins}}},
  author = {Oakes, Bentley James and Zhang, Houxiang and Hatledal, Lars Ivar and Feng, Hao and Frasheri, Mirgita and Sandberg, Michael and Gil, Santiago and Gomes, Cl{\'a}udio},
  year = {2023},
}

@misc{omarChatGPTTraditionalQuestion2023,
  title = {{{ChatGPT}} versus {{Traditional Question Answering}} for {{Knowledge Graphs}}: {{Current Status}} and {{Future Directions Towards Knowledge Graph Chatbots}}},
  shorttitle = {{{ChatGPT}} versus {{Traditional Question Answering}} for {{Knowledge Graphs}}},
  author = {Omar, Reham and Mangukiya, Omij and Kalnis, Panos and Mansour, Essam},
  year = {2023},
  month = feb,
  number = {arXiv:2302.06466},
  eprint = {2302.06466},
  primaryclass = {cs},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/2302.06466},
  urldate = {2024-03-04},
  abstract = {Conversational AI and Question-Answering systems (QASs) for knowledge graphs (KGs) are both emerging research areas: they empower users with natural language interfaces for extracting information easily and effectively. Conversational AI simulates conversations with humans; however, it is limited by the data captured in the training datasets. In contrast, QASs retrieve the most recent information from a KG by understanding and translating the natural language question into a formal query supported by the database engine. In this paper, we present a comprehensive study of the characteristics of the existing alternatives towards combining both worlds into novel KG chatbots. Our framework compares two representative conversational models, ChatGPT and Galactica, against KGQAN, the current state-of-the-art QAS. We conduct a thorough evaluation using four real KGs across various application domains to identify the current limitations of each category of systems. Based on our findings, we propose open research opportunities to empower QASs with chatbot capabilities for KGs. All benchmarks and all raw results are available1 for further analysis.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Information Retrieval},
}

@article{omarUniversalQuestionAnsweringPlatform2023,
  title = {A {{Universal Question-Answering Platform}} for {{Knowledge Graphs}}},
  author = {Omar, Reham and Dhall, Ishika and Kalnis, Panos and Mansour, Essam},
  year = {2023},
  month = may,
  journal = {Proceedings of the ACM on Management of Data},
  volume = {1},
  number = {1},
  pages = {1--25},
  issn = {2836-6573},
  doi = {10.1145/3588911},
  urldate = {2024-01-16},
  abstract = {Knowledge from diverse application domains is organized as knowledge graphs (KGs) that are stored in RDF engines accessible in the web via SPARQL endpoints. Expressing a well-formed SPARQL query requires information about the graph structure and the exact URIs of its components, which is impractical for the average user. Question answering (QA) systems assist by translating natural language questions to SPARQL. Existing QA systems are typically based on application-specific human-curated rules, or require prior information, expensive pre-processing and model adaptation for each targeted KG. Therefore, they are hard to generalize to a broad set of applications and KGs. In this paper, we propose KGQAn, a universal QA system that does not need to be tailored to each target KG. Instead of curated rules, KGQAn introduces a novel formalization of question understanding as a text generation problem to convert a question into an intermediate abstract representation via a neural sequence-to-sequence model. We also develop a just-in-time linker that maps at query time the abstract representation to a SPARQL query for a specific KG, using only the publicly accessible APIs and the existing indices of the RDF store, without requiring any pre-processing. Our experiments with several real KGs demonstrate that KGQAn is easily deployed and outperforms by a large margin the state-of-the-art in terms of quality of answers and processing time, especially for arbitrary KGs, unseen during the training.},
  code = {https://github.com/CoDS-GCS/KGQAn},
  langid = {english},
  annotation = {Read\_Status: Read\\
Read\_Status\_Date: 2024-12-04T13:15:15.808Z},
}

@misc{OntologybasedSubgraphQuerying,
  title = {Ontology-Based Subgraph Querying {\textbar} {{IEEE Conference Publication}} {\textbar} {{IEEE Xplore}}},
  url = {https://ieeexplore.ieee.org/document/6544867},
  urldate = {2024-08-30},
}

@article{pandeyFineTuningRAGModels,
  title = {Fine-{{Tuning RAG Models}} for {{Custom Content Generation}}},
  author = {Pandey, Pankaj},
  langid = {english},
}

@article{panSurveyTransferLearning2010,
  title = {A {{Survey}} on {{Transfer Learning}}},
  author = {Pan, Sinno Jialin and Yang, Qiang},
  year = {2010},
  month = oct,
  journal = {IEEE Transactions on Knowledge and Data Engineering},
  volume = {22},
  number = {10},
  pages = {1345--1359},
  issn = {1558-2191},
  doi = {10.1109/TKDE.2009.191},
  urldate = {2024-08-26},
  abstract = {A major assumption in many machine learning and data mining algorithms is that the training and future data must be in the same feature space and have the same distribution. However, in many real-world applications, this assumption may not hold. For example, we sometimes have a classification task in one domain of interest, but we only have sufficient training data in another domain of interest, where the latter data may be in a different feature space or follow a different data distribution. In such cases, knowledge transfer, if done successfully, would greatly improve the performance of learning by avoiding much expensive data-labeling efforts. In recent years, transfer learning has emerged as a new learning framework to address this problem. This survey focuses on categorizing and reviewing the current progress on transfer learning for classification, regression, and clustering problems. In this survey, we discuss the relationship between transfer learning and other related machine learning techniques such as domain adaptation, multitask learning and sample selection bias, as well as covariate shift. We also explore some potential future issues in transfer learning research.},
  keywords = {Data mining,data mining.,Knowledge engineering,Knowledge transfer,Labeling,Learning systems,machine learning,Machine learning,Machine learning algorithms,Space technology,survey,Testing,Training data,Transfer learning},
}

@misc{PaperPageAnchored2024,
  title = {Paper Page - {{Anchored Preference Optimization}} and {{Contrastive Revisions}}: {{Addressing Underspecification}} in {{Alignment}}},
  shorttitle = {Paper Page - {{Anchored Preference Optimization}} and {{Contrastive Revisions}}},
  year = {2024},
  month = aug,
  url = {https://huggingface.co/papers/2408.06266},
  urldate = {2024-09-02},
  abstract = {Join the discussion on this paper page},
}

@inproceedings{papineniBleuMethodAutomatic2002,
  title = {Bleu: A {{Method}} for {{Automatic Evaluation}} of {{Machine Translation}}},
  shorttitle = {Bleu},
  booktitle = {Proceedings of the 40th {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}}},
  author = {Papineni, Kishore and Roukos, Salim and Ward, Todd and Zhu, Wei-Jing},
  editor = {Isabelle, Pierre and Charniak, Eugene and Lin, Dekang},
  year = {2002},
  month = jul,
  pages = {311--318},
  publisher = {Association for Computational Linguistics},
  address = {Philadelphia, Pennsylvania, USA},
  doi = {10.3115/1073083.1073135},
  urldate = {2024-05-28},
}

@misc{parnamiLearningFewExamples2022,
  title = {Learning from {{Few Examples}}: {{A Summary}} of {{Approaches}} to {{Few-Shot Learning}}},
  shorttitle = {Learning from {{Few Examples}}},
  author = {Parnami, Archit and Lee, Minwoo},
  year = {2022},
  month = mar,
  number = {arXiv:2203.04291},
  eprint = {2203.04291},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2203.04291},
  urldate = {2024-08-05},
  abstract = {Few-Shot Learning refers to the problem of learning the underlying pattern in the data just from a few training samples. Requiring a large number of data samples, many deep learning solutions suffer from data hunger and extensively high computation time and resources. Furthermore, data is often not available due to not only the nature of the problem or privacy concerns but also the cost of data preparation. Data collection, preprocessing, and labeling are strenuous human tasks. Therefore, few-shot learning that could drastically reduce the turnaround time of building machine learning applications emerges as a low-cost solution. This survey paper comprises a representative list of recently proposed few-shot learning algorithms. Given the learning dynamics and characteristics, the approaches to few-shot learning problems are discussed in the perspectives of meta-learning, transfer learning, and hybrid approaches (i.e., different variations of the few-shot learning problem).},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Synthetic data},
}

@article{ParseTree2024,
  title = {Parse Tree},
  year = {2024},
  month = nov,
  journal = {Wikipedia},
  url = {https://en.wikipedia.org/w/index.php?title=Parse_tree&oldid=1257981114#Constituency-based_parse_trees},
  urldate = {2024-11-22},
  abstract = {A parse tree or parsing tree (also known as a derivation tree or concrete syntax tree) is an ordered, rooted tree that represents the syntactic structure of a string according to some context-free grammar. The term parse tree itself is used primarily in computational linguistics; in theoretical syntax, the term syntax tree is more common. Concrete syntax trees reflect the syntax of the input language, making them distinct from the abstract syntax trees used in computer programming. Unlike Reed-Kellogg sentence diagrams used for teaching grammar, parse trees do not use distinct symbol shapes for different types of constituents. Parse trees are usually constructed based on either the constituency relation of constituency grammars (phrase structure grammars) or the dependency relation of dependency grammars. Parse trees may be generated for sentences in natural languages (see natural language processing), as well as during processing of computer languages, such as programming languages. A related concept is that of phrase marker or P-marker, as used in transformational generative grammar. A phrase marker is a linguistic expression marked as to its phrase structure. This may be presented in the form of a tree, or as a bracketed expression. Phrase markers are generated by applying phrase structure rules, and themselves are subject to further transformational rules. A set of possible parse trees for a syntactically ambiguous sentence is called a "parse forest".},
  copyright = {Creative Commons Attribution-ShareAlike License},
  langid = {english},
  annotation = {Page Version ID: 1257981114},
}

@article{Pcomplete2024,
  title = {P-Complete},
  year = {2024},
  month = jul,
  journal = {Wikipedia},
  url = {https://en.wikipedia.org/w/index.php?title=P-complete&oldid=1232687388},
  urldate = {2024-08-30},
  abstract = {In computational complexity theory,  a decision problem is P-complete (complete for the complexity class P) if it is in P and every problem in P can be reduced to it by an appropriate reduction. The notion of P-complete decision problems is useful in the analysis of: which problems are difficult to parallelize effectively, which problems are difficult to solve in limited space. specifically when stronger notions of reducibility than polytime-reducibility are considered. The specific type of reduction used varies and may affect the exact set of problems. Generically, reductions stronger than polynomial-time reductions are used, since all languages in P (except the empty language and the language of all strings) are P-complete under polynomial-time reductions. If we use NC reductions, that is, reductions which can operate in polylogarithmic time on a parallel computer with a polynomial number of processors, then all P-complete problems lie outside NC and so cannot be effectively parallelized, under the unproven assumption that NC {$\neq$} P. If we use the stronger log-space reduction, this remains true, but additionally we learn that all P-complete problems lie outside L under the weaker unproven assumption that L {$\neq$} P. In this latter case the set P-complete may be smaller.},
  copyright = {Creative Commons Attribution-ShareAlike License},
  langid = {english},
  annotation = {Page Version ID: 1232687388},
}

@article{pellicerDataAugmentationTechniques2023,
  title = {Data Augmentation Techniques in Natural Language Processing},
  author = {Pellicer, Lucas Francisco Amaral Orosco and Ferreira, Taynan Maier and Costa, Anna Helena Reali},
  year = {2023},
  month = jan,
  journal = {Applied Soft Computing},
  volume = {132},
  pages = {109803},
  issn = {1568-4946},
  doi = {10.1016/j.asoc.2022.109803},
  urldate = {2024-11-22},
  abstract = {Data Augmentation (DA) methods -- a family of techniques designed for synthetic generation of training data -- have shown remarkable results in various Deep Learning and Machine Learning tasks. Despite its widespread and successful adoption within the computer vision community, DA techniques designed for natural language processing (NLP) tasks have exhibited much slower advances and limited success in achieving performance gains. As a consequence, with the exception of applications of back-translation to machine translation tasks, these techniques have not been as thoroughly explored by the wider NLP community. Recent research on the subject still lacks a proper practical understanding of the relationship between the various existing DA methods. The connection between DA methods and several important aspects of its outputs, such as lexical diversity and semantic fidelity, is also still poorly understood. In this work, we perform a comprehensive study of NLP DA techniques, comparing their relative performance under different settings. We analyze the quality of the synthetic data generated, evaluate its performance gains and compare all of these aspects to previous existing DA procedures.},
  keywords = {Back-translation,Data augmentation,Machine learning,Natural language processing},
}

@misc{pengChatGraphChatYour2024,
  title = {{{ChatGraph}}: {{Chat}} with {{Your Graphs}}},
  shorttitle = {{{ChatGraph}}},
  author = {Peng, Yun and Lin, Sen and Chen, Qian and Xu, Lyu and Ren, Xiaojun and Li, Yafei and Xu, Jianliang},
  year = {2024},
  month = jan,
  number = {arXiv:2401.12672},
  eprint = {2401.12672},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2401.12672},
  urldate = {2024-02-02},
  abstract = {Graph analysis is fundamental in real-world applications. Traditional approaches rely on SPARQL-like languages or clicking-and-dragging interfaces to interact with graph data. However, these methods either require users to possess high programming skills or support only a limited range of graph analysis functionalities. To address the limitations, we propose a large language model (LLM)-based framework called ChatGraph. With ChatGraph, users can interact with graphs through natural language, making it easier to use and more flexible than traditional approaches. The core of ChatGraph lies in generating chains of graph analysis APIs based on the understanding of the texts and graphs inputted in the user prompts. To achieve this, ChatGraph consists of three main modules: an API retrieval module that searches for relevant APIs, a graph-aware LLM module that enables the LLM to comprehend graphs, and an API chain-oriented finetuning module that guides the LLM in generating API chains. We have implemented ChatGraph and will showcase its usability and efficiency in four scenarios using real-world graphs.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence},
}

@misc{pengSoftPromptTuning2024,
  title = {Soft {{Prompt Tuning}} for {{Augmenting Dense Retrieval}} with {{Large Language Models}}},
  author = {Peng, Zhiyuan and Wu, Xuyang and Wang, Qifan and Fang, Yi},
  year = {2024},
  month = feb,
  number = {arXiv:2307.08303},
  eprint = {2307.08303},
  primaryclass = {cs},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/2307.08303},
  urldate = {2024-05-23},
  abstract = {Dense retrieval (DR) converts queries and documents into dense embeddings and measures the similarity between queries and documents in vector space. One of the major challenges in DR is the lack of domain-specific training data. While DR models can learn from large-scale public datasets like MS MARCO through transfer learning, evidence shows that not all DR models and domains can benefit from transfer learning. Recently, researchers have resorted to large language models (LLMs) to improve the zero-shot and few-shot DR models. However, the hard prompts or human-written prompts utilized in these works are suboptimal and the generated weak queries are often sensitive to the prompts. To tackle this, we propose soft prompt tuning for augmenting DR (SPTAR1): for each task, we leverage soft prompt-tuning to optimize a task-specific soft prompt on limited ground truth data and then prompt the LLMs to tag unlabeled documents with weak queries, yielding weak documentquery pairs to train task-specific dense retrievers. We design a filter to select high-quality example document-query pairs in the prompt to further improve the quality of weak tagged queries. To the best of our knowledge, there is no prior work utilizing soft prompt tuning to augment DR models. Moreover, unlike much of the existing work, ours is based on popular open-source LLMs to ensure reproducible and deterministic results. Our experimental results demonstrate that SPTAR outperforms both unsupervised baselines and the recently proposed LLMs-based augmentation method for DR.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Information Retrieval,Computer Science - Machine Learning},
}

@article{pereiraSystematicReviewQuestion2022,
  title = {Systematic Review of Question Answering over Knowledge Bases},
  author = {Pereira, Arnaldo and Trifan, Alina and Lopes, Rui Pedro and Oliveira, Jos{\'e} Lu{\'i}s},
  year = {2022},
  month = feb,
  journal = {IET Software},
  volume = {16},
  number = {1},
  pages = {1--13},
  issn = {1751-8806, 1751-8814},
  doi = {10.1049/sfw2.12028},
  urldate = {2023-12-19},
  abstract = {Over the years, a growing number of semantic data repositories have been made available on the web. However, this has created new challenges in exploiting these resources efficiently. Querying services require knowledge beyond the typical user's expertise, which is a critical issue in adopting semantic information solutions. Several proposals to overcome this difficulty have suggested using question answering (QA) systems to provide user-friendly interfaces and allow natural language use. Because question answering over knowledge bases (KBQAs) is a very active research topic, a comprehensive view of the field is essential. The purpose of this study was to conduct a systematic review of methods and systems for KBQAs to identify their main advantages and limitations. The inclusion criteria rationale was English full-text articles published since 2015 on methods and systems for KBQAs. Sixty-six articles were reviewed to describe their underlying reference architectures.},
  langid = {english},
  keywords = {KBQA},
}

@misc{perevalovQALD9plusMultilingualDataset2022,
  title = {{{QALD-9-plus}}: {{A Multilingual Dataset}} for {{Question Answering}} over {{DBpedia}} and {{Wikidata Translated}} by {{Native Speakers}}},
  shorttitle = {{{QALD-9-plus}}},
  author = {Perevalov, Aleksandr and Diefenbach, Dennis and Usbeck, Ricardo and Both, Andreas},
  year = {2022},
  month = feb,
  number = {arXiv:2202.00120},
  eprint = {2202.00120},
  primaryclass = {cs},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/2202.00120},
  urldate = {2024-02-29},
  abstract = {The ability to have the same experience for different user groups (i.e., accessibility) is one of the most important characteristics of Web-based systems. The same is true for Knowledge Graph Question Answering (KGQA) systems that provide the access to Semantic Web data via natural language interface. While following our research agenda on the multilingual aspect of accessibility of KGQA systems, we identified several ongoing challenges. One of them is the lack of multilingual KGQA benchmarks. In this work, we extend one of the most popular KGQA benchmarks - QALD-9 by introducing high-quality questions' translations to 8 languages provided by native speakers, and transferring the SPARQL queries of QALD-9 from DBpedia to Wikidata, s.t., the usability and relevance of the dataset is strongly increased. Five of the languages - Armenian, Ukrainian, Lithuanian, Bashkir and Belarusian - to our best knowledge were never considered in KGQA research community before. The latter two of the languages are considered as "endangered" by UNESCO. We call the extended dataset QALD-9-plus and made it available online https://github.com/Perevalov/qald\_9\_plus.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language,Computer Science - Information Retrieval},
}

@article{perezSemanticsComplexitySPARQL2009,
  title = {Semantics and Complexity of {{SPARQL}}},
  author = {P{\'e}rez, Jorge and Arenas, Marcelo and Gutierrez, Claudio},
  year = {2009},
  month = aug,
  journal = {ACM Transactions on Database Systems},
  volume = {34},
  number = {3},
  pages = {1--45},
  issn = {0362-5915, 1557-4644},
  doi = {10.1145/1567274.1567278},
  urldate = {2024-08-17},
  abstract = {SPARQL is the standard language for querying RDF data. In this article, we address systematically the formal study of the database aspects of SPARQL, concentrating in its graph pattern matching facility. We provide a compositional semantics for the core part of SPARQL, and study the complexity of the evaluation of several fragments of the language. Among other complexity results, we show that the evaluation of general SPARQL patterns is PSPACE-complete. We identify a large class of SPARQL patterns, defined by imposing a simple and natural syntactic restriction, where the query evaluation problem can be solved more efficiently. This restriction gives rise to the class of well-designed patterns. We show that the evaluation problem is coNP-complete for well-designed patterns. Moreover, we provide several rewriting rules for well-designed patterns whose application may have a considerable impact in the cost of evaluating SPARQL queries.},
  langid = {english},
}

@incollection{phojanamongkolkijModelingMarsNASA,
  title = {Modeling to {{Mars}}: A {{NASA Model Based Systems Engineering Pathfinder Effort}}},
  shorttitle = {Modeling to {{Mars}}},
  booktitle = {{{AIAA SPACE}} and {{Astronautics Forum}} and {{Exposition}}},
  author = {Phojanamongkolkij, Nipa and Lee, Kristopher and Miller, Scott T. and Vorndran, Kenneth A. and Vaden, Karl R. and Ross, Eric P. and Powell, Robert C. and Moses, Robert},
  publisher = {{American Institute of Aeronautics and Astronautics}},
  doi = {10.2514/6.2017-5235},
  urldate = {2024-12-09},
  annotation = {Read\_Status: Read\\
Read\_Status\_Date: 2024-12-09T17:44:27.811Z},
}

@article{pliukhinImprovingSubgraphExtraction,
  title = {Improving {{Subgraph Extraction Algorithms}} for {{One-Shot SPARQL Query Generation}} with {{Large Language Models}}},
  author = {Pliukhin, Dmitrii and Radyush, Daniil and Kovriguina, Liubov and Mouromtsev, Dmitry},
  abstract = {Question answering over scholarly knowledge graphs involves many challenges: complex graph patterns, long-tail distributed data, revision and evolution of the scholarly ontologies, and knowledge graphs incompleteness due to constant research dynamics. In this work, we present an LLM-based approach for SPARQL query generation over Open Research Knowledge Graph (ORKG) for the ISWC SciQA Challenge. Our approach proposes a couple of improvements to the recently published SPARQLGEN approach, that performs one-shot SPARQL query generation by augmenting Large Language Models (LLMs) with the relevant context within a single prompt. Similar to SPARQLGEN, we include heterogeneous data sources in the SPARQL generation prompt: a question itself, an RDF subgraph required to answer the question, and an example of a correct SPARQL query. In the current work, we focused on designing subgraph extraction algorithms, that are close to real-life scenarios of generative KGQA, and replaced the random choice of example question-query pair with similarity scoring.},
  langid = {english},
}

@article{popowichInteractiveNaturalLanguage2012,
  title = {Interactive {{Natural Language Query Construction}} for {{Report Generation}}},
  author = {Popowich, Fred and Mosny, Milan and Lindberg, David},
  year = {2012},
  abstract = {Question answering is an age old AI challenge. How we approach this challenge is determined by decisions regarding the linguistic and domain knowledge our system will need, the technical and business acumen of our users, the interface used to input questions, and the form in which we should present answers to a user's questions. Our approach to question answering involves the interactive construction of natural language queries. We describe and evaluate a question answering system that provides a point-and-click, webbased interface in conjunction with a semantic grammar to support user-controlled natural language question generation. A preliminary evaluation is performed using a selection of 12 questions based on the Adventure Works sample database.},
  langid = {english},
}

@article{raissyaVizKGFrameworkVisualizing2021,
  title = {{{VizKG}}: {{A Framework}} for {{Visualizing SPARQL Query Results}} over {{Knowledge Graphs}}},
  shorttitle = {{{VizKG}}},
  author = {Raissya, Hana and Darari, Fariz and Ekaputra, Fajar J.},
  year = {2021},
  journal = {CEUR Workshop Proceedings},
  volume = {3023},
  pages = {95--102},
  issn = {1613-0073},
  langid = {english},
  keywords = {Insights,Knowledge graphs,SPARQL,Visualization},
  annotation = {http://www.scopus.com/inward/record.url?scp=85120791101\&partnerID=8YFLogxK},
}

@inproceedings{rajbhojDocToModelAutomatedAuthoring2023,
  title = {{{DocToModel}}: {{Automated Authoring}} of {{Models}} from {{Diverse Requirements Specification Documents}}},
  shorttitle = {{{DocToModel}}},
  booktitle = {2023 {{IEEE}}/{{ACM}} 45th {{International Conference}} on {{Software Engineering}}: {{Software Engineering}} in {{Practice}} ({{ICSE-SEIP}})},
  author = {Rajbhoj, Asha and Nistala, Padmalata and Kulkarni, Vinay and Soni, Shivani and Pathan, Ajim},
  year = {2023},
  month = may,
  pages = {199--210},
  publisher = {IEEE},
  address = {Melbourne, Australia},
  doi = {10.1109/ICSE-SEIP58684.2023.00024},
  urldate = {2023-12-12},
  abstract = {Early stages of Software Development Life Cycle (SDLC) namely requirement elicitation and requirements analysis have remained document-centric in the industry for marketdriven, complex, large-scale business applications and products. The documentation typically runs into hundreds of Natural Language (NL) text documents which requirements engineers need to sift looking for the relevant information and also maintain these documents in-sync over time -- a time-consuming and errorprone activity. Much of this difficulty can be overcome if the information is available in a structured form that is amenable to automated processing. Purposive models offer a way out. However, for easy adoption by industry practitioners, these models must be populated from NL text documents in a largely automated manner. This task is characterized by high variability with several documents containing different information conforming to different structures and styles. As a result, purposive information extractors need to be developed for each project/ product. Moreover, being an open-ended space there is no upper bound on the information extractors that need to be developed. To overcome this difficulty, we propose a document structure agnostic and meta-model agnostic tool, DocToModel, for the automated authoring of models from NL text documents. It provides a pattern mapping language to specify a mapping of structured and unstructured document information to metamodel elements, and a pattern interpreter to automate model authoring. The configurable and extensible architecture of DocToModel makes it generic and amenable to easy repurposing for other NL documents. This paper, describes the approach and illustrates its utility and efficacy on multiple real-world case studies.},
  isbn = {9798350300376},
  langid = {english},
}

@misc{rajpurkarKnowWhatYou2018,
  title = {Know {{What You Don}}'t {{Know}}: {{Unanswerable Questions}} for {{SQuAD}}},
  shorttitle = {Know {{What You Don}}'t {{Know}}},
  author = {Rajpurkar, Pranav and Jia, Robin and Liang, Percy},
  year = {2018},
  month = jun,
  number = {arXiv:1806.03822},
  eprint = {1806.03822},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1806.03822},
  urldate = {2024-04-12},
  abstract = {Extractive reading comprehension systems can often locate the correct answer to a question in a context document, but they also tend to make unreliable guesses on questions for which the correct answer is not stated in the context. Existing datasets either focus exclusively on answerable questions, or use automatically generated unanswerable questions that are easy to identify. To address these weaknesses, we present SQuAD 2.0, the latest version of the Stanford Question Answering Dataset (SQuAD). SQuAD 2.0 combines existing SQuAD data with over 50,000 unanswerable questions written adversarially by crowdworkers to look similar to answerable ones. To do well on SQuAD 2.0, systems must not only answer questions when possible, but also determine when no answer is supported by the paragraph and abstain from answering. SQuAD 2.0 is a challenging natural language understanding task for existing models: a strong neural system that gets 86\% F1 on SQuAD 1.1 achieves only 66\% F1 on SQuAD 2.0.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language},
}

@article{ramosModelBasedSystemsEngineering2012,
  title = {Model-{{Based Systems Engineering}}: {{An Emerging Approach}} for {{Modern Systems}}},
  shorttitle = {Model-{{Based Systems Engineering}}},
  author = {Ramos, A. L. and Ferreira, J. V. and Barcelo, J.},
  year = {2012},
  month = jan,
  journal = {IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)},
  volume = {42},
  number = {1},
  pages = {101--111},
  issn = {1094-6977, 1558-2442},
  doi = {10.1109/TSMCC.2011.2106495},
  urldate = {2024-03-02},
  abstract = {To engineer the modern large, complex, interdisciplinary systems-of-systems (SoS), the collaborative world teams must ``speak'' the same language and must work on the same ``matter.'' The ``matter'' is the system model and the communication mechanisms must be supported by standard, flexible, and friendly modeling languages. The evolving model-based systems engineering (MBSE) approach is leading the way and is expected to become a standard practice in the field of systems engineering (SE) in the next decade. As an emerging paradigm for the systems of the 21st century, it seems useful to overview its current state of the art concerning the developing standards, the embryonic formalisms, the available modeling languages, the methodologies, and the major applications.},
  langid = {english},
}

@misc{rangelSPARQLGenerationAnalysis2024,
  title = {{{SPARQL Generation}}: An Analysis on Fine-Tuning {{OpenLLaMA}} for {{Question Answering}} over a {{Life Science Knowledge Graph}}},
  shorttitle = {{{SPARQL Generation}}},
  author = {Rangel, Julio C. and {Mendes de Farias} and Sima, Ana Claudia and Kobayashi, Norio},
  year = {2024},
  month = feb,
  publisher = {arXiv},
  doi = {10.48550/arXiv.2402.04627},
  urldate = {2024-05-27},
  abstract = {The recent success of Large Language Models (LLM) in a wide range of Natural Language Processing applications opens the path towards novel Question Answering Systems over Knowledge Graphs leveraging LLMs. However, one of the main obstacles preventing their implementation is the scarcity of training data for the task of translating questions into corresponding SPARQL queries, particularly in the case of domain-specific KGs. To overcome this challenge, in this study, we evaluate several strategies for fine-tuning the OpenLlama LLM for question answering over life science knowledge graphs. In particular, we propose an end-to-end data augmentation approach for extending a set of existing queries over a given knowledge graph towards a larger dataset of semantically enriched question-to-SPARQL query pairs, enabling fine-tuning even for datasets where these pairs are scarce. In this context, we also investigate the role of semantic "clues" in the queries, such as meaningful variable names and inline comments. Finally, we evaluate our approach over the real-world Bgee gene expression knowledge graph and we show that semantic clues can improve model performance by up to 33\% compared to a baseline with random variable names and no comments included.},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Databases,Computer Science - Information Retrieval},
}

@misc{raviDocuBotGeneratingFinancial2021,
  title = {{{DocuBot}} : {{Generating}} Financial Reports Using Natural Language Interactions},
  shorttitle = {{{DocuBot}}},
  author = {Ravi, Vineeth and Amrouni, Selim and Stefanucci, Andrea and Nourbakhsh, Armineh and Reddy, Prashant and Veloso, Manuela},
  year = {2021},
  month = feb,
  eprint = {2010.01169},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2010.01169},
  urldate = {2024-01-17},
  abstract = {The financial services industry perpetually processes an overwhelming amount of complex data. Digital reports are often created based on tedious manual analysis as well as visualization of the underlying trends and characteristics of data. Often, the accruing costs of human computation errors in creating these reports are very high. We present DocuBot, a novel AI-powered virtual assistant for creating and modifying content in digital documents by modeling natural language interactions as ``skills'' and using them to transform underlying data. DocuBot has the ability to agglomerate saved skills for reuse, enabling humans to automatically generate recurrent reports. DocuBot also has the capability to continuously learn domain-specific and user-specific vocabulary by interacting with the user. We present evidence that DocuBot adds value to the financial industry and demonstrate its impact with experiments involving real and simulated users tasked with creating PowerPoint presentations.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computation and Language},
}

@inproceedings{rayFastDomainAdaptation2019,
  title = {Fast {{Domain Adaptation}} of {{Semantic Parsers}} via {{Paraphrase Attention}}},
  booktitle = {Proceedings of the 2nd {{Workshop}} on {{Deep Learning Approaches}} for {{Low-Resource NLP}} ({{DeepLo}} 2019)},
  author = {Ray, Avik and Shen, Yilin and Jin, Hongxia},
  editor = {Cherry, Colin and Durrett, Greg and Foster, George and Haffari, Reza and Khadivi, Shahram and Peng, Nanyun and Ren, Xiang and Swayamdipta, Swabha},
  year = {2019},
  month = nov,
  pages = {94--103},
  publisher = {Association for Computational Linguistics},
  address = {Hong Kong, China},
  doi = {10.18653/v1/D19-6111},
  urldate = {2024-11-22},
  abstract = {Semantic parsers are used to convert user's natural language commands to executable logical form in intelligent personal agents. Labeled datasets required to train such parsers are expensive to collect, and are never comprehensive. As a result, for effective post-deployment domain adaptation and personalization, semantic parsers are continuously retrained to learn new user vocabulary and paraphrase variety. However, state-of-the art attention based neural parsers are slow to retrain which inhibits real time domain adaptation. Secondly, these parsers do not leverage numerous paraphrases already present in the training dataset. Designing parsers which can simultaneously maintain high accuracy and fast retraining time is challenging. In this paper, we present novel paraphrase attention based sequence-to-sequence/tree parsers which support fast near real time retraining. In addition, our parsers often boost accuracy by jointly modeling the semantic dependencies of paraphrases. We evaluate our model on benchmark datasets to demonstrate upto 9X speedup in retraining time compared to existing parsers, as well as achieving state-of-the-art accuracy.},
  annotation = {Read\_Status: To Read\\
Read\_Status\_Date: 2024-11-22T16:51:12.752Z},
}

@article{reddyLargescaleSemanticParsing2014,
  title = {Large-Scale {{Semantic Parsing}} without {{Question-Answer Pairs}}},
  author = {Reddy, Siva and Lapata, Mirella and Steedman, Mark},
  editor = {Lin, Dekang and Collins, Michael and Lee, Lillian},
  year = {2014},
  journal = {Transactions of the Association for Computational Linguistics},
  volume = {2},
  pages = {377--392},
  publisher = {MIT Press},
  address = {Cambridge, MA},
  doi = {10.1162/tacl_a_00190},
  urldate = {2024-11-22},
  abstract = {In this paper we introduce a novel semantic parsing approach to query Freebase in natural language without requiring manual annotations or question-answer pairs. Our key insight is to represent natural language via semantic graphs whose topology shares many commonalities with Freebase. Given this representation, we conceptualize semantic parsing as a graph matching problem. Our model converts sentences to semantic graphs using CCG and subsequently grounds them to Freebase guided by denotations as a form of weak supervision. Evaluation experiments on a subset of the Free917 and WebQuestions benchmark datasets show our semantic parser improves over the state of the art.},
}

@misc{reimersSentenceBERTSentenceEmbeddings2019,
  title = {Sentence-{{BERT}}: {{Sentence Embeddings}} Using {{Siamese BERT-Networks}}},
  shorttitle = {Sentence-{{BERT}}},
  author = {Reimers, Nils and Gurevych, Iryna},
  year = {2019},
  month = aug,
  number = {arXiv:1908.10084},
  eprint = {1908.10084},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1908.10084},
  urldate = {2024-05-30},
  abstract = {BERT (Devlin et al., 2018) and RoBERTa (Liu et al., 2019) has set a new state-of-the-art performance on sentence-pair regression tasks like semantic textual similarity (STS). However, it requires that both sentences are fed into the network, which causes a massive computational overhead: Finding the most similar pair in a collection of 10,000 sentences requires about 50 million inference computations ({\textasciitilde}65 hours) with BERT. The construction of BERT makes it unsuitable for semantic similarity search as well as for unsupervised tasks like clustering.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computation and Language},
}

@inproceedings{RelevantSubgraphExtraction,
  title = {Relevant Subgraph Extraction from Random Walks in a Graph},
}

@misc{renFindingMinimumConnected2020,
  title = {Finding {{Minimum Connected Subgraphs}} with {{Ontology Exploration}} on {{Large RDF Data}}},
  author = {Ren, Xiangnan and Sengupta, Neha and Ren, Xuguang and Wang, Junhu and Cur{\'e}, Olivier},
  year = {2020},
  month = oct,
  number = {arXiv:2010.06336},
  eprint = {2010.06336},
  primaryclass = {cs},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/2010.06336},
  urldate = {2024-07-10},
  abstract = {In this paper, we study the following problem: given a knowledge graph (KG) and a set of input vertices (representing concepts or entities) and edge labels, we aim to find the smallest connected subgraphs containing all of the inputs. This problem plays a key role in KG-based search engines and natural language question answering systems, and it is a natural extension of the Steiner tree problem, which is known to be NP-hard. We present RECON, a system for finding approximate answers. RECON aims at achieving high accuracy with instantaneous response (i.e., sub-second/millisecond delay) over KGs with hundreds of millions edges without resorting to expensive computational resources. Furthermore, when no answer exists due to disconnection between concepts and entities, RECON refines the input to a semantically similar one based on the ontology, and attempt to find answers with respect to the refined input. We conduct a comprehensive experimental evaluation of RECON. In particular we compare it with five existing approaches for finding approximate Steiner trees. Our experiments on four large real and synthetic KGs show that RECON significantly outperforms its competitors and incurs a much smaller memory footprint.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Databases},
}

@article{renFindingMinimumConnected2023,
  title = {Finding {{Minimum Connected Subgraphs With Ontology Exploration}} on {{Large RDF Data}}},
  author = {Ren, Xiangnan and Sengupta, Neha and Ren, Xuguang and Wang, Junhu and Cur{\'e}, Olivier},
  year = {2023},
  month = nov,
  journal = {IEEE Transactions on Knowledge and Data Engineering},
  volume = {35},
  number = {11},
  pages = {11403--11418},
  issn = {1558-2191},
  doi = {10.1109/TKDE.2022.3225076},
  urldate = {2024-08-30},
  abstract = {In this paper, we study the following problem: given a knowledge graph (KG) and a set of input vertices (representing concepts or entities) and edge labels, we aim to find the smallest connected subgraphs containing all of the inputs. This problem plays a key role in KG-based search engines and natural language question answering systems, and it is a natural extension of the Steiner tree problem, which is known to be NP-hard. We present RECON, a system for finding approximate answers. RECON aims at achieving high accuracy with instantaneous response (i.e., sub-second/millisecond delay) over KGs with hundreds of millions edges without resorting to expensive computational resources. Furthermore, when no answer exists due to disconnection between concepts and entities, RECON refines the input to a semantically similar one based on the ontology, and attempts to find answers with respect to the refined input. We conduct a comprehensive experimental evaluation of RECON. In particular we compare it with five existing approaches for finding approximate Steiner trees. Our experiments on four large real and synthetic KGs show that RECON significantly outperforms its competitors and incurs a much smaller memory footprint.},
  keywords = {Cognition,Engines,Indexes,Keyword search,knowledge graph,Ontologies,ontology,reasoning,Resource description framework,Steiner trees,Task analysis},
}

@inproceedings{reydAssessingGeneralizationCapabilities2023,
  title = {Assessing the~{{Generalization Capabilities}} of~{{Neural Machine Translation Models}} for~{{SPARQL Query Generation}}},
  booktitle = {The {{Semantic Web}} -- {{ISWC}} 2023: 22nd {{International Semantic Web Conference}}, {{Athens}}, {{Greece}}, {{November}} 6--10, 2023, {{Proceedings}}, {{Part I}}},
  author = {Reyd, Samuel and Zouaq, Amal},
  year = {2023},
  month = nov,
  pages = {484--501},
  publisher = {Springer-Verlag},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-031-47240-4_26},
  urldate = {2024-05-29},
  abstract = {Recent studies in the field of Neural Machine Translation for SPARQL query generation have shown rapidly rising performance. State-of-the-art models have reached almost perfect query generation for simple datasets. However, such progress raises the question of the ability of these models to generalize and deal with unseen question-query structures and entities. In this work, we propose copy-enhanced pre-trained models with question annotation and test the ability of several models to handle unknown question-query structures and URIs. To do so, we split two popular datasets based on unknown URIs and question-query structures. Our results show that the copy mechanism effectively allows non-pre-trained models to deal with unknown URIs, and that it also improves the results of some pre-trained models. Our results also show that, when exposed to unknown question-query structures on a simple dataset, pre-trained models significantly outperform non-pre-trained models, but both non-pre-trained and pre-trained models have a considerable drop in performance on a harder dataset. However, the copy mechanism significantly boosts the results of non-pre-trained models on all settings and of the BART pre-trained model, except for the template split on LC-QuAD 2.0 dataset.},
  isbn = {978-3-031-47239-8},
  keywords = {Generalization,Out-of-vocabulary problem,SPARQL query generation,Unknown templates,Unknown URIs},
}

@misc{rhedogianChangeMyView2024,
  type = {Reddit {{Post}}},
  title = {Change {{My View}}: {{Model Based Systems Engineering}} in 2024 Is at Best Overhyped, or Is at Worst Actively Dying},
  shorttitle = {Change {{My View}}},
  author = {Rhedogian},
  year = {2024},
  month = mar,
  journal = {r/systems\_engineering},
  url = {www.reddit.com/r/systems_engineering/comments/1bpavpi/change_my_view_model_based_systems_engineering_in/},
  urldate = {2024-11-20},
}

@article{rogersQADatasetExplosion2023,
  title = {{{QA Dataset Explosion}}: {{A Taxonomy}} of {{NLP Resources}} for {{Question Answering}} and {{Reading Comprehension}}},
  shorttitle = {{{QA Dataset Explosion}}},
  author = {Rogers, Anna and Gardner, Matt and Augenstein, Isabelle},
  year = {2023},
  month = oct,
  journal = {ACM Computing Surveys},
  volume = {55},
  number = {10},
  pages = {1--45},
  issn = {0360-0300, 1557-7341},
  doi = {10.1145/3560260},
  urldate = {2024-03-07},
  abstract = {Alongside huge volumes of research on deep learning models in NLP in the recent years, there has been much work on benchmark datasets needed to track modeling progress. Question answering and reading comprehension have been particularly prolific in this regard, with more than 80 new datasets appearing in the past 2 years. This study is the largest survey of the field to date. We provide an overview of the various formats and domains of the current resources, highlighting the current lacunae for future work. We further discuss the current classifications of ``skills'' that question answering/reading comprehension systems are supposed to acquire and propose a new taxonomy. The supplementary materials survey the current multilingual resources and monolingual resources for languages other than English, and we discuss the implications of overfocusing on English. The study is aimed at both practitioners looking for pointers to the wealth of existing data and at researchers working on new resources.},
  langid = {english},
}

@misc{rohantaoriAlpacaStrongReplicable2024,
  title = {Alpaca: {{A Strong}}, {{Replicable Instruction-Following Model}}},
  shorttitle = {Alpaca},
  author = {{Rohan Taori} and {Ishaan Gulrajani} and {Tianyi Zhang} and {Yann Dubois} and {Xuechen Li} and {Carlos Guestrin} and {Percy Liang} and {Tatsunori B. Hashimoto}},
  year = {2024},
  journal = {Stanford CRFM},
  url = {https://crfm.stanford.edu/2023/03/13/alpaca.html},
  urldate = {2024-08-23},
  langid = {english},
}

@inproceedings{rongaliDontParseGenerate2020,
  title = {Don't {{Parse}}, {{Generate}}! {{A Sequence}} to {{Sequence Architecture}} for {{Task-Oriented Semantic Parsing}}},
  booktitle = {Proceedings of {{The Web Conference}} 2020},
  author = {Rongali, Subendhu and Soldaini, Luca and Monti, Emilio and Hamza, Wael},
  year = {2020},
  month = apr,
  series = {{{WWW}} '20},
  pages = {2962--2968},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3366423.3380064},
  urldate = {2024-11-24},
  abstract = {Virtual assistants such as Amazon Alexa, Apple Siri, and Google Assistant often rely on a semantic parsing component to understand which action(s) to execute for an utterance spoken by its users. Traditionally, rule-based or statistical slot-filling systems have been used to parse ``simple'' queries; that is, queries that contain a single action and can be decomposed into a set of non-overlapping entities. More recently, shift-reduce parsers have been proposed to process more complex utterances. These methods, while powerful, impose specific limitations on the type of queries that can be parsed; namely, they require a query to be representable as a parse tree. In this work, we propose a unified architecture based on Sequence to Sequence models and Pointer Generator Network to handle both simple and complex queries. Unlike other works, our approach does not impose any restriction on the semantic parse schema. Furthermore, experiments show that it achieves state of the art performance on three publicly available datasets (ATIS, SNIPS, Facebook TOP), relatively improving between 3.3\% and 7.7\% in exact match accuracy over previous systems. Finally, we show the effectiveness of our approach on two internal datasets.},
  isbn = {978-1-4503-7023-3},
}

@article{ronySGPTGenerativeApproach2022,
  title = {{{SGPT}}: {{A Generative Approach}} for {{SPARQL Query Generation From Natural Language Questions}}},
  shorttitle = {{{SGPT}}},
  author = {Rony, Md Rashad Al Hasan and Kumar, Uttam and Teucher, Roman and Kovriguina, Liubov and Lehmann, Jens},
  year = {2022},
  journal = {IEEE Access},
  volume = {10},
  pages = {70712--70723},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2022.3188714},
  urldate = {2024-01-16},
  abstract = {SPARQL query generation from natural language questions is complex because it requires an understanding of both the question and underlying knowledge graph (KG) patterns. Most SPARQL query generation approaches are template-based, tailored to a specific knowledge graph and require pipelines with multiple steps, including entity and relation linking. Template-based approaches are also difficult to adapt for new KGs and require manual efforts from domain experts to construct query templates. To overcome this hurdle, we propose a new approach, dubbed SGPT, that combines the benefits of end-to-end and modular systems and leverages recent advances in large-scale language models. Specifically, we devise a novel embedding technique that can encode linguistic features from the question which enables the system to learn complex question patterns. In addition, we propose training techniques that allow the system to implicitly employ the graph-specific information (i.e., entities and relations) into the language model's parameters and generate SPARQL queries accurately. Finally, we introduce a strategy to adapt standard automatic metrics for evaluating SPARQL query generation. A comprehensive evaluation demonstrates the effectiveness of SGPT over state-of-the-art methods across several benchmark datasets.},
  langid = {english},
}

@article{ronyTreeKGQAUnsupervisedApproach2022,
  title = {Tree-{{KGQA}}: {{An Unsupervised Approach}} for {{Question Answering Over Knowledge Graphs}}},
  shorttitle = {Tree-{{KGQA}}},
  author = {Rony, Md Rashad Al Hasan and Chaudhuri, Debanjan and Usbeck, Ricardo and Lehmann, Jens},
  year = {2022},
  journal = {IEEE Access},
  volume = {10},
  pages = {50467--50478},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2022.3173355},
  urldate = {2024-05-27},
  abstract = {Most Knowledge Graph-based Question Answering (KGQA) systems rely on training data to reach their optimal performance. However, acquiring training data for supervised systems is both time-consuming and resource-intensive. To address this, in this paper, we propose Tree-KGQA, an unsupervised KGQA system leveraging pre-trained language models and tree-based algorithms. Entity and relation linking are essential components of any KGQA system. We employ several pre-trained language models in the entity linking task to recognize the entities mentioned in the question and obtain the contextual representation for indexing. Furthermore, for relation linking we incorporate a pre-trained language model previously trained for language inference task. Finally, we introduce a novel algorithm for extracting the answer entities from a KG, where we construct a forest of interpretations and introduce tree-walking and tree disambiguation techniques. Our algorithm uses the linked relation and predicts the tree branches that eventually lead to the potential answer entities. The proposed method achieves 4.5\% and 7.1\% gains in F1 score in entity linking tasks on LC-QuAD 2.0 and LC-QuAD 2.0 (KBpearl) datasets, respectively, and a 5.4\% increase in the relation linking task on LC-QuAD 2.0 (KBpearl). The comprehensive evaluations demonstrate that our unsupervised KGQA approach outperforms other supervised state-of-the-art methods on the WebQSP-WD test set (1.4\% increase in F1 score) - without training on the target dataset.},
  copyright = {https://creativecommons.org/licenses/by/4.0/legalcode},
  langid = {english},
}

@misc{royMaximumCommonSubgraph2022,
  title = {Maximum {{Common Subgraph Guided Graph Retrieval}}: {{Late}} and {{Early Interaction Networks}}},
  shorttitle = {Maximum {{Common Subgraph Guided Graph Retrieval}}},
  author = {Roy, Indradyumna and Chakrabarti, Soumen and De, Abir},
  year = {2022},
  month = oct,
  number = {arXiv:2210.11020},
  eprint = {2210.11020},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2210.11020},
  urldate = {2024-12-04},
  abstract = {The graph retrieval problem is to search in a large corpus of graphs for ones that are most similar to a query graph. A common consideration for scoring similarity is the maximum common subgraph (MCS) between the query and corpus graphs, usually counting the number of common edges (i.e., MCES). In some applications, it is also desirable that the common subgraph be connected, i.e., the maximum common connected subgraph (MCCS). Finding exact MCES and MCCS is intractable, but may be unnecessary if ranking corpus graphs by relevance is the goal. We design fast and trainable neural functions that approximate MCES and MCCS well. Late interaction methods compute dense representations for the query and corpus graph separately, and compare these representations using simple similarity functions at the last stage, leading to highly scalable systems. Early interaction methods combine information from both graphs right from the input stages, are usually considerably more accurate, but slower. We propose both late and early interaction neural MCES and MCCS formulations. They are both based on a continuous relaxation of a node alignment matrix between query and corpus nodes. For MCCS, we propose a novel differentiable network for estimating the size of the largest connected common subgraph. Extensive experiments with seven data sets show that our proposals are superior among late interaction models in terms of both accuracy and speed. Our early interaction models provide accuracy competitive with the state of the art, at substantially greater speeds.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Information Retrieval,Computer Science - Machine Learning},
}

@inproceedings{sachanImprovingPassageRetrieval2022,
  title = {Improving {{Passage Retrieval}} with {{Zero-Shot Question Generation}}},
  booktitle = {Proceedings of the 2022 {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}}},
  author = {Sachan, Devendra and Lewis, Mike and Joshi, Mandar and Aghajanyan, Armen and Yih, Wen-tau and Pineau, Joelle and Zettlemoyer, Luke},
  year = {2022},
  pages = {3781--3797},
  publisher = {Association for Computational Linguistics},
  address = {Abu Dhabi, United Arab Emirates},
  doi = {10.18653/v1/2022.emnlp-main.249},
  urldate = {2024-03-01},
  langid = {english},
}

@article{sachanQuestionsAreAll2023,
  title = {Questions {{Are All You Need}} to {{Train}} a {{Dense Passage Retriever}}},
  author = {Sachan, Devendra Singh and Lewis, Mike and Yogatama, Dani and Zettlemoyer, Luke and Pineau, Joelle and Zaheer, Manzil},
  year = {2023},
  month = jun,
  journal = {Transactions of the Association for Computational Linguistics},
  volume = {11},
  pages = {600--616},
  issn = {2307-387X},
  doi = {10.1162/tacl_a_00564},
  urldate = {2024-02-29},
  abstract = {We introduce ART, a new corpus-level autoencoding approach for training dense retrieval models that does not require any labeled training data. Dense retrieval is a central challenge for open-domain tasks, such as Open QA, where state-of-the-art methods typically require large supervised datasets with custom hard-negative mining and denoising of positive examples. ART, in contrast, only requires access to unpaired inputs and outputs (e.g., questions and potential answer passages). It uses a new passage-retrieval autoencoding scheme, where (1) an input question is used to retrieve a set of evidence passages, and (2) the passages are then used to compute the probability of reconstructing the original question. Training for retrieval based on question reconstruction enables effective unsupervised learning of both passage and question encoders, which can be later incorporated into complete Open QA systems without any further finetuning. Extensive experiments demonstrate that ART obtains state-of-the-art results on multiple QA retrieval benchmarks with only generic initialization from a pre-trained language model, removing the need for labeled data and task-specific losses.1Our code and model checkpoints are available at: https://github.com/DevSinghSachan/art.},
}

@misc{sahaCanLanguageModels2023,
  title = {Can {{Language Models Teach Weaker Agents}}? {{Teacher Explanations Improve Students}} via {{Personalization}}},
  shorttitle = {Can {{Language Models Teach Weaker Agents}}?},
  author = {Saha, Swarnadeep and Hase, Peter and Bansal, Mohit},
  year = {2023},
  month = nov,
  number = {arXiv:2306.09299},
  eprint = {2306.09299},
  primaryclass = {cs},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/2306.09299},
  urldate = {2024-06-01},
  abstract = {A hallmark property of explainable AI models is the ability to teach other agents, communicating knowledge of how to perform a task. While Large Language Models perform complex reasoning by generating explanations for their predictions, it is unclear whether they also make good teachers for weaker agents. To address this, we consider a student-teacher framework between two LLM agents and study if, when, and how the teacher should intervene with natural language explanations to improve the student's performance. Since communication is expensive, we define a budget such that the teacher only communicates explanations for a fraction of the data, after which the student should perform well on its own. We decompose the teaching problem along four axes: (1) if teacher's test time intervention improve student predictions, (2) when it is worth explaining a data point, (3) how the teacher should personalize explanations to better teach the student, and (4) if teacher explanations also improve students on future unexplained data. We first show that teacher LLMs can indeed intervene on student reasoning to improve their performance. Next, inspired by the Theory of Mind abilities of effective teachers, we propose building two few-shot mental models of the student. The first model defines an Intervention Function that simulates the utility of an intervention, allowing the teacher to intervene when this utility is the highest and improving student performance at lower budgets. The second model enables the teacher to personalize explanations for a particular student and outperform unpersonalized teachers. We also demonstrate that in multi-turn interactions, teacher explanations generalize and learning from explained data improves student performance on future unexplained data. Finally, we verify that misaligned teachers can lower student performance to random chance by intentionally misleading them.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},
}

@inproceedings{sahaExplaGraphsExplanationGraph2021,
  title = {{{ExplaGraphs}}: {{An Explanation Graph Generation Task}} for {{Structured Commonsense Reasoning}}},
  shorttitle = {{{ExplaGraphs}}},
  booktitle = {Proceedings of the 2021 {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}}},
  author = {Saha, Swarnadeep and Yadav, Prateek and Bauer, Lisa and Bansal, Mohit},
  year = {2021},
  pages = {7716--7740},
  publisher = {Association for Computational Linguistics},
  address = {Online and Punta Cana, Dominican Republic},
  doi = {10.18653/v1/2021.emnlp-main.609},
  urldate = {2024-07-10},
  langid = {english},
}

@article{sanderOntologyBasedTranslationNatural2014,
  title = {Ontology-{{Based Translation}} of {{Natural Language Queries}} to {{SPARQL}}},
  author = {Sander, Malte},
  year = {2014},
  abstract = {We present an implemented approach to transform natural language sentences into SPARQL, using background knowledge from ontologies and lexicons. Therefore, eligible technologies and data storage possibilities are analyzed and evaluated. The contributions of this paper are twofold. Firstly, we describe the motivation and current needs for a natural language access to industry data. We describe several scenarios where the proposed solution is required. Resulting in an architectural approach based on automatic SPARQL query construction for effective natural language queries. Secondly, we analyze the performance of RDBMS, RDF and Triple Stores for the knowledge representation. The proposed approach will be evaluated on the basis of a query catalog by means of query efficiency, accuracy, and data storage performance. The results show, that natural language access to industry data using ontologies and lexicons, is a simple but effective approach to improve the diagnosis process and the data search for a broad range of users. Furthermore, virtual RDF graphs do support the DB-driven knowledge graph representation process, but do not perform efficient under industry conditions in terms of performance and scalability.},
  langid = {english},
}

@inproceedings{satoVocabularyAdaptationDomain2020,
  title = {Vocabulary {{Adaptation}} for {{Domain Adaptation}} in {{Neural Machine Translation}}},
  booktitle = {Findings of the {{Association}} for {{Computational Linguistics}}: {{EMNLP}} 2020},
  author = {Sato, Shoetsu and Sakuma, Jin and Yoshinaga, Naoki and Toyoda, Masashi and Kitsuregawa, Masaru},
  editor = {Cohn, Trevor and He, Yulan and Liu, Yang},
  year = {2020},
  month = nov,
  pages = {4269--4279},
  publisher = {Association for Computational Linguistics},
  address = {Online},
  doi = {10.18653/v1/2020.findings-emnlp.381},
  urldate = {2024-08-26},
  abstract = {Neural network methods exhibit strong performance only in a few resource-rich domains. Practitioners therefore employ domain adaptation from resource-rich domains that are, in most cases, distant from the target domain. Domain adaptation between distant domains (e.g., movie subtitles and research papers), however, cannot be performed effectively due to mismatches in vocabulary; it will encounter many domain-specific words (e.g., ``angstrom'') and words whose meanings shift across domains (e.g., ``conductor''). In this study, aiming to solve these vocabulary mismatches in domain adaptation for neural machine translation (NMT), we propose vocabulary adaptation, a simple method for effective fine-tuning that adapts embedding layers in a given pretrained NMT model to the target domain. Prior to fine-tuning, our method replaces the embedding layers of the NMT model by projecting general word embeddings induced from monolingual data in a target domain onto a source-domain embedding space. Experimental results indicate that our method improves the performance of conventional fine-tuning by 3.86 and 3.28 BLEU points in En-Ja and De-En translation, respectively.},
}

@article{scarselliGraphNeuralNetwork2009,
  title = {The {{Graph Neural Network Model}}},
  author = {Scarselli, F. and Gori, M. and {Ah Chung Tsoi} and Hagenbuchner, M. and Monfardini, G.},
  year = {2009},
  month = jan,
  journal = {IEEE Transactions on Neural Networks},
  volume = {20},
  number = {1},
  pages = {61--80},
  issn = {1045-9227, 1941-0093},
  doi = {10.1109/TNN.2008.2005605},
  urldate = {2024-08-20},
  abstract = {Many underlying relationships among data in several areas of science and engineering, e.g., computer vision, molecular chemistry, molecular biology, pattern recognition, and data mining, can be represented in terms of graphs. In this paper, we propose a new neural network model, called graph neural network (GNN) model, that extends existing neural network methods for processing the data represented in graph domains. This GNN model, which can directly process most of the practically useful types of graphs, e.g., acyclic, cyclic, directed, and undirected, implements a function   that maps a graph and one of its nodes into an -dimensional Euclidean space. A supervised learning algorithm is derived to estimate the parameters of the proposed GNN model. The computational cost of the proposed algorithm is also considered. Some experimental results are shown to validate the proposed learning algorithm, and to demonstrate its generalization capabilities.},
  copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
  langid = {english},
  keywords = {Formalization,GNN},
}

@misc{schatzleS2RDFRDFQuerying2016,
  title = {{{S2RDF}}: {{RDF Querying}} with {{SPARQL}} on {{Spark}}},
  shorttitle = {{{S2RDF}}},
  author = {Sch{\"a}tzle, Alexander and {Przyjaciel-Zablocki}, Martin and Skilevic, Simon and Lausen, Georg},
  year = {2016},
  month = jan,
  publisher = {arXiv},
  doi = {10.48550/arXiv.1512.07021},
  urldate = {2024-12-03},
  abstract = {RDF has become very popular for semantic data publishing due to its flexible and universal graph-like data model. Yet, the ever-increasing size of RDF data collections makes it more and more infeasible to store and process them on a single machine, raising the need for distributed approaches. Instead of building a standalone but closed distributed RDF store, we endorse the usage of existing infrastructures for Big Data processing, e.g. Hadoop. However, SPARQL query performance is a major challenge as these platforms are not designed for RDF processing from ground. Thus, existing Hadoop-based approaches often favor certain query pattern shape while performance drops significantly for other shapes. In this paper, we describe a novel relational partitioning schema for RDF data called ExtVP that uses a semi-join based preprocessing, akin to the concept of Join Indices in relational databases, to efficiently minimize query input size regardless of its pattern shape and diameter. Our prototype system S2RDF is built on top of Spark and uses its relational interface to execute SPARQL queries over ExtVP. We demonstrate its superior performance in comparison to state of the art SPARQL-on-Hadoop approaches using the recent WatDiv test suite. S2RDF achieves sub-second runtimes for majority of queries on a billion triples RDF graph.},
  keywords = {Computer Science - Databases,Computer Science - Distributed Parallel and Cluster Computing},
}

@article{seegerComplementarityEigenvalueAnalysis2018,
  title = {Complementarity Eigenvalue Analysis of Connected Graphs},
  author = {Seeger, Alberto},
  year = {2018},
  month = apr,
  journal = {Linear Algebra and its Applications},
  volume = {543},
  pages = {205--225},
  issn = {0024-3795},
  doi = {10.1016/j.laa.2017.12.021},
  urldate = {2024-08-07},
  abstract = {This work concerns the spectral analysis of connected graphs from a non-traditional point of view. Instead of the usual eigenvalues of the adjacency matrix AG of a graph G under consideration, we compute and analyze the complementarity eigenvalues of AG. The complementarity eigenvalues of a general square matrix are defined in terms of a certain complementarity system relative to the componentwise ordering. The complementarity eigenvalues of AG form the so-called complementarity spectrum of G. In general, the structure of a connected graph is better discriminated in terms of its complementarity spectrum than in terms of its usual spectrum. This observation is one of the leading motivation behind our work.},
  keywords = {Complementarity eigenvalue analysis,Connected graphs,Connected induced subgraphs,Second largest complementarity eigenvalue,Spectral radius},
}

@article{SemanticParsing2024,
  title = {Semantic Parsing},
  year = {2024},
  month = apr,
  journal = {Wikipedia},
  url = {https://en.wikipedia.org/w/index.php?title=Semantic_parsing&oldid=1220612743},
  urldate = {2024-11-22},
  abstract = {Semantic parsing is the task of converting a natural language utterance to a logical form: a machine-understandable representation of its meaning. Semantic parsing can thus be understood as extracting the precise meaning of an utterance. Applications of semantic parsing include machine translation, question answering, ontology induction, automated reasoning, and code generation. The phrase was first used in the 1970s by Yorick Wilks as the basis for machine translation programs working with only semantic representations. Semantic parsing is one of the important tasks in computational linguistics and natural language processing. Semantic parsing maps text to formal meaning representations. This contrasts with semantic role labeling and other forms of shallow semantic processing, which do not aim to produce complete formal meanings. In computer vision, semantic parsing is a process of segmentation for 3D objects.},
  copyright = {Creative Commons Attribution-ShareAlike License},
  langid = {english},
  annotation = {Page Version ID: 1220612743},
}

@misc{semlasymposiumsSoftwareEngineeringMachine2024,
  title = {Software {{Engineering}} for {{Machine Learning Applications}} ({{SEMLA}}) International Symposium -- {{SEMLA2024}}},
  author = {{SEMLA Symposiums}},
  year = {2024},
  url = {https://www.youtube.com/watch?v=YY3RM3bnNvc},
  urldate = {2024-08-23},
  annotation = {Start time: 07:16:00}
}

@inproceedings{shakeriEndEndSyntheticData2020,
  title = {End-to-{{End Synthetic Data Generation}} for {{Domain Adaptation}} of {{Question Answering Systems}}},
  booktitle = {Proceedings of the 2020 {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}} ({{EMNLP}})},
  author = {Shakeri, Siamak and {Nogueira dos Santos}, Cicero and Zhu, Henghui and Ng, Patrick and Nan, Feng and Wang, Zhiguo and Nallapati, Ramesh and Xiang, Bing},
  editor = {Webber, Bonnie and Cohn, Trevor and He, Yulan and Liu, Yang},
  year = {2020},
  month = nov,
  pages = {5445--5460},
  publisher = {Association for Computational Linguistics},
  address = {Online},
  doi = {10.18653/v1/2020.emnlp-main.439},
  urldate = {2024-08-26},
  abstract = {We propose an end-to-end approach for synthetic QA data generation. Our model comprises a single transformer-based encoder-decoder network that is trained end-to-end to generate both answers and questions. In a nutshell, we feed a passage to the encoder and ask the decoder to generate a question and an answer token-by-token. The likelihood produced in the generation process is used as a filtering score, which avoids the need for a separate filtering model. Our generator is trained by fine-tuning a pretrained LM using maximum likelihood estimation. The experimental results indicate significant improvements in the domain adaptation of QA models outperforming current state-of-the-art methods.},
  annotation = {Read\_Status: To Read\\
Read\_Status\_Date: 2024-10-10T15:16:19.986Z},
}

@misc{shamesFrameworkModelingSpace2006,
  title = {Towards a {{Framework}} for {{Modeling Space Systems Architectures}}},
  author = {Shames, Peter and Skipper, Joseph},
  year = {2006},
  month = may,
  publisher = {NASA Jet Propulsion Laboratory, California Institute of Technology},
  url = {https://web.archive.org/web/20100527225452/http://trs-new.jpl.nasa.gov/dspace/bitstream/2014/39798/1/06-1543.pdf},
  urldate = {2025-01-02},
}

@article{shaRetrievalAugmentedKnowledgeGraph2023,
  title = {Retrieval-{{Augmented Knowledge Graph Reasoning}} for {{Commonsense Question Answering}}},
  author = {Sha, Yuchen and Feng, Yujian and He, Miao and Liu, Shangdong and Ji, Yimu},
  year = {2023},
  month = jul,
  journal = {Mathematics},
  volume = {11},
  number = {15},
  pages = {3269},
  issn = {2227-7390},
  doi = {10.3390/math11153269},
  urldate = {2024-03-06},
  abstract = {Existing knowledge graph (KG) models for commonsense question answering present two challenges: (i) existing methods retrieve entities related to questions from the knowledge graph, which may extract noise and irrelevant nodes, and (ii) there is a lack of interaction representation between questions and graph entities. However, current methods mainly focus on retrieving relevant entities with some noisy and irrelevant nodes. In this paper, we propose a novel retrieval-augmented knowledge graph (RAKG) model, which solves the above issues using two key innovations. First, we leverage the density matrix to make the model reason along the corrected knowledge path and extract an enhanced subgraph of the knowledge graph. Second, we fuse representations of questions and graph entities through a bidirectional attention strategy, in which two representations fuse and update using a graph convolutional network (GCN). To evaluate the performance of our method, we conducted experiments on two widely used benchmark datasets: CommonsenseQA and OpenBookQA. The case study gives insight into the finding that the augmented subgraph provides reasoning along the corrected knowledge path for question answering.},
  langid = {english},
}

@article{shekarpourGeneratingSPARQLQueries2013,
  title = {Generating {{SPARQL}} Queries Using Templates},
  author = {Shekarpour, Saeedeh and Auer, S{\"o}ren and Ngonga Ngomo, Axel-Cyrille and Gerber, Daniel and Hellmann, Sebastian and Stadler, Claus},
  year = {2013},
  journal = {Web Intelligence and Agent Systems: An International Journal},
  volume = {11},
  number = {3},
  pages = {283--295},
  issn = {15701263},
  doi = {10.3233/WIA-130275},
  urldate = {2024-08-17},
  abstract = {The search for information on the Web of Data is becoming increasingly difficult due to its considerable growth. Especially novice users need to acquire both knowledge about the underlying ontology structure and proficiency in formulating formal queries (e.g. SPARQL queries) to retrieve information from Linked Data sources. So as to simplify and automate the querying and retrieval of information from such sources, this paper presents an approach for constructing SPARQL queries based on user-supplied keywords. Our approach utilizes a set of predefined basic graph pattern templates for generating adequate interpretations of user queries. This is achieved by obtaining ranked lists of candidate resource identifiers for the supplied keywords and then injecting these identifiers into suitable positions in the graph pattern templates. The main advantages of our approach are that it is completely agnostic of the underlying knowledge base and ontology schema, that it scales to large knowledge bases and is simple to use. We evaluate all 17 possible valid graph pattern templates by measuring their precision and recall on 53 queries against DBpedia. Our results show that 8 of these basic graph pattern templates return results with a precision above 70\%. Our approach is implemented as a Web search interface and performs sufficiently fast to provide answers within an acceptable time frame even when used on large knowledge bases.},
  langid = {english},
}

@article{shekarQuestionAnswerExtraction,
  title = {Question and {{Answer Extraction Using NLP}}},
  author = {Shekar, Akash},
  langid = {english},
}

@misc{shettyDeployingPythonFlask2020,
  title = {Deploying a {{Python}} 3 {{Flask}} App into {{AWS}} Using {{Apache2}}/{{WSGI}}},
  author = {Shetty, Prithvi},
  year = {2020},
  month = may,
  journal = {Medium},
  url = {https://medium.com/@prithvishetty/deploying-a-python-3-flask-app-into-aws-using-apache2-wsgi-1b26ed29c6c2},
  urldate = {2024-08-29},
  abstract = {Steps:},
  langid = {english},
}

@article{simaBioSODAUXEnabling2022,
  title = {Bio-{{SODA UX}}: Enabling Natural Language Question Answering over Knowledge Graphs with User Disambiguation},
  shorttitle = {Bio-{{SODA UX}}},
  author = {Sima, Ana Claudia and {Mendes de Farias}, Tarcisio and Anisimova, Maria and Dessimoz, Christophe and {Robinson-Rechavi}, Marc and Zbinden, Erich and Stockinger, Kurt},
  year = {2022},
  month = sep,
  journal = {Distributed and Parallel Databases},
  volume = {40},
  number = {2},
  pages = {409--440},
  issn = {1573-7578},
  doi = {10.1007/s10619-022-07414-w},
  urldate = {2024-12-09},
  abstract = {The problem of natural language processing over structured data has become a growing research field, both within the relational database and the Semantic Web community, with significant efforts involved in question answering over knowledge graphs (KGQA). However, many of these approaches are either specifically targeted at open-domain question answering using DBpedia, or require large training datasets to translate a natural language question to SPARQL in order to query the knowledge graph. Hence, these approaches often cannot be applied directly to complex scientific datasets where no prior training data is available. In this paper, we focus on the challenges of natural language processing over knowledge graphs of scientific datasets. In particular, we introduce Bio-SODA, a natural language processing engine that does not require training data in the form of question-answer pairs for generating SPARQL queries. Bio-SODA uses a generic graph-based approach for translating user questions to a ranked list of SPARQL candidate queries. Furthermore, Bio-SODA uses a novel ranking algorithm that includes node centrality as a measure of relevance for selecting the best SPARQL candidate query. Our experiments with real-world datasets across several scientific domains, including the official bioinformatics Question Answering over Linked Data (QALD) challenge, as well as the CORDIS dataset of European projects, show that Bio-SODA outperforms publicly available KGQA systems by an F1-score of least 20\% and by an even higher factor on more complex bioinformatics datasets. Finally, we introduce Bio-SODA UX, a graphical user interface designed to assist users in the exploration of large knowledge graphs and in dynamically disambiguating natural language questions that target the data available in these graphs.},
  langid = {english},
  keywords = {Knowledge graphs,Question answering,Ranking},
}

@inproceedings{simitsisNaturalLanguageReporting2008,
  title = {Natural Language Reporting for {{ETL}} Processes},
  booktitle = {Proceedings of the {{ACM}} 11th International Workshop on {{Data}} Warehousing and {{OLAP}}},
  author = {Simitsis, Alkis and Skoutas, Dimitrios and Castellanos, Mal{\'u}},
  year = {2008},
  month = oct,
  series = {{{DOLAP}} '08},
  pages = {65--72},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/1458432.1458444},
  urldate = {2024-08-05},
  abstract = {The conceptual design of the Extract -- Transform -- Load (ETL) processes is a crucial, burdensome, and challenging procedure that takes places at the early phases of a Data Warehouse project. Several models have been proposed for the conceptual design and representation of ETL processes, but all share two inconveniences: they require intensive human effort from the designers to create them, as well as technical knowledge from the business people to understand them. In a previous work, we have relaxed the former difficulty by working on the automation of the conceptual design leveraging Semantic Web technology. In this paper, we built upon our previous results and we tackle the second issue by investigating the application of natural language generation techniques to the ETL environment. In particular, we provide a method for the representation of a conceptual ETL design as a narrative, which is the most natural means of communication and does not require knowledge of any specific model. We discuss how linguistic techniques can be used for the establishment of a common application vocabulary. Finally, we present a flexible and customizable template-based mechanism for generating natural language representations for the ETL process requirements and operations.},
  isbn = {978-1-60558-250-4},
  keywords = {Evaluation,Extract Transform Load}
}

@incollection{simperlAchievingMaturityState2009,
  title = {Achieving {{Maturity}}: {{The State}} of {{Practice}} in {{Ontology Engineering}} in 2009},
  shorttitle = {Achieving {{Maturity}}},
  booktitle = {On the {{Move}} to {{Meaningful Internet Systems}}: {{OTM}} 2009},
  author = {Simperl, Elena and Mochol, Malgorzata and B{\"u}rger, Tobias and Popov, Igor O.},
  editor = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Doug and Vardi, Moshe Y. and Weikum, Gerhard and Meersman, Robert and Dillon, Tharam and Herrero, Pilar},
  year = {2009},
  volume = {5871},
  pages = {983--991},
  publisher = {Springer Berlin Heidelberg},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-642-05151-7_17},
  urldate = {2024-05-27},
  isbn = {978-3-642-05151-7},
  langid = {english},
}

@article{simsekKnowledgeGraphPerspective2022,
  title = {A {{Knowledge Graph Perspective}} on {{Knowledge Engineering}}},
  author = {Simsek, Umutcan and K{\"a}rle, Elias and Angele, Kevin and Huaman, Elwin and Opdenplatz, Juliette and Sommer, Dennis and Umbrich, J{\"u}rgen and Fensel, Dieter},
  year = {2022},
  month = oct,
  journal = {SN Computer Science},
  volume = {4},
  number = {1},
  pages = {16},
  issn = {2661-8907},
  doi = {10.1007/s42979-022-01429-x},
  urldate = {2024-08-17},
  abstract = {For over 50 years researchers and practitioners have searched for ways to elicit and formalize expert knowledge to support AI applications. Expert systems and knowledge bases were all results of these efforts. The initial efforts on knowledge bases were focused on defining a domain and task intensionally with rather complex ontologies. The increasing complexity of knowledge and knowledge-based systems eventually led to the development of knowledge engineering methodologies. Knowledge graphs, in contrast to the traditional knowledge bases, represent knowledge more extensionally with a very large set of explicit statements and rather simpler and smaller ontologies. This paradigm change calls for a new take on knowledge engineering that focuses on the curation of ABox statements. In this paper, we introduce various aspects of the knowledge graphs lifecycle namely creation, hosting, curation and deployment. We define each task, give example approaches from the literature and explain our approach with a running example. Additionally, we present the German Tourism Knowledge Graph that is being implemented with our methodology.},
  langid = {english},
}

@article{siriwardhanaHowFinetuneEntire,
  title = {How to {{Finetune}} the {{Entire RAG Architecture}} (Including {{DPR}} Retriever)},
  author = {Siriwardhana, Shamane},
  langid = {english},
}

@article{siriwardhanaImprovingDomainAdaptation2023,
  title = {Improving the {{Domain Adaptation}} of {{Retrieval Augmented Generation}} ({{RAG}}) {{Models}} for {{Open Domain Question Answering}}},
  author = {Siriwardhana, Shamane and Weerasekera, Rivindu and Wen, Elliott and Kaluarachchi, Tharindu and Rana, Rajib and Nanayakkara, Suranga},
  year = {2023},
  month = jan,
  journal = {Transactions of the Association for Computational Linguistics},
  volume = {11},
  pages = {1--17},
  issn = {2307-387X},
  doi = {10.1162/tacl_a_00530},
  urldate = {2024-08-26},
  abstract = {Retrieval Augment Generation (RAG) is a recent advancement in Open-Domain Question Answering (ODQA). RAG has only been trained and explored with a Wikipedia-based external knowledge base and is not optimized for use in other specialized domains such as healthcare and news. In this paper, we evaluate the impact of joint training of the retriever and generator components of RAG for the task of domain adaptation in ODQA. We propose RAG-end2end, an extension to RAG that can adapt to a domain-specific knowledge base by updating all components of the external knowledge base during training. In addition, we introduce an auxiliary training signal to inject more domain-specific knowledge. This auxiliary signal forces RAG-end2end to reconstruct a given sentence by accessing the relevant information from the external knowledge base. Our novel contribution is that, unlike RAG, RAG-end2end does joint training of the retriever and generator for the end QA task and domain adaptation. We evaluate our approach with datasets from three domains: COVID-19, News, and Conversations, and achieve significant performance improvements compared to the original RAG model. Our work has been open-sourced through the HuggingFace Transformers library, attesting to our work's credibility and technical consistency.},
}

@article{sokolOneExplanationDoes2020,
  title = {One {{Explanation Does Not Fit All}}: {{The Promise}} of {{Interactive Explanations}} for {{Machine Learning Transparency}}},
  shorttitle = {One {{Explanation Does Not Fit All}}},
  author = {Sokol, Kacper and Flach, Peter},
  year = {2020},
  month = jun,
  journal = {KI - K{\"u}nstliche Intelligenz},
  volume = {34},
  number = {2},
  pages = {235--250},
  issn = {0933-1875, 1610-1987},
  doi = {10.1007/s13218-020-00637-y},
  urldate = {2024-08-17},
  abstract = {The need for transparency of predictive systems based on Machine Learning algorithms arises as a consequence of their ever-increasing proliferation in the industry. Whenever black-box algorithmic predictions influence human affairs, the inner workings of these algorithms should be scrutinised and their decisions explained to the relevant stakeholders, including the system engineers, the system's operators and the individuals whose case is being decided. While a variety of interpretability and explainability methods is available, none of them is a panacea that can satisfy all diverse expectations and competing objectives that might be required by the parties involved. We address this challenge in this paper by discussing the promises of Interactive Machine Learning for improved transparency of black-box systems using the example of contrastive explanations---a state-of-the-art approach to Interpretable Machine Learning. Specifically, we show how to personalise counterfactual explanations by interactively adjusting their conditional statements and extract additional explanations by asking follow-up ``What if?'' questions. Our experience in building, deploying and presenting this type of system allowed us to list desired properties as well as potential limitations, which can be used to guide the development of interactive explainers. While customising the medium of interaction, i.e., the user interface comprising of various communication channels, may give an impression of personalisation, we argue that adjusting the explanation itself and its content is more important. To this end, properties such as breadth, scope, context, purpose and target of the explanation have to be considered, in addition to explicitly informing the explainee about its limitations and caveats. Furthermore, we discuss the challenges of mirroring the explainee's mental model, which is the main building block of intelligible human--machine interactions. We also deliberate on the risks of allowing the explainee to freely manipulate the explanations and thereby extracting information about the underlying predictive model, which might be leveraged by malicious actors to steal or game the model. Finally, building an end-to-end interactive explainability system is a challenging engineering task; unless the main goal is its deployment, we recommend ``Wizard of Oz'' studies as a proxy for testing and evaluating standalone interactive explainability algorithms.},
  langid = {english},
}

@inproceedings{spaneyModelDrivenDigitalTwin2023,
  title = {A {{Model-Driven Digital Twin}} for {{Manufacturing Process Adaptation}}},
  booktitle = {2023 {{ACM}}/{{IEEE International Conference}} on {{Model Driven Engineering Languages}} and {{Systems Companion}} ({{MODELS-C}})},
  author = {Spaney, Patrick and Becker, Steffen and Str{\"o}bel, Robin and Fleischer, J{\"u}rgen and Zenhari, Soraya and M{\"o}hring, Hans-Christian and Splettst{\"o}{\ss}er, Ann-Kathrin and Wortmann, Andreas},
  year = {2023},
  month = oct,
  pages = {465--469},
  publisher = {IEEE},
  address = {V{\"a}ster{\aa}s, Sweden},
  doi = {10.1109/MODELS-C59198.2023.00081},
  urldate = {2024-01-25},
  abstract = {Digital twins are a means to better understand, engineer, and use cyber-physical systems. In manufacturing, digital twins can optimize production, prevent failures, and save resources. To consolidate the different approaches to digital twins in manufacturing, ISO 23247 defines the essential functional elements of a digital twin. We present a model-driven digital twin exemplar that realizes part of this standard to analyze milling processes. Our digital twin reference architecture includes a digital twin service component that manages and connects different services to adapt the manufacturing process according to a given objective. Two digital twin services, for the adaptation of component and tool conditions and for geometric error adaptation, illustrate the potential of this reference architecture. The digital twin connects to an industrial milling machine via domainspecific languages. This exemplar uses models at design time and at runtime to separate the concerns of software engineers and domain experts and leverages these models to understand and optimize the use of industrial machine tools.},
  isbn = {9798350324983},
  langid = {english},
  keywords = {Digital twins,Formalizing model reporting},
}

@article{spinellisCommandsAIConversations2023,
  title = {Commands as {{AI Conversations}}},
  author = {Spinellis, Diomidis},
  year = {2023},
  month = nov,
  journal = {IEEE Software},
  volume = {40},
  number = {6},
  pages = {22--26},
  issn = {0740-7459, 1937-4194},
  doi = {10.1109/MS.2023.3307170},
  urldate = {2023-12-05},
  abstract = {Developers and data scientists often struggle to write command-line inputs, even though graphical interfaces or tools like ChatGPT can assist. The solution? "ai-cli," an open-source system inspired by GitHub Copilot that converts natural language prompts into executable commands for various Linux command-line tools. By tapping into OpenAI's API, which allows interaction through JSON HTTP requests, "ai-cli" transforms user queries into actionable command-line instructions. However, integrating AI assistance across multiple command-line tools, especially in open source settings, can be complex. Historically, operating systems could mediate, but individual tool functionality and the lack of a unified approach have made centralized integration challenging. The "ai-cli" tool, by bridging this gap through dynamic loading and linking with each program's Readline library API, makes command-line interfaces smarter and more user-friendly, opening avenues for further enhancement and cross-platform applicability.},
  langid = {english},
  keywords = {Competition},
}

@misc{SQLtoSchemaEnhancesSchema,
  title = {{{SQL-to-Schema Enhances Schema Linking}} in {{Text-to-SQL}}},
}

@misc{StanfordAlpacaInstructionfollowing2024,
  title = {Stanford {{Alpaca}}: {{An Instruction-following LLaMA Model}}},
  year = {2024},
  month = aug,
  url = {https://github.com/tatsu-lab/stanford_alpaca},
  urldate = {2024-08-23},
  abstract = {Code and documentation to train Stanford's Alpaca models, and generate the data.},
  copyright = {Apache-2.0},
  howpublished = {Tatsu's shared repositories},
  keywords = {deep-learning,instruction-following,language-model}
}

@misc{steckCosineSimilarityEmbeddingsReally2024,
  title = {Is {{Cosine-Similarity}} of {{Embeddings Really About Similarity}}?},
  author = {Steck, Harald and Ekanadham, Chaitanya and Kallus, Nathan},
  year = {2024},
  month = mar,
  eprint = {2403.05440},
  primaryclass = {cs},
  doi = {10.1145/3589335.3651526},
  urldate = {2024-04-04},
  abstract = {Cosine-similarity is the cosine of the angle between two vectors, or equivalently the dot product between their normalizations. A popular application is to quantify semantic similarity between high-dimensional objects by applying cosine-similarity to a learned low-dimensional feature embedding. This can work better but sometimes also worse than the unnormalized dot-product between embedded vectors in practice. To gain insight into this empirical observation, we study embeddings derived from regularized linear models, where closed-form solutions facilitate analytical insights. We derive analytically how cosine-similarity can yield arbitrary and therefore meaningless `similarities.' For some linear models the similarities are not even unique, while for others they are implicitly controlled by the regularization. We discuss implications beyond linear models: a combination of different regularizations are employed when learning deep models; these have implicit and unintended effects when taking cosine-similarities of the resulting embeddings, rendering results opaque and possibly arbitrary. Based on these insights, we caution against blindly using cosine-similarity and outline alternatives.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Information Retrieval,Computer Science - Machine Learning},
}

@article{styperekEvaluationSPARQLcompliantSemantic2015,
  title = {Evaluation of {{SPARQL-compliant}} Semantic Search User Interfaces},
  author = {Styperek, Adam and Ciesielczyk, Michal and Szwabe, Andrzej and Misiorek, Pawel},
  year = {2015},
  month = aug,
  journal = {Vietnam Journal of Computer Science},
  volume = {2},
  number = {3},
  pages = {191--199},
  issn = {2196-8888, 2196-8896},
  doi = {10.1007/s40595-015-0044-y},
  urldate = {2024-05-23},
  langid = {english},
}

@misc{SubgraphPatternMatching,
  title = {Subgraph Pattern Matching over Uncertain Graphs with Identity Linkage Uncertainty {\textbar} {{IEEE Conference Publication}} {\textbar} {{IEEE Xplore}}},
  url = {https://ieeexplore.ieee.org/document/6816710},
  urldate = {2024-09-01},
}

@inproceedings{suCrossdomainSemanticParsing2017,
  title = {Cross-Domain {{Semantic Parsing}} via {{Paraphrasing}}},
  booktitle = {Proceedings of the 2017 {{Conference}} on {{Empirical Methods}} in {{Natural Language Processing}}},
  author = {Su, Yu and Yan, Xifeng},
  year = {2017},
  pages = {1235--1246},
  publisher = {Association for Computational Linguistics},
  address = {Copenhagen, Denmark},
  doi = {10.18653/v1/D17-1127},
  urldate = {2024-11-22},
  abstract = {Existing studies on semantic parsing mainly focus on the in-domain setting. We formulate cross-domain semantic parsing as a domain adaptation problem: train a semantic parser on some source domains and then adapt it to the target domain. Due to the diversity of logical forms in different domains, this problem presents unique and intriguing challenges. By converting logical forms into canonical utterances in natural language, we reduce semantic parsing to paraphrasing, and develop an attentive sequence-to-sequence paraphrase model that is general and flexible to adapt to different domains. We discover two problems, small micro variance and large macro variance, of pre-trained word embeddings that hinder their direct use in neural networks, and propose standardization techniques as a remedy. On the popular Overnight dataset, which contains eight domains, we show that both cross-domain training and standardized pre-trained word embeddings can bring significant improvement.},
  langid = {english},
  keywords = {Computer Science - Computation and Language},
  annotation = {Read\_Status: To Read\\
Read\_Status\_Date: 2024-11-22T16:51:12.750Z},
}

@misc{sunOpenDomainQuestion2018,
  title = {Open {{Domain Question Answering Using Early Fusion}} of {{Knowledge Bases}} and {{Text}}},
  author = {Sun, Haitian and Dhingra, Bhuwan and Zaheer, Manzil and Mazaitis, Kathryn and Salakhutdinov, Ruslan and Cohen, William W.},
  year = {2018},
  month = sep,
  number = {arXiv:1809.00782},
  eprint = {1809.00782},
  primaryclass = {cs},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/1809.00782},
  urldate = {2024-07-30},
  abstract = {Open Domain Question Answering (QA) is evolving from complex pipelined systems to end-to-end deep neural networks. Specialized neural models have been developed for extracting answers from either text alone or Knowledge Bases (KBs) alone. In this paper we look at a more practical setting, namely QA over the combination of a KB and entitylinked text, which is appropriate when an incomplete KB is available with a large text corpus. Building on recent advances in graph representation learning we propose a novel model, GRAFT-Net, for extracting answers from a question-specific subgraph containing text and KB entities and relations. We construct a suite of benchmark tasks for this problem, varying the difficulty of questions, the amount of training data, and KB completeness. We show that GRAFT-Net is competitive with the state-of-the-art when tested using either KBs or text alone, and vastly outperforms existing methods in the combined setting.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning},
}

@article{SystemsEngineering2024,
  title = {Systems Engineering},
  year = {2024},
  month = sep,
  journal = {Wikipedia},
  url = {https://en.wikipedia.org/w/index.php?title=Systems_engineering&oldid=1245462226},
  urldate = {2024-11-20},
  abstract = {Systems engineering is an interdisciplinary field of engineering and engineering management that focuses on how to design, integrate, and manage complex systems over their life cycles. At its core, systems engineering utilizes systems thinking principles to organize this body of knowledge. The individual outcome of such efforts, an engineered system, can be defined as a combination of components that work in synergy to collectively perform a useful function. Issues such as requirements engineering, reliability, logistics, coordination of different teams, testing and evaluation, maintainability, and many other disciplines, aka "ilities",  necessary for successful system design, development, implementation, and ultimate decommission become more difficult when dealing with large or complex projects. Systems engineering deals with work processes, optimization methods, and risk management tools in such projects. It overlaps technical and human-centered disciplines such as industrial engineering, production systems engineering, process systems engineering, mechanical engineering, manufacturing engineering, production engineering, control engineering, software engineering, electrical engineering, cybernetics, aerospace engineering, organizational studies, civil engineering and project management. Systems engineering ensures that all likely aspects of a project or system are considered and integrated into a whole. The systems engineering process is a discovery process that is quite unlike a manufacturing process. A manufacturing process is focused on repetitive activities that achieve high-quality outputs with minimum cost and time. The systems engineering process must begin by discovering the real problems that need to be resolved and identifying the most probable or highest-impact failures that can occur. Systems engineering involves finding solutions to these problems.},
  copyright = {Creative Commons Attribution-ShareAlike License},
  langid = {english},
  annotation = {Page Version ID: 1245462226},
}

@techreport{SystemsEngineeringVision2007,
  title = {Systems Engineering Vision 2020},
  year = {2007},
  month = sep,
  number = {INCOSE-TP-2004-004-02 version 2.03},
  institution = {INCOSE Technical Operations},
  url = {https://sdincose.org/wp-content/uploads/2011/12/SEVision2020_20071003_v2_03.pdf},
}

@article{SystemsModelingLanguage2024,
  title = {Systems Modeling Language},
  year = {2024},
  month = jun,
  journal = {Wikipedia},
  url = {https://en.wikipedia.org/w/index.php?title=Systems_modeling_language&oldid=1228436534},
  urldate = {2024-11-20},
  abstract = {The systems modeling language (SysML) is a general-purpose modeling language for systems engineering applications. It supports the specification, analysis, design, verification and validation of a broad range of systems and systems-of-systems. SysML was originally developed by an open source specification project, and includes an open source license for distribution and use. SysML is defined as an extension of a subset of the Unified Modeling Language (UML) using UML's profile mechanism. The language's extensions were designed to support systems engineering activities.},
  copyright = {Creative Commons Attribution-ShareAlike License},
  langid = {english},
  annotation = {Page Version ID: 1228436534},
}

@misc{tangTARNeuralLogical2022,
  title = {{{TAR}}: {{Neural Logical Reasoning}} across {{TBox}} and {{ABox}}},
  shorttitle = {{{TAR}}},
  author = {Tang, Zhenwei and Pei, Shichao and Peng, Xi and Zhuang, Fuzhen and Zhang, Xiangliang and Hoehndorf, Robert},
  year = {2022},
  month = aug,
  number = {arXiv:2205.14591},
  eprint = {2205.14591},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2205.14591},
  urldate = {2024-11-27},
  abstract = {Many ontologies, i.e., Description Logic (DL) knowledge bases, have been developed to provide rich knowledge about various domains. An ontology consists of an ABox, i.e., assertion axioms between two entities or between a concept and an entity, and a TBox, i.e., terminology axioms between two concepts. Neural logical reasoning (NLR) is a fundamental task to explore such knowledge bases, which aims at answering multi-hop queries with logical operations based on distributed representations of queries and answers. While previous NLR methods can give specific entity-level answers, i.e., ABox answers, they are not able to provide descriptive concept-level answers, i.e., TBox answers, where each concept is a description of a set of entities. In other words, previous NLR methods only reason over the ABox of an ontology while ignoring the TBox. In particular, providing TBox answers enables inferring the explanations of each query with descriptive concepts, which make answers comprehensible to users and are of great usefulness in the field of applied ontology. In this work, we formulate the problem of neural logical reasoning across TBox and ABox (TA-NLR), solving which needs to address challenges in incorporating, representing, and operating on concepts. We propose an original solution named TAR for TA-NLR. Firstly, we incorporate description logic based ontological axioms to provide the source of concepts. Then, we represent concepts and queries as fuzzy sets, i.e., sets whose elements have degrees of membership, to bridge concepts and queries with entities. Moreover, we design operators involving concepts on top of fuzzy set representation of concepts and queries for optimization and inference. Extensive experimental results on two real-world datasets demonstrate the effectiveness of TAR for TA-NLR.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Logic in Computer Science,Computer Science - Machine Learning},
}

@misc{thakkarIntegratedGraphAlgebra2019,
  title = {Towards an {{Integrated Graph Algebra}} for {{Graph Pattern Matching}} with {{Gremlin}} ({{Extended Version}})},
  author = {Thakkar, Harsh and Punjani, Dharmen and Auer, Soeren and Vidal, Maria-Esther},
  year = {2019},
  month = sep,
  publisher = {arXiv},
  doi = {10.48550/arXiv.1908.06265},
  urldate = {2024-08-26},
  abstract = {Graph data management (also called NoSQL) has revealed beneficial characteristics in terms of flexibility and scalability by differently balancing between query expressivity and schema flexibility. This peculiar advantage has resulted into an unforeseen race of developing new task-specific graph systems, query languages and data models, such as property graphs, key-value, wide column, resource description framework (RDF), etc. Present-day graph query languages are focused towards flexible graph pattern matching (aka sub-graph matching), whereas graph computing frameworks aim towards providing fast parallel (distributed) execution of instructions. The consequence of this rapid growth in the variety of graph-based data management systems has resulted in a lack of standardization. Gremlin, a graph traversal language, and machine provides a common platform for supporting any graph computing system (such as an OLTP graph database or OLAP graph processors). We present a formalization of graph pattern matching for Gremlin queries. We also study, discuss and consolidate various existing graph algebra operators into an integrated graph algebra.},
  keywords = {Computer Science - Databases},
}

@article{tianGraphNeuralPrompting2024,
  title = {Graph {{Neural Prompting}} with {{Large Language Models}}},
  author = {Tian, Yijun and Song, Huan and Wang, Zichen and Wang, Haozhu and Hu, Ziqing and Wang, Fang and Chawla, Nitesh V. and Xu, Panpan},
  year = {2024},
  month = mar,
  journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
  volume = {38},
  number = {17},
  pages = {19080--19088},
  issn = {2374-3468, 2159-5399},
  doi = {10.1609/aaai.v38i17.29875},
  urldate = {2024-08-17},
  abstract = {Large language models (LLMs) have shown remarkable generalization capability with exceptional performance in various language modeling tasks. However, they still exhibit inherent limitations in precisely capturing and returning grounded knowledge. While existing work has explored utilizing knowledge graphs (KGs) to enhance language modeling via joint training and customized model architectures, applying this to LLMs is problematic owing to their large number of parameters and high computational cost. Therefore, how to enhance pre-trained LLMs using grounded knowledge, e.g., retrieval-augmented generation, remains an open question. In this work, we propose Graph Neural Prompting (GNP), a novel plug-and-play method to assist pre-trained LLMs in learning beneficial knowledge from KGs. GNP encompasses various designs, including a standard graph neural network encoder, a crossmodality pooling module, a domain projector, and a selfsupervised link prediction objective. Extensive experiments on multiple datasets demonstrate the superiority of GNP on both commonsense and biomedical reasoning tasks across different LLM sizes and settings. Code is available at https://github.com/meettyj/GNP.},
  langid = {english},
  annotation = {Read\_Status: To Read\\
Read\_Status\_Date: 2024-12-04T12:28:59.905Z},
}

@misc{touvronLlama2Open2023,
  title = {Llama 2: {{Open Foundation}} and {{Fine-Tuned Chat Models}}},
  shorttitle = {Llama 2},
  author = {Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and Bikel, Dan and Blecher, Lukas and Ferrer, Cristian Canton and Chen, Moya and Cucurull, Guillem and Esiobu, David and Fernandes, Jude and Fu, Jeremy and Fu, Wenyin and Fuller, Brian and Gao, Cynthia and Goswami, Vedanuj and Goyal, Naman and Hartshorn, Anthony and Hosseini, Saghar and Hou, Rui and Inan, Hakan and Kardas, Marcin and Kerkez, Viktor and Khabsa, Madian and Kloumann, Isabel and Korenev, Artem and Koura, Punit Singh and Lachaux, Marie-Anne and Lavril, Thibaut and Lee, Jenya and Liskovich, Diana and Lu, Yinghai and Mao, Yuning and Martinet, Xavier and Mihaylov, Todor and Mishra, Pushkar and Molybog, Igor and Nie, Yixin and Poulton, Andrew and Reizenstein, Jeremy and Rungta, Rashi and Saladi, Kalyan and Schelten, Alan and Silva, Ruan and Smith, Eric Michael and Subramanian, Ranjan and Tan, Xiaoqing Ellen and Tang, Binh and Taylor, Ross and Williams, Adina and Kuan, Jian Xiang and Xu, Puxin and Yan, Zheng and Zarov, Iliyan and Zhang, Yuchen and Fan, Angela and Kambadur, Melanie and Narang, Sharan and Rodriguez, Aurelien and Stojnic, Robert and Edunov, Sergey and Scialom, Thomas},
  year = {2023},
  month = jul,
  number = {arXiv:2307.09288},
  eprint = {2307.09288},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2307.09288},
  urldate = {2024-08-26},
  abstract = {In this work, we develop and release Llama 2, a collection of pretrained and fine-tuned large language models (LLMs) ranging in scale from 7 billion to 70 billion parameters. Our fine-tuned LLMs, called Llama 2-Chat, are optimized for dialogue use cases. Our models outperform open-source chat models on most benchmarks we tested, and based on our human evaluations for helpfulness and safety, may be a suitable substitute for closed-source models. We provide a detailed description of our approach to fine-tuning and safety improvements of Llama 2-Chat in order to enable the community to build on our work and contribute to the responsible development of LLMs.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
}

@misc{touvronLLaMAOpenEfficient2023,
  title = {{{LLaMA}}: {{Open}} and {{Efficient Foundation Language Models}}},
  shorttitle = {{{LLaMA}}},
  author = {Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timoth{\'e}e and Rozi{\`e}re, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and Rodriguez, Aurelien and Joulin, Armand and Grave, Edouard and Lample, Guillaume},
  year = {2023},
  month = feb,
  number = {arXiv:2302.13971},
  eprint = {2302.13971},
  primaryclass = {cs},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/2302.13971},
  urldate = {2023-12-05},
  abstract = {We introduce LLaMA, a collection of foundation language models ranging from 7B to 65B parameters. We train our models on trillions of tokens, and show that it is possible to train state-of-the-art models using publicly available datasets exclusively, without resorting to proprietary and inaccessible datasets. In particular, LLaMA-13B outperforms GPT-3 (175B) on most benchmarks, and LLaMA65B is competitive with the best models, Chinchilla-70B and PaLM-540B. We release all our models to the research community1.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computation and Language,Foundational},
}

@inproceedings{traseModeldrivenVisualizationTool2014,
  title = {A Model-Driven Visualization Tool for Use with {{Model-Based Systems Engineering}} Projects},
  booktitle = {2014 {{IEEE Aerospace Conference}}},
  author = {Trase, Kathryn and Fink, Eric},
  year = {2014},
  month = mar,
  pages = {1--10},
  issn = {1095-323X},
  doi = {10.1109/AERO.2014.6836268},
  urldate = {2024-12-09},
  abstract = {Model-Based Systems Engineering (MBSE) promotes increased consistency between a system's design and its design documentation through the use of an object-oriented system model. The creation of this system model facilitates data presentation by providing a mechanism from which information can be extracted by automated manipulation of model content. Existing MBSE tools enable model creation, but are often too complex for the unfamiliar model viewer to easily use. These tools do not yet provide many opportunities for easing into the development and use of a system model when system design documentation already exists. This study creates a Systems Modeling Language (SysML) Document Traceability Framework (SDTF) for integrating design documentation with a system model, and develops an Interactive Visualization Engine for SysML Tools (InVEST), that exports consistent, clear, and concise views of SysML model data. These exported views are each meaningful to a variety of project stakeholders with differing subjects of concern and depth of technical involvement. InVEST allows a model user to generate multiple views and reports from a MBSE model, including wiki pages and interactive visualizations of data. System data can also be filtered to present only the information relevant to the particular stakeholder, resulting in a view that is both consistent with the larger system model and other model views. Viewing the relationships between system artifacts and documentation, and filtering through data to see specialized views improves the value of the system as a whole, as data becomes information.},
  keywords = {Data models,Data visualization,Materials,NASA,Standards,Visualization},
  annotation = {Read\_Status: Read\\
Read\_Status\_Date: 2024-12-09T17:44:27.819Z},
}

@article{upadhyayImplementingRAGLangchain,
  title = {Implementing {{RAG}} with {{Langchain}} and {{Hugging Face}}},
  author = {Upadhyay, Akriti},
  langid = {english},
}

@misc{vaswaniAttentionAllYou2023,
  title = {Attention {{Is All You Need}}},
  author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
  year = {2023},
  month = aug,
  number = {arXiv:1706.03762},
  eprint = {1706.03762},
  primaryclass = {cs},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/1706.03762},
  urldate = {2023-12-08},
  abstract = {The dominant sequence transduction models are based on complex recurrent or convolutional neural networks that include an encoder and a decoder. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 Englishto-German translation task, improving over the existing best results, including ensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning},
}

@misc{velickovicGraphAttentionNetworks2018,
  title = {Graph {{Attention Networks}}},
  author = {Veli{\v c}kovi{\'c}, Petar and Cucurull, Guillem and Casanova, Arantxa and Romero, Adriana and Li{\`o}, Pietro and Bengio, Yoshua},
  year = {2018},
  month = feb,
  number = {arXiv:1710.10903},
  eprint = {1710.10903},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1710.10903},
  urldate = {2024-05-30},
  abstract = {We present graph attention networks (GATs), novel neural network architectures that operate on graph-structured data, leveraging masked self-attentional layers to address the shortcomings of prior methods based on graph convolutions or their approximations. By stacking layers in which nodes are able to attend over their neighborhoods' features, we enable (implicitly) specifying different weights to different nodes in a neighborhood, without requiring any kind of costly matrix operation (such as inversion) or depending on knowing the graph structure upfront. In this way, we address several key challenges of spectral-based graph neural networks simultaneously, and make our model readily applicable to inductive as well as transductive problems. Our GAT models have achieved or matched state-of-theart results across four established transductive and inductive graph benchmarks: the Cora, Citeseer and Pubmed citation network datasets, as well as a proteinprotein interaction dataset (wherein test graphs remain unseen during training).},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Computer Science - Social and Information Networks,Statistics - Machine Learning},
}

@misc{vermaLearningUniversalGraph2019,
  title = {Learning {{Universal Graph Neural Network Embeddings With Aid Of Transfer Learning}}},
  author = {Verma, Saurabh and Zhang, Zhi-Li},
  year = {2019},
  month = nov,
  number = {arXiv:1909.10086},
  eprint = {1909.10086},
  primaryclass = {cs, stat},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/1909.10086},
  urldate = {2024-03-05},
  abstract = {Learning powerful data embeddings has become a center piece in machine learning, especially in natural language processing and computer vision domains. The crux of these embeddings is that they are pretrained on huge corpus of data in a unsupervised fashion, sometimes aided with transfer learning. However currently in the graph learning domain, embeddings learned through existing graph neural networks (GNNs) are task dependent and thus cannot be shared across different datasets. In this paper, we present a first powerful and theoretically guaranteed graph neural network that is designed to learn task-independent graph embeddings, thereafter referred to as deep universal graph embedding (DUGNN). Our DUGNN model incorporates a novel graph neural network (as a universal graph encoder) and leverages rich Graph Kernels (as a multi-task graph decoder) for both unsupervised learning and (task-specific) adaptive supervised learning. By learning task-independent graph embeddings across diverse datasets, DUGNN also reaps the benefits of transfer learning. Through extensive experiments and ablation studies, we show that the proposed DUGNN model consistently outperforms both the existing state-of-art GNN models and Graph Kernels by an increased accuracy of 3\% - 8\% on graph classification benchmark datasets.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
}

@misc{vizuaraGraphConvolutionalNeural2024,
  title = {Graph {{Convolutional Neural Network}} ({{GCNN}}) {\textbar} {{Explained}} with a Simple Numerical Example},
  author = {{Vizuara}},
  year = {2024},
  url = {https://www.youtube.com/watch?v=wpSjM5wqFfQ},
  urldate = {2024-08-17},
  abstract = {``Classifying research papers using Graph Neural Network'':  Convolution operation in images helps us identify features from the image by considering not just the value of individual pixels, but also the values of neighboring pixels. It is also possible to extract meaning from the features using a convolution operation in Graph Neural Networks (GNN). Imagine a Graph Neural Network (GNN) that represents research papers. Each paper cites a few other papers in the network. The papers are represented by nodes and citations by edges. The individual papers may be based on a few different topics: say Machine Learning, NLP, GenAI, Computer Vision etc. Often when we are referring to a paper, we are very interested to find similar papers. Is it possible to group the papers into a few different categories using the framework of GNN? This is totally possible. To classify the papers (nodes of the GNN), we consider the features of the papers (nodes) as well as those of the neighboring nodes (features of cited papers). We can accomplish feature aggregation and node classification using a concept called Graph Convolutional Network (GCN). This lecture teaches you how to use GCN to perform a simple node classification operation, using a numerical example. The example is very easy to understand. If you are a total beginner or have no idea about GNNs I am quite certain that this lecture will still help you. I build the GNN from scratch and hand-calculate the message passing, feature aggregation, transformation and node classification. Very simple. Please check out the lecture here. I have contributed this lecture is part of the Graph Neural Network lecture organized by Aiswarya.}
}

@incollection{vollmersKnowledgeGraphQuestion2021,
  title = {Knowledge {{Graph Question Answering}} Using {{Graph-Pattern Isomorphism}}},
  author = {Vollmers, Daniel and Jalota, Rricha and Moussallem, Diego and Topiwala, Hardik and Ngomo, Axel-Cyrille Ngonga and Usbeck, Ricardo},
  year = {2021},
  month = aug,
  eprint = {2103.06752},
  primaryclass = {cs},
  doi = {10.3233/SSW210038},
  urldate = {2024-02-04},
  abstract = {Knowledge Graph Question Answering (KGQA) systems are often based on machine learning algorithms, requiring thousands of question-answer pairs as training examples or natural language processing pipelines that need module fine-tuning. In this paper, we present a novel QA approach, dubbed TeBaQA. Our approach learns to answer questions based on graph isomorphisms from basic graph patterns of SPARQL queries. Learning basic graph patterns is efficient due to the small number of possible patterns. This novel paradigm reduces the amount of training data necessary to achieve state-of-the-art performance. TeBaQA also speeds up the domain adaption process by transforming the QA system development task into a much smaller and easier data compilation task. In our evaluation, TeBaQA achieves state-of-the-art performance on QALD-8 and delivers comparable results on QALD-9 and LC-QuAD v1. Additionally, we performed a finegrained evaluation on complex queries that deal with aggregation and superlative questions as well as an ablation study, highlighting future research challenges.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
}

@inproceedings{wagnerCAESARModelBasedApproach2020,
  title = {{{CAESAR Model-Based Approach}} to {{Harness Design}}},
  booktitle = {2020 {{IEEE Aerospace Conference}}},
  author = {Wagner, David and {Kim-Castet}, So Young and Jimenez, Alejandro and Elaasar, Maged and Rouquette, Nicolas and Jenkins, Steven},
  year = {2020},
  month = mar,
  pages = {1--13},
  publisher = {IEEE},
  address = {Big Sky, MT, USA},
  doi = {10.1109/AERO47225.2020.9172630},
  urldate = {2024-02-29},
  abstract = {In this paper we describe a system called the Computer Aided Engineering for Spacecraft System Architectures Tool Suite, or CAESAR for short, a platform for enabling model-based system engineering (MBSE). CAESAR recognizes that engineers are already likely to use models, but they typically keep the models private, only interpreting model information into documents or presentations that become project baseline. MBSE needs to enable more automated sharing of information directly between models to ensure model consistency, improve the rigor of engineering process, and ultimately, reduce the effort needed to get a clear answer to engineering questions.},
  isbn = {978-1-72812-734-7},
  langid = {english},
}

@incollection{wagnerOntologicalMetamodelingAnalysis2023,
  title = {Ontological {{Metamodeling}} and {{Analysis Using openCAESAR}}},
  booktitle = {Handbook of {{Model-Based Systems Engineering}}},
  author = {Wagner, D. A. and Chodas, M. and Elaasar, M. and Jenkins, J. S. and Rouquette, N.},
  editor = {Madni, Azad M. and Augustine, Norman and Sievers, Michael},
  year = {2023},
  pages = {925--954},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-93582-5_78},
  urldate = {2024-12-09},
  abstract = {All modeling depends on having some vocabulary in which a model can be expressed. For the purpose of this chapter, we will define metamodeling as the modeling of vocabularies that can then be used to build useful models. This chapter will explain how standards developed for the semantic web can be used to produce precise vocabularies (ontologies) that can then be used as the foundation, on which to build precise descriptive models.},
  isbn = {978-3-030-93582-5},
  langid = {english}
}

@inproceedings{wangBuildingSemanticParser2015,
  title = {Building a {{Semantic Parser Overnight}}},
  booktitle = {Proceedings of the 53rd {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}} and the 7th {{International Joint Conference}} on {{Natural Language Processing}} ({{Volume}} 1: {{Long Papers}})},
  author = {Wang, Yushi and Berant, Jonathan and Liang, Percy},
  year = {2015},
  pages = {1332--1342},
  publisher = {Association for Computational Linguistics},
  address = {Beijing, China},
  doi = {10.3115/v1/P15-1129},
  urldate = {2024-11-22},
  abstract = {How do we build a semantic parser in a new domain starting with zero training examples? We introduce a new methodology for this setting: First, we use a simple grammar to generate logical forms paired with canonical utterances. The logical forms are meant to cover the desired set of compositional operators, and the canonical utterances are meant to capture the meaning of the logical forms (although clumsily). We then use crowdsourcing to paraphrase these canonical utterances into natural utterances. The resulting data is used to train the semantic parser. We further study the role of compositionality in the resulting paraphrases. Finally, we test our methodology on seven domains and show that we can build an adequate semantic parser in just a few hours.},
  langid = {english},
}

@misc{wangHowMuchAutomation2021,
  title = {How {{Much Automation Does}} a {{Data Scientist Want}}?},
  author = {Wang, Dakuo and Liao, Q. Vera and Zhang, Yunfeng and Khurana, Udayan and Samulowitz, Horst and Park, Soya and Muller, Michael and Amini, Lisa},
  year = {2021},
  month = jan,
  number = {arXiv:2101.03970},
  eprint = {2101.03970},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2101.03970},
  urldate = {2024-08-05},
  abstract = {Data science and machine learning (DS/ML) are at the heart of the recent advancements of many Artificial Intelligence (AI) applications. There is an active research thread in AI, {\textbackslash}autoai, that aims to develop systems for automating end-to-end the DS/ML Lifecycle. However, do DS and ML workers really want to automate their DS/ML workflow? To answer this question, we first synthesize a human-centered AutoML framework with 6 User Role/Personas, 10 Stages and 43 Sub-Tasks, 5 Levels of Automation, and 5 Types of Explanation, through reviewing research literature and marketing reports. Secondly, we use the framework to guide the design of an online survey study with 217 DS/ML workers who had varying degrees of experience, and different user roles "matching" to our 6 roles/personas. We found that different user personas participated in distinct stages of the lifecycle -- but not all stages. Their desired levels of automation and types of explanation for AutoML also varied significantly depending on the DS/ML stage and the user persona. Based on the survey results, we argue there is no rationale from user needs for complete automation of the end-to-end DS/ML lifecycle. We propose new next steps for user-controlled DS/ML automation.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Human-Computer Interaction,Computer Science - Machine Learning},
}

@inproceedings{wangSlide4NCreatingPresentation2023,
  title = {{{Slide4N}}: {{Creating Presentation Slides}} from {{Computational Notebooks}} with {{Human-AI Collaboration}}},
  shorttitle = {{{Slide4N}}},
  booktitle = {Proceedings of the 2023 {{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Wang, Fengjie and Liu, Xuye and Liu, Oujing and Neshati, Ali and Ma, Tengfei and Zhu, Min and Zhao, Jian},
  year = {2023},
  month = apr,
  pages = {1--18},
  publisher = {ACM},
  address = {Hamburg Germany},
  doi = {10.1145/3544548.3580753},
  urldate = {2024-02-29},
  abstract = {Data scientists often have to use other presentation tools (e.g., Microsoft PowerPoint) to create slides to communicate their analysis obtained using computational notebooks. Much tedious and repetitive work is needed to transfer the routines of notebooks (e.g., code, plots) to the presentable contents on slides (e.g., bullet points, figures). We propose a human-AI collaborative approach and operationalize it within Slide4N, an interactive AI assistant for data scientists to create slides from computational notebooks. Slide4N leverages advanced natural language processing techniques to distill key information from user-selected notebook cells and then {$\ast$} These authors contributed equally. {\dag} Correspondence authors.},
  isbn = {978-1-4503-9421-5},
  langid = {english},
}

@misc{wanSciQAGFrameworkAutoGenerated2024,
  title = {{{SciQAG}}: {{A Framework}} for {{Auto-Generated Science Question Answering Dataset}} with {{Fine-grained Evaluation}}},
  shorttitle = {{{SciQAG}}},
  author = {Wan, Yuwei and Liu, Yixuan and Ajith, Aswathy and Grazian, Clara and Hoex, Bram and Zhang, Wenjie and Kit, Chunyu and Xie, Tong and Foster, Ian},
  year = {2024},
  month = jul,
  number = {arXiv:2405.09939},
  eprint = {2405.09939},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2405.09939},
  urldate = {2024-12-17},
  abstract = {We introduce SciQAG, a novel framework for automatically generating high-quality science question-answer pairs from a large corpus of scientific literature based on large language models (LLMs). SciQAG consists of a QA generator and a QA evaluator, which work together to extract diverse and research-level questions and answers from scientific papers. Utilizing this framework, we construct a large-scale, high-quality, open-ended science QA dataset containing 188,042 QA pairs extracted from 22,743 scientific papers across 24 scientific domains. We also introduce SciQAG-24D, a new benchmark task designed to evaluate the science question-answering ability of LLMs. Extensive experiments demonstrate that finetuning LLMs on the SciQAG dataset significantly improves their performance on both open-ended question answering and scientific tasks. To foster research and collaboration, we make the datasets, models, and evaluation codes publicly available, contributing to the advancement of science question answering and developing more interpretable and reasoningcapable AI systems.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
}

@misc{weilkiensWhatsNewSysML2014,
  title = {What's New in {{SysML}} 1.4 - {{View}} and {{Viewpoint}}},
  author = {Weilkiens, Tim},
  year = {2014},
  month = oct,
  journal = {Model Based Systems Engineering 4 You},
  url = {https://mbse4u.com/2014/10/02/whats-new-in-sysml-1-4-view-and-viewpoint/},
  urldate = {2024-11-20},
  abstract = {The third part of the blogpost series about the changes in SysML 1.4 presents the updated concept of view and viewpoints. View and Viewpoint are model elements of SysML since the very first public version 1.0. As you may know SysML was developed based on a request for proposal with a set of requirements. One{\dots} Read more},
  langid = {american},
}

@misc{weiNovelCascadeBinary2020,
  title = {A {{Novel Cascade Binary Tagging Framework}} for {{Relational Triple Extraction}}},
  author = {Wei, Zhepei and Su, Jianlin and Wang, Yue and Tian, Yuan and Chang, Yi},
  year = {2020},
  month = jun,
  number = {arXiv:1909.03227},
  eprint = {1909.03227},
  primaryclass = {cs},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/1909.03227},
  urldate = {2024-03-07},
  abstract = {Extracting relational triples from unstructured text is crucial for large-scale knowledge graph construction. However, few existing works excel in solving the overlapping triple problem where multiple relational triples in the same sentence share the same entities. In this work, we introduce a fresh perspective to revisit the relational triple extraction task and propose a novel cascade binary tagging framework (CasRel) derived from a principled problem formulation. Instead of treating relations as discrete labels as in previous works, our new framework models relations as functions that map subjects to objects in a sentence, which naturally handles the overlapping problem. Experiments show that the CasRel framework already outperforms state-of-the-art methods even when its encoder module uses a randomly initialized BERT encoder, showing the power of the new tagging framework. It enjoys further performance boost when employing a pre-trained BERT encoder, outperforming the strongest baseline by 17.5 and 30.2 absolute gain in F1-score on two public datasets NYT and WebNLG, respectively. In-depth analysis on different scenarios of overlapping triples shows that the method delivers consistent performance gain across all these scenarios. The source code and data are released online.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language},
}

@inproceedings{wongLearningSynchronousGrammars2007,
  title = {Learning {{Synchronous Grammars}} for {{Semantic Parsing}} with {{Lambda Calculus}}},
  booktitle = {Proceedings of the 45th {{Annual Meeting}} of the {{Association}} of {{Computational Linguistics}}},
  author = {Wong, Yuk Wah and Mooney, Raymond},
  editor = {Zaenen, Annie and {van den Bosch}, Antal},
  year = {2007},
  month = jun,
  pages = {960--967},
  publisher = {Association for Computational Linguistics},
  address = {Prague, Czech Republic},
  urldate = {2024-12-05},
  annotation = {https://aclanthology.org/P07-1121},
}

@misc{wuGraphLearningDistribution2024,
  title = {Graph {{Learning}} under {{Distribution Shifts}}: {{A Comprehensive Survey}} on {{Domain Adaptation}}, {{Out-of-distribution}}, and {{Continual Learning}}},
  shorttitle = {Graph {{Learning}} under {{Distribution Shifts}}},
  author = {Wu, Man and Zheng, Xin and Zhang, Qin and Shen, Xiao and Luo, Xiong and Zhu, Xingquan and Pan, Shirui},
  year = {2024},
  month = mar,
  number = {arXiv:2402.16374},
  eprint = {2402.16374},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2402.16374},
  urldate = {2025-01-12},
  abstract = {Graph learning plays a pivotal role and has gained significant attention in various application scenarios, from social network analysis to recommendation systems, for its effectiveness in modeling complex data relations represented by graph structural data. In reality, the real-world graph data typically show dynamics over time, with changing node attributes and edge structure, leading to the severe graph data distribution shift issue. This issue is compounded by the diverse and complex nature of distribution shifts, which can significantly impact the performance of graph learning methods in degraded generalization and adaptation capabilities, posing a substantial challenge to their effectiveness. In this survey, we provide a comprehensive review and summary of the latest approaches, strategies, and insights that address distribution shifts within the context of graph learning. Concretely, according to the observability of distributions in the inference stage and the availability of sufficient supervision information in the training stage, we categorize existing graph learning methods into several essential scenarios, including graph domain adaptation learning, graph out-of-distribution learning, and graph continual learning. For each scenario, a detailed taxonomy is proposed, with specific descriptions and discussions of existing progress made in distribution-shifted graph learning. Additionally, we discuss the potential applications and future directions for graph learning under distribution shifts with a systematic analysis of the current state in this field. The survey is positioned to provide general guidance for the development of effective graph learning algorithms in handling graph distribution shifts, and to stimulate future research and advancements in this area.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning,Computer Science - Social and Information Networks},
}

@inproceedings{wuOntologybasedSubgraphQuerying2013,
  title = {Ontology-Based Subgraph Querying},
  booktitle = {Proceedings of the 2013 {{IEEE International Conference}} on {{Data Engineering}} ({{ICDE}} 2013)},
  author = {Wu, Yinghui and Yan, Xifeng and Yang, Shengqi},
  year = {2013},
  month = apr,
  series = {{{ICDE}} '13},
  pages = {697--708},
  publisher = {IEEE Computer Society},
  address = {USA},
  doi = {10.1109/ICDE.2013.6544867},
  urldate = {2024-08-30},
  abstract = {Subgraph querying has been applied in a variety of emerging applications. Traditional subgraph querying based on subgraph isomorphism requires identical label matching, which is often too restrictive to capture the matches that are semantically close to the query graphs. This paper extends subgraph querying to identify semantically related matches by leveraging ontology information. (1) We introduce the ontology-based subgraph querying, which revises subgraph isomorphism by mapping a query to semantically related subgraphs in terms of a given ontology graph. We introduce a metric to measure the similarity of the matches. Based on the metric, we introduce an optimization problem to find top K best matches. (2) We provide a filtering-and-verification framework to identify (top-K) matches for ontology-based subgraph queries. The framework efficiently extracts a small subgraph of the data graph from an ontology index, and further computes the matches by only accessing the extracted subgraph. (3) In addition, we show that the ontology index can be efficiently updated upon the changes to the data graphs, enabling the framework to cope with dynamic data graphs. (4) We experimentally verify the effectiveness and efficiency of our framework using both synthetic and real life graphs, comparing with traditional subgraph querying methods.},
  isbn = {978-1-4673-4909-3},
  keywords = {Data mining,Indexing,Measurement,Ontologies,Query processing,Semantics},
}

@article{yangSchemalessStructurelessGraph2014,
  title = {Schemaless and Structureless Graph Querying},
  author = {Yang, Shengqi and Wu, Yinghui and Sun, Huan and Yan, Xifeng},
  year = {2014},
  month = mar,
  journal = {Proceedings of the VLDB Endowment},
  volume = {7},
  number = {7},
  pages = {565--576},
  issn = {2150-8097},
  doi = {10.14778/2732286.2732293},
  urldate = {2024-08-30},
  abstract = {Querying complex graph databases such as knowledge graphs is a challenging task for non-professional users. Due to their complex schemas and variational information descriptions, it becomes very hard for users to formulate a query that can be properly processed by the existing systems. We argue that for a user-friendly graph query engine, it must support various kinds of transformations such as synonym, abbreviation, and ontology. Furthermore, the derived query results must be ranked in a principled manner.                            In this paper, we introduce a novel framework enabling {$<$}u{$>$}s{$<$}/u{$>$}chema{$<$}u{$>$}l{$<$}/u{$>$}ess and {$<$}u{$>$}s{$<$}/u{$>$}tructure{$<$}u{$>$}l{$<$}/u{$>$}ess graph {$<$}u{$>$}q{$<$}/u{$>$}uerying (SLQ), where a user need not describe queries precisely as required by most databases. The query engine is built on a set of transformation functions that automatically map keywords and linkages from a query to their matches in a graph. It automatically               learns               an effective ranking model,               without               assuming manually labeled training examples, and can efficiently return top ranked matches using graph sketch and belief propagation. The architecture of SLQ is elastic for "plug-in" new transformation functions and query logs. Our experimental results show that this new graph querying paradigm is promising: It identifies high-quality matches for both keyword and graph queries over real-life knowledge graphs, and outperforms existing methods significantly in terms of effectiveness and efficiency.},
  langid = {english},
}

@misc{yasunagaQAGNNReasoningLanguage2022,
  title = {{{QA-GNN}}: {{Reasoning}} with {{Language Models}} and {{Knowledge Graphs}} for {{Question Answering}}},
  shorttitle = {{{QA-GNN}}},
  author = {Yasunaga, Michihiro and Ren, Hongyu and Bosselut, Antoine and Liang, Percy and Leskovec, Jure},
  year = {2022},
  month = dec,
  number = {arXiv:2104.06378},
  eprint = {2104.06378},
  primaryclass = {cs},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/2104.06378},
  urldate = {2024-05-27},
  abstract = {The problem of answering questions using knowledge from pre-trained language models (LMs) and knowledge graphs (KGs) presents two challenges: given a QA context (question and answer choice), methods need to (i) identify relevant knowledge from large KGs, and (ii) perform joint reasoning over the QA context and KG. In this work, we propose a new model, QA-GNN, which addresses the above challenges through two key innovations: (i) relevance scoring, where we use LMs to estimate the importance of KG nodes relative to the given QA context, and (ii) joint reasoning, where we connect the QA context and KG to form a joint graph, and mutually update their representations through graph neural networks. We evaluate our model on QA benchmarks in the commonsense (CommonsenseQA, OpenBookQA) and biomedical (MedQA-USMLE) domains. QA-GNN outperforms existing LM and LM+KG models, and exhibits capabilities to perform interpretable and structured reasoning, e.g., correctly handling negation in questions.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning},
}

@inproceedings{yihSemanticParsingStaged2015,
  title = {Semantic {{Parsing}} via {{Staged Query Graph Generation}}: {{Question Answering}} with {{Knowledge Base}}},
  shorttitle = {Semantic {{Parsing}} via {{Staged Query Graph Generation}}},
  booktitle = {Proceedings of the 53rd {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}} and the 7th {{International Joint Conference}} on {{Natural Language Processing}} ({{Volume}} 1: {{Long Papers}})},
  author = {Yih, Wen-tau and Chang, Ming-Wei and He, Xiaodong and Gao, Jianfeng},
  editor = {Zong, Chengqing and Strube, Michael},
  year = {2015},
  pages = {1321--1331},
  publisher = {Association for Computational Linguistics},
  address = {Beijing, China},
  doi = {10.3115/v1/P15-1128},
  urldate = {2024-11-22},
  abstract = {We propose a novel semantic parsing framework for question answering using a knowledge base. We define a query graph that resembles subgraphs of the knowledge base and can be directly mapped to a logical form. Semantic parsing is reduced to query graph generation, formulated as a staged search problem. Unlike traditional approaches, our method leverages the knowledge base in an early stage to prune the search space and thus simplifies the semantic matching problem. By applying an advanced entity linking system and a deep convolutional neural network model that matches questions and predicate sequences, our system outperforms previous methods substantially, and achieves an F1 measure of 52.5\% on the WEBQUESTIONS dataset.},
  langid = {english},
}

@inproceedings{yihValueSemanticParse2016,
  title = {The {{Value}} of {{Semantic Parse Labeling}} for {{Knowledge Base Question Answering}}},
  booktitle = {Proceedings of the 54th {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}} ({{Volume}} 2: {{Short Papers}})},
  author = {Yih, Wen-tau and Richardson, Matthew and Meek, Chris and Chang, Ming-Wei and Suh, Jina},
  editor = {Erk, Katrin and Smith, Noah A.},
  year = {2016},
  month = aug,
  pages = {201--206},
  publisher = {Association for Computational Linguistics},
  address = {Berlin, Germany},
  doi = {10.18653/v1/P16-2033},
  urldate = {2024-07-10},
}

@misc{yingTransformersReallyPerform2021,
  title = {Do {{Transformers Really Perform Bad}} for {{Graph Representation}}?},
  author = {Ying, Chengxuan and Cai, Tianle and Luo, Shengjie and Zheng, Shuxin and Ke, Guolin and He, Di and Shen, Yanming and Liu, Tie-Yan},
  year = {2021},
  month = nov,
  number = {arXiv:2106.05234},
  eprint = {2106.05234},
  primaryclass = {cs},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/2106.05234},
  urldate = {2024-08-20},
  abstract = {The Transformer architecture has become a dominant choice in many domains, such as natural language processing and computer vision. Yet, it has not achieved competitive performance on popular leaderboards of graph-level prediction compared to mainstream GNN variants. Therefore, it remains a mystery how Transformers could perform well for graph representation learning. In this paper, we solve this mystery by presenting Graphormer, which is built upon the standard Transformer architecture, and could attain excellent results on a broad range of graph representation learning tasks, especially on the recent OGB Large-Scale Challenge. Our key insight to utilizing Transformer in the graph is the necessity of effectively encoding the structural information of a graph into the model. To this end, we propose several simple yet effective structural encoding methods to help Graphormer better model graph-structured data. Besides, we mathematically characterize the expressive power of Graphormer and exhibit that with our ways of encoding the structural information of graphs, many popular GNN variants could be covered as the special cases of Graphormer. The code and models of Graphormer will be made publicly available at https://github.com/Microsoft/Graphormer.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning},
}

@article{yinNeuralMachineTranslating2021,
  title = {Neural Machine Translating from Natural Language to {{SPARQL}}},
  author = {Yin, Xiaoyu and Gromann, Dagmar and Rudolph, Sebastian},
  year = {2021},
  month = apr,
  journal = {Future Generation Computer Systems},
  volume = {117},
  pages = {510--519},
  issn = {0167-739X},
  doi = {10.1016/j.future.2020.12.013},
  urldate = {2024-08-09},
  abstract = {SPARQL is a highly powerful query language for an ever-growing number of resources and knowledge graphs represented in the Resource Description Framework (RDF) data format. Using it requires a certain familiarity with the entities in the domain to be queried as well as expertise in the language's syntax and semantics, none of which average human web users can be assumed to possess. To overcome this limitation, automatically translating natural language questions to SPARQL queries has been a vibrant field of research. However, to this date, the vast success of deep learning methods has not yet been fully propagated to this research problem. This paper contributes to filling this gap by evaluating the utilization of eight different Neural Machine Translation (NMT) models for the task of translating from natural language to the structured query language SPARQL. While highlighting the importance of high-quantity and high-quality datasets, the results show a dominance of a Convolutional Neural Network (CNN)-based architecture with a Bilingual Evaluation Understudy (BLEU) score of up to 98 and accuracy of up to 94\%.},
  keywords = {Learning structured knowledge,Natural language queries,Neural Machine Translation,SPARQL},
}

@article{yuEvaluatingProgressAutomatic2023,
  title = {Evaluating Progress in Automatic Chest {{X-ray}} Radiology Report Generation},
  author = {Yu, Feiyang and Endo, Mark and Krishnan, Rayan and Pan, Ian and Tsai, Andy and Reis, Eduardo Pontes and Fonseca, Eduardo Kaiser Ururahy Nunes and Lee, Henrique Min Ho and Abad, Zahra Shakeri Hossein and Ng, Andrew Y. and Langlotz, Curtis P. and Venugopal, Vasantha Kumar and Rajpurkar, Pranav},
  year = {2023},
  month = sep,
  journal = {Patterns},
  volume = {4},
  number = {9},
  pages = {100802},
  issn = {26663899},
  doi = {10.1016/j.patter.2023.100802},
  urldate = {2024-08-05},
  abstract = {Artificial intelligence (AI) models for automatic generation of narrative radiology reports from images have the potential to enhance efficiency and reduce the workload of radiologists. However, evaluating the correctness of these reports requires metrics that can capture clinically pertinent differences. In this study, we investigate the alignment between automated metrics and radiologists' scoring of errors in report generation. We address the limitations of existing metrics by proposing new metrics, RadGraph F1 and RadCliQ, which demonstrate stronger correlation with radiologists' evaluations. In addition, we analyze the failure modes of the metrics to understand their limitations and provide guidance for metric selection and interpretation. This study establishes RadGraph F1 and RadCliQ as meaningful metrics for guiding future research in radiology report generation.},
  langid = {english},
  keywords = {Evaluation},
}

@misc{zhangFinSQLModelAgnosticLLMsbased2024,
  title = {{{FinSQL}}: {{Model-Agnostic LLMs-based Text-to-SQL Framework}} for {{Financial Analysis}}},
  shorttitle = {{{FinSQL}}},
  author = {Zhang, Chao and Mao, Yuren and Fan, Yijiang and Mi, Yu and Gao, Yunjun and Chen, Lu and Lou, Dongfang and Lin, Jinshu},
  year = {2024},
  month = jan,
  number = {arXiv:2401.10506},
  eprint = {2401.10506},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2401.10506},
  urldate = {2024-02-02},
  abstract = {Text-to-SQL, which provides zero-code interface for operating relational databases, has gained much attention in financial analysis; because, financial professionals may not well-skilled in SQL programming. However, until now, there is no practical Text-toSQL benchmark dataset for financial analysis, and existing Textto-SQL methods have not considered the unique characteristics of databases in financial applications, such as commonly existing wide tables. To address these issues, we collect a practical Text-to-SQL benchmark dataset and propose a model-agnostic Large Language Model (LLMs)-based Text-to-SQL framework for financial analysis. The benchmark dataset, BULL, is collected from the practical financial analysis business of Hundsun Technologies Inc., including databases for fund, stock, and macro economy. Besides, the proposed LLMs-based Text-to-SQL framework, FinSQL, provides a systematic treatment for financial Text-to-SQL from the perspectives of prompt construction, parameter-efficient fine-tuning and output calibration. Extensive experimental results on BULL demonstrate that FinSQL achieves the state-of-the-art Text-to-SQL performance at a small cost; furthermore, FinSQL can bring up to 36.64\% performance improvement in scenarios requiring few-shot cross-database model transfer.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Databases},
}

@article{zhangLearningbasedSPARQLQuery2018,
  title = {Learning-Based {{SPARQL}} Query Performance Modeling and Prediction},
  author = {Zhang, Wei Emma and Sheng, Quan Z. and Qin, Yongrui and Taylor, Kerry and Yao, Lina},
  year = {2018},
  month = jul,
  journal = {World Wide Web},
  volume = {21},
  number = {4},
  pages = {1015--1035},
  issn = {1386-145X, 1573-1413},
  doi = {10.1007/s11280-017-0498-1},
  urldate = {2024-08-17},
  langid = {english},
}

@misc{zhangLLaMAAdapterEfficientFinetuning2023,
  title = {{{LLaMA-Adapter}}: {{Efficient Fine-tuning}} of {{Language Models}} with {{Zero-init Attention}}},
  shorttitle = {{{LLaMA-Adapter}}},
  author = {Zhang, Renrui and Han, Jiaming and Liu, Chris and Gao, Peng and Zhou, Aojun and Hu, Xiangfei and Yan, Shilin and Lu, Pan and Li, Hongsheng and Qiao, Yu},
  year = {2023},
  month = jun,
  number = {arXiv:2303.16199},
  eprint = {2303.16199},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2303.16199},
  urldate = {2024-06-01},
  abstract = {We present LLaMA-Adapter, a lightweight adaption method to efficiently finetune LLaMA into an instruction-following model. Using 52K self-instruct demonstrations, LLaMA-Adapter only introduces 1.2M learnable parameters upon the frozen LLaMA 7B model, and costs less than one hour for fine-tuning on 8 A100 GPUs. Specifically, we adopt a set of learnable adaption prompts, and prepend them to the word tokens at higher transformer layers. Then, a zero-initialized attention mechanism with zero gating is proposed, which adaptively injects the new instructional cues into LLaMA, while effectively preserves its pre-trained knowledge. With our efficient training, LLaMA-Adapter can generate high-quality responses, comparable to Alpaca with fully fine-tuned 7B parameters. Besides language commands, our approach can be simply extended to multi-modal instructions for learning image-conditioned LLaMA model, which achieves superior reasoning performance on ScienceQA and COCO Caption benchmarks. Furthermore, we also evaluate the zero-initialized attention mechanism for fine-tuning other pre-trained models (ViT, RoBERTa) on traditional vision and language tasks, demonstrating the superior generalization capacity of our approach. Code is released at https://github.com/OpenGVLab/LLaMA-Adapter.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Computer Science - Multimedia},
}

@inproceedings{zhangSubgraphRetrievalEnhanced2022,
  title = {Subgraph {{Retrieval Enhanced Model}} for {{Multi-hop Knowledge Base Question Answering}}},
  booktitle = {Proceedings of the 60th {{Annual Meeting}} of the {{Association}} for {{Computational Linguistics}} ({{Volume}} 1: {{Long Papers}})},
  author = {Zhang, Jing and Zhang, Xiaokang and Yu, Jifan and Tang, Jian and Tang, Jie and Li, Cuiping and Chen, Hong},
  editor = {Muresan, Smaranda and Nakov, Preslav and Villavicencio, Aline},
  year = {2022},
  month = may,
  pages = {5773--5784},
  publisher = {Association for Computational Linguistics},
  address = {Dublin, Ireland},
  doi = {10.18653/v1/2022.acl-long.396},
  urldate = {2024-07-30},
  abstract = {Recent works on knowledge base question answering (KBQA) retrieve subgraphs for easier reasoning. The desired subgraph is crucial as a small one may exclude the answer but a large one might introduce more noises. However, the existing retrieval is either heuristic or interwoven with the reasoning, causing reasoning on the partial subgraphs, which increases the reasoning bias when the intermediate supervision is missing. This paper proposes a trainable subgraph retriever (SR) decoupled from the subsequent reasoning process, which enables a plug-and-play framework to enhance any subgraph-oriented KBQA model. Extensive experiments demonstrate SR achieves significantly better retrieval and QA performance than existing retrieval methods. Via weakly supervised pre-training as well as the end-to-end fine-tuning, SR achieves new state-of-the-art performance when combined with NSM (He et al., 2021), a subgraph-oriented reasoner, for embedding-based KBQA methods. Codes and datasets are available online (https://github.com/RUCKBReasoning/SubgraphRetrievalKBQA)},
}

@misc{zhaoRetrievalAugmentedGenerationAIGenerated2024,
  title = {Retrieval-{{Augmented Generation}} for {{AI-Generated Content}}: {{A Survey}}},
  shorttitle = {Retrieval-{{Augmented Generation}} for {{AI-Generated Content}}},
  author = {Zhao, Penghao and Zhang, Hailin and Yu, Qinhan and Wang, Zhengren and Geng, Yunteng and Fu, Fangcheng and Yang, Ling and Zhang, Wentao and Jiang, Jie and Cui, Bin},
  year = {2024},
  month = jun,
  number = {arXiv:2402.19473},
  eprint = {2402.19473},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2402.19473},
  urldate = {2024-08-26},
  abstract = {Advancements in model algorithms, the growth of foundational models, and access to high-quality datasets have propelled the evolution of Artificial Intelligence Generated Content (AIGC). Despite its notable successes, AIGC still faces hurdles such as updating knowledge, handling long-tail data, mitigating data leakage, and managing high training and inference costs. Retrieval-Augmented Generation (RAG) has recently emerged as a paradigm to address such challenges. In particular, RAG introduces the information retrieval process, which enhances the generation process by retrieving relevant objects from available data stores, leading to higher accuracy and better robustness. In this paper, we comprehensively review existing efforts that integrate RAG technique into AIGC scenarios. We first classify RAG foundations according to how the retriever augments the generator, distilling the fundamental abstractions of the augmentation methodologies for various retrievers and generators. This unified perspective encompasses all RAG scenarios, illuminating advancements and pivotal technologies that help with potential future progress. We also summarize additional enhancements methods for RAG, facilitating effective engineering and implementation of RAG systems. Then from another view, we survey on practical applications of RAG across different modalities and tasks, offering valuable references for researchers and practitioners. Furthermore, we introduce the benchmarks for RAG, discuss the limitations of current RAG systems, and suggest potential directions for future research. Github: https://github.com/PKU-DAIR/RAG-Survey.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@article{zhengSemanticSPARQLSimilarity2016,
  title = {Semantic {{SPARQL}} Similarity Search over {{RDF}} Knowledge Graphs},
  author = {Zheng, Weiguo and Zou, Lei and Peng, Wei and Yan, Xifeng and Song, Shaoxu and Zhao, Dongyan},
  year = {2016},
  month = jul,
  journal = {Proc. VLDB Endow.},
  volume = {9},
  number = {11},
  pages = {840--851},
  issn = {2150-8097},
  doi = {10.14778/2983200.2983201},
  urldate = {2024-08-30},
  abstract = {RDF knowledge graphs have attracted increasing attentions these years. However, due to the schema-free nature of RDF data, it is very difficult for users to have full knowledge of the underlying schema. Furthermore, the same kind of information can be represented in diverse graph fragments. Hence, it is a huge challenge to formulate complex SPARQL expressions by taking the union of all possible structures.In this paper, we propose an effective framework to access the RDF repository even if users have no full knowledge of the underlying schema. Specifically, given a SPARQL query, the system could return as more answers that match the query based on the semantic similarity as possible. Interestingly, we propose a systematic method to mine diverse semantically equivalent structure patterns. More importantly, incorporating both structural and semantic similarities we are the first to propose a novel similarity measure, semantic graph edit distance. In order to improve the efficiency performance, we apply the semantic summary graph to summarize the knowledge graph, which supports both high-level pruning and drill-down pruning. We also devise an effective lower bound based on the TA-style access to each of the candidate sets. Extensive experiments over real datasets confirm the effectiveness and efficiency of our approach.},
}

@inproceedings{zhengTellingStoriesComputational2022,
  title = {Telling {{Stories}} from {{Computational Notebooks}}: {{AI-Assisted Presentation Slides Creation}} for {{Presenting Data Science Work}}},
  shorttitle = {Telling {{Stories}} from {{Computational Notebooks}}},
  booktitle = {{{CHI Conference}} on {{Human Factors}} in {{Computing Systems}}},
  author = {Zheng, Chengbo and Wang, Dakuo and Wang, April Yi and Ma, Xiaojuan},
  year = {2022},
  month = apr,
  pages = {1--20},
  doi = {10.1145/3491102.3517615},
  urldate = {2024-04-07},
  abstract = {Creating presentation slides is a critical but time-consuming task for data scientists. While researchers have proposed many AI techniques to lift data scientists' burden on data preparation and model selection, few have targeted the presentation creation task. Based on the needs identified from a formative study, this paper presents NB2Slides, an AI system that facilitates users to compose presentations of their data science work. NB2Slides uses deep learning methods as well as example-based prompts to generate slides from computational notebooks, and take users' input (e.g., audience background) to structure the slides. NB2Slides also provides an interactive visualization that links the slides with the notebook to help users further edit the slides. A follow-up user evaluation with 12 data scientists shows that participants believed NB2Slides can improve efficiency and reduces the complexity of creating slides. Yet, participants questioned the future of full automation and suggested a human-AI collaboration paradigm.},
  keywords = {Computer Science - Human-Computer Interaction,Computer Science - Machine Learning},
}

@misc{zhongSeq2SQLGeneratingStructured2017,
  title = {{{Seq2SQL}}: {{Generating Structured Queries}} from {{Natural Language}} Using {{Reinforcement Learning}}},
  shorttitle = {{{Seq2SQL}}},
  author = {Zhong, Victor and Xiong, Caiming and Socher, Richard},
  year = {2017},
  month = nov,
  number = {arXiv:1709.00103},
  eprint = {1709.00103},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1709.00103},
  urldate = {2024-05-28},
  abstract = {Relational databases store a significant amount of the worlds data. However, accessing this data currently requires users to understand a query language such as SQL. We propose Seq2SQL, a deep neural network for translating natural language questions to corresponding SQL queries. Our model uses rewards from inthe-loop query execution over the database to learn a policy to generate the query, which contains unordered parts that are less suitable for optimization via cross entropy loss. Moreover, Seq2SQL leverages the structure of SQL to prune the space of generated queries and significantly simplify the generation problem. In addition to the model, we release WikiSQL, a dataset of 80654 hand-annotated examples of questions and SQL queries distributed across 24241 tables from Wikipedia that is an order of magnitude larger than comparable datasets. By applying policybased reinforcement learning with a query execution environment to WikiSQL, Seq2SQL outperforms a state-of-the-art semantic parser, improving execution accuracy from 35.9\% to 59.4\% and logical form accuracy from 23.4\% to 48.3\%.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
}

@article{zhouGraphNeuralNetworks2020,
  title = {Graph Neural Networks: {{A}} Review of Methods and Applications},
  shorttitle = {Graph Neural Networks},
  author = {Zhou, Jie and Cui, Ganqu and Hu, Shengding and Zhang, Zhengyan and Yang, Cheng and Liu, Zhiyuan and Wang, Lifeng and Li, Changcheng and Sun, Maosong},
  year = {2020},
  journal = {AI Open},
  volume = {1},
  pages = {57--81},
  issn = {26666510},
  doi = {10.1016/j.aiopen.2021.01.001},
  urldate = {2024-08-20},
  abstract = {Lots of learning tasks require dealing with graph data which contains rich relation information among elements. Modeling physics systems, learning molecular fingerprints, predicting protein interface, and classifying diseases demand a model to learn from graph inputs. In other domains such as learning from non-structural data like texts and images, reasoning on extracted structures (like the dependency trees of sentences and the scene graphs of images) is an important research topic which also needs graph reasoning models. Graph neural networks (GNNs) are neural models that capture the dependence of graphs via message passing between the nodes of graphs. In recent years, variants of GNNs such as graph convolutional network (GCN), graph attention network (GAT), graph recurrent network (GRN) have demonstrated ground-breaking performances on many deep learning tasks. In this survey, we propose a general design pipeline for GNN models and discuss the variants of each component, systematically categorize the applications, and propose four open problems for future research.},
  langid = {english},
  keywords = {Formalization,GNN},
}

@article{zhuangComprehensiveSurveyTransfer2021,
  title = {A {{Comprehensive Survey}} on {{Transfer Learning}}},
  author = {Zhuang, Fuzhen and Qi, Zhiyuan and Duan, Keyu and Xi, Dongbo and Zhu, Yongchun and Zhu, Hengshu and Xiong, Hui and He, Qing},
  year = {2021},
  month = jan,
  journal = {Proceedings of the IEEE},
  volume = {109},
  number = {1},
  pages = {43--76},
  issn = {1558-2256},
  doi = {10.1109/JPROC.2020.3004555},
  urldate = {2024-08-26},
  abstract = {Transfer learning aims at improving the performance of target learners on target domains by transferring the knowledge contained in different but related source domains. In this way, the dependence on a large number of target-domain data can be reduced for constructing target learners. Due to the wide application prospects, transfer learning has become a popular and promising area in machine learning. Although there are already some valuable and impressive surveys on transfer learning, these surveys introduce approaches in a relatively isolated way and lack the recent advances in transfer learning. Due to the rapid expansion of the transfer learning area, it is both necessary and challenging to comprehensively review the relevant studies. This survey attempts to connect and systematize the existing transfer learning research studies, as well as to summarize and interpret the mechanisms and the strategies of transfer learning in a comprehensive way, which may help readers have a better understanding of the current research status and ideas. Unlike previous surveys, this survey article reviews more than 40 representative transfer learning approaches, especially homogeneous transfer learning approaches, from the perspectives of data and model. The applications of transfer learning are also briefly introduced. In order to show the performance of different transfer learning models, over 20 representative transfer learning models are used for experiments. The models are performed on three different data sets, that is, Amazon Reviews, Reuters-21578, and Office-31, and the experimental results demonstrate the importance of selecting appropriate transfer learning models for different applications in practice.},
  keywords = {Adaptation models,Covariance matrices,Data models,Domain adaptation,interpretation,machine learning,Machine learning,Semisupervised learning,transfer learning,Transfer learning},
}

@misc{zhuCanChatGPTReproduce2023,
  title = {Can {{ChatGPT Reproduce Human-Generated Labels}}? {{A Study}} of {{Social Computing Tasks}}},
  shorttitle = {Can {{ChatGPT Reproduce Human-Generated Labels}}?},
  author = {Zhu, Yiming and Zhang, Peixian and Haq, Ehsan-Ul and Hui, Pan and Tyson, Gareth},
  year = {2023},
  month = apr,
  number = {arXiv:2304.10145},
  eprint = {2304.10145},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2304.10145},
  urldate = {2024-08-01},
  abstract = {The release of ChatGPT has uncovered a range of possibilities whereby large language models (LLMs) can substitute human intelligence. In this paper, we seek to understand whether ChatGPT has the potential to reproduce human-generated label annotations in social computing tasks. Such an achievement could significantly reduce the cost and complexity of social computing research. As such, we use ChatGPT to re-label five seminal datasets covering stance detection (2x), sentiment analysis, hate speech, and bot detection. Our results highlight that ChatGPT does have the potential to handle these data annotation tasks, although a number of challenges remain. ChatGPT obtains an average accuracy 0.609. Performance is highest for the sentiment analysis dataset, with ChatGPT correctly annotating 64.9\% of tweets. Yet, we show that performance varies substantially across individual labels. We believe this work can open up new lines of analysis and act as a basis for future research into the exploitation of ChatGPT for human annotation tasks.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
}

@article{zouGraphBasedRDFData2017,
  title = {Graph-{{Based RDF Data Management}}},
  author = {Zou, Lei and {\"O}zsu, M. Tamer},
  year = {2017},
  month = mar,
  journal = {Data Science and Engineering},
  volume = {2},
  pages = {1--15},
  doi = {10.1007/s41019-016-0029-6},
  abstract = {The increasing size of RDF data requires efficient systems to store and query them. There have been efforts to map RDF data to a relational representation, and a number of systems exist that follow this approach. We have been investigating an alternative approach of maintaining the native graph model to represent RDF data, and utilizing graph database techniques (such as a structure-aware index and a graph matching algorithm) to address RDF data management. Since 2009, we have been developing a set of graph-based RDF data management systems that follow this approach: gStore, gStore-D and gAnswer. The first two are designed to support efficient SPARQL query evaluation in a centralized and distributed/parallel environments, respectively, while the last one aims to provide an easy-to-use interface (natural language question/answering) for users to access a RDF repository. In this paper, we give an overview of these systems and also discuss our design philosophy.},
}

@article{zouGStoreAnsweringSPARQL2011,
  title = {{{gStore}}: Answering {{SPARQL}} Queries via Subgraph Matching},
  shorttitle = {{{gStore}}},
  author = {Zou, Lei and Mo, Jinghui and Chen, Lei and {\"O}zsu, M. Tamer and Zhao, Dongyan},
  year = {2011},
  month = may,
  journal = {Proc. VLDB Endow.},
  volume = {4},
  number = {8},
  pages = {482--493},
  issn = {2150-8097},
  doi = {10.14778/2002974.2002976},
  urldate = {2024-07-31},
  abstract = {Due to the increasing use of RDF data, efficient processing of SPARQL queries over RDF datasets has become an important issue. However, existing solutions suffer from two limitations: 1) they cannot answer SPARQL queries with wildcards in a scalable manner; and 2) they cannot handle frequent updates in RDF repositories efficiently. Thus, most of them have to reprocess the dataset from scratch. In this paper, we propose a graph-based approach to store and query RDF data. Rather than mapping RDF triples into a relational database as most existing methods do, we store RDF data as a large graph. A SPARQL query is then converted into a corresponding subgraph matching query. In order to speed up query processing, we develop a novel index, together with some effective pruning rules and efficient search algorithms. Our method can answer exact SPARQL queries and queries with wildcards in a uniform manner. We also propose an effective maintenance algorithm to handle online updates over RDF repositories. Extensive experiments confirm the efficiency and effectiveness of our solution.},
}
